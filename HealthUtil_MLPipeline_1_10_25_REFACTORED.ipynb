{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the key packages\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import sklearn\n",
    "import hyperopt\n",
    "from hyperopt import hp\n",
    "import imblearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.calibration as cal\n",
    "import xgboost as xgb\n",
    "import sklearn.utils.class_weight as wt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from pathlib import Path\n",
    "from sklearn import datasets, metrics, model_selection, svm\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import skopt\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "import multiprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 12:30:54.624138: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/anaconda3/envs/myConda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers, utils, backend as K, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "#tensorflow.compat.v1.disable_v2_behavior() \n",
    "import random\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from numpy.ma import MaskedArray\n",
    "import sklearn.utils.fixes\n",
    "\n",
    "import miceforest as mf\n",
    "\n",
    "sklearn.utils.fixes.MaskedArray = MaskedArray\n",
    "\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configure the logging module\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.23.5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 12:30:59,638\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-01-19 12:30:59,984\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "## Rays and tune imports\n",
    "from tune_sklearn import TuneSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.2\n",
      "0.46.0\n",
      "2.16.2\n",
      "2.2.3\n",
      "1.23.5\n",
      "2.1.1\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSHOUD BE THE FOLLOWING WITH 3.11.0\\n1.5.2\\n0.46.0\\n2.16.2\\n2.2.3\\n1.23.5\\n2.1.1\\nsetuptools for conda == 41.0.0\\nTrue\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### USING PYTHON 3.11.0\n",
    "print(sklearn.__version__)\n",
    "print(shap.__version__)\n",
    "print(tf.__version__)\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(xgb.__version__)\n",
    "print(tf.executing_eagerly())\n",
    "\n",
    "'''\n",
    "Should be: \n",
    "1.5.2\n",
    "0.46.0\n",
    "2.16.2\n",
    "2.2.2\n",
    "1.26.4\n",
    "True\n",
    "'''\n",
    "\n",
    "'''\n",
    "SHOUD BE THE FOLLOWING WITH 3.11.0\n",
    "1.5.2\n",
    "0.46.0\n",
    "2.16.2\n",
    "2.2.3\n",
    "1.23.5\n",
    "2.1.1\n",
    "setuptools for conda == 41.0.0\n",
    "True\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Initializing dataframes to store the results\n",
    "\n",
    "\n",
    "all_results = []\n",
    "\n",
    "\n",
    "# hyperparam_results = pd.DataFrame(\n",
    "#     {\n",
    "#         \"Procedure\": [],\n",
    "#         \"Outcome\": [],\n",
    "#         \"Features\": [],\n",
    "#         \"Model\": [],\n",
    "#         \"Rep\": [],\n",
    "#         \"Hyp_Name\": [],\n",
    "#         \"Hyp_Value\": []\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "feature_results = []\n",
    "\n",
    "auc_plot_results = []\n",
    "\n",
    "\n",
    "# Areas which below pipeline will iterate through -- CHANGE THIS BASED ON NEED\n",
    "\n",
    "\n",
    "#binary_outcomes = np.array([\"readmission_binary\", \"major_med_comp\", \"extended_los\", \"returnor\", \"wnd_related_comp\"])\n",
    "#binary_outcomes = np.array([\"readmission_binary\"])\n",
    "#binary_outcomes = np.array([\"returnor\", \"any_med_comp_no_wnd\", \"any_med_comp_wnd\", \"any_comp_overall\"])\n",
    "binary_outcomes = [\"High_Health_Utilizer\"]\n",
    "\n",
    "#continuous_outcomes = np.array([\"outpatient_resource_sum\", \"los_days\"])\n",
    "#continuous_outcomes = np.array(['los_days'])\n",
    "\n",
    "continuous_outcomes = []\n",
    "\n",
    "\n",
    "outcomes = binary_outcomes + continuous_outcomes\n",
    "\n",
    "#procedures = [\"Microdisc\", \"Foraminotomy\", \"Laminectomy\", \"AXDLIF\", \"PLF\", \"PTLIF\"]\n",
    "procedures = [\"Fusion\", \"Decompression\"]\n",
    "\n",
    "\n",
    "#features = [\"Spine_Institution\", \"Spine_NSQIP\", \"Peripheral_NSQIP\"]\n",
    "#features = [\"Spine_Institution\"]\n",
    "#features = [\"Peripheral_NSQIP\"]\n",
    "#features = [\"PLS_features\"]\n",
    "features = [\"Health_Util_Features\"]\n",
    "feature = features[0]\n",
    "\n",
    "model_set = [\"RF\", \"ENet\", \"XGBoost\", \"NN\", \"ASA\", \"Dummy\"]\n",
    "#model_set = [\"RF\"]\n",
    "\n",
    "#model_set = [\"XGBoost\"]\n",
    "#model_set = [\"Dummy\"]\n",
    "\n",
    "\n",
    "\n",
    "repetitions = list(range(10)) #TODO: Change to range(10)\n",
    "date = \"01_14_25\"\n",
    "impute_iterations = 2 #TODO CHANGE TO 2\n",
    "tunesearch_iterations = 10 #TODO: Switch to 10\n",
    "Get_shaps = False #TODO: DO I WANT SHAPS?\n",
    "procedure_of_interest = \"Decompression\" #TODO: Change procedure-of-interest\n",
    "pickle_folder_name = \"Labs\" # Change when doing a different pickling #NoLabs\n",
    "FullDataset_model = \"RF\"\n",
    "feature_perturbation_version = \"tree_path_dependent\" #TODO: For full dataset model RF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_random_seed(rep):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    os.environ['PYTHONHASHSEED']=str(rep)\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "    tf.random.set_seed(rep)\n",
    "    np.random.seed(rep)\n",
    "    random.seed(rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(procedure):\n",
    "    readdata = pd.read_csv(r\"122124_Spine_Reports.csv\", sep=',')\n",
    "    \n",
    "    if procedure == \"Fusion\":\n",
    "        readdata = readdata[\n",
    "            (readdata['cpt_thoracolumbar_sacro_arthrodesis'] == True) &\n",
    "            (readdata['cohort_query_lumbar'] == True)\n",
    "            ]\n",
    "    elif procedure == \"Decompression\":\n",
    "        readdata = readdata[\n",
    "            (readdata['cpt_thoracolumbar_sacro_arthrodesis'] == False) & \n",
    "            (readdata['cohort_query_spinal_decompression'] == True) & \n",
    "            (readdata['cohort_query_lumbar'] == True)\n",
    "        ]\n",
    "\n",
    "\n",
    "    readdata = readdata.reset_index(drop=True)\n",
    "    return readdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preop_to_binary(input_df):\n",
    "    df = input_df.copy()\n",
    "    # Get all columns that start with \"preop_med_\"\n",
    "    preop_med_cols = [col for col in df.columns if col.startswith('preop_med_')]\n",
    "    print(f\"There are {len(preop_med_cols)} preop columns\")\n",
    "\n",
    "    # Check for missing values first\n",
    "    missing_values = {col: df[col].isna().sum() \n",
    "                    for col in preop_med_cols \n",
    "                    if df[col].isna().any()}\n",
    "\n",
    "    if missing_values:\n",
    "        raise ValueError(f\"Missing values found in the following columns: {missing_values}\")\n",
    "\n",
    "    # Convert to boolean if no missing values found\n",
    "    for col in preop_med_cols:\n",
    "        # Store original values for verification\n",
    "        original_values = df[col].value_counts()\n",
    "        \n",
    "        # Convert: 0 -> False, >=1 -> True\n",
    "        df[col] = df[col] > 0\n",
    "        \n",
    "        # Print verification of the conversion\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        print(\"Original value counts:\")\n",
    "        print(original_values)\n",
    "        print(\"New value counts:\")\n",
    "        print(df[col].value_counts())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_columns_remove_rows(input_df):\n",
    "\n",
    "    df = input_df.copy()\n",
    "    # Recode categorical columns\n",
    "        # anesthesia_type\n",
    "    df['anesthesia_type_General'] = df['anesthesia_type'].apply(\n",
    "        lambda x: 1 if pd.notna(x) and str(x).upper() == 'GENERAL'\n",
    "                  else (0 if pd.notna(x)  # if it's not NaN and not 'GENERAL', return 0\n",
    "                        else np.nan)  # if it's NaN, return np.nan\n",
    "    )\n",
    "    df['anesthesia_type_General'] = df['anesthesia_type_General'].astype('Int64')\n",
    "    \n",
    "    #procedure_setting\n",
    "    df['procedure_setting_Inpatient'] = df['procedure_setting'].apply(lambda x: 1 if str(x).upper() == 'INPATIENT' \n",
    "                                            else (0 if str(x).upper() == 'OUTPATIENT' \n",
    "                                            else np.nan))\n",
    "    df['procedure_setting_Inpatient'] = df['procedure_setting_Inpatient'].astype('Int64')\n",
    "    # Recode gender into new binary column\n",
    "    df['gender_female'] = df['gender'].apply(lambda x: 1 if str(x).upper() == 'F' \n",
    "                                           else (0 if str(x).upper() == 'M' \n",
    "                                           else np.nan))\n",
    "    df['gender_female'] = df['gender_female'].astype('Int64')\n",
    "\n",
    "    # add allograft and autograft columns\n",
    "    df['cpt_allograft'] = df['procedure_codes'].str.contains('20930|20931').astype(bool)\n",
    "    df['cpt_autograft'] = df['procedure_codes'].str.contains('20936|20937|20938').astype(bool)\n",
    "\n",
    "    # Anterior approach codes\n",
    "    df['cpt_anterior_approach'] = df['procedure_codes'].str.contains(\n",
    "        '22556|22558|22586|22808|22810|22812'\n",
    "    ).astype(bool)\n",
    "\n",
    "    # Lateral approach codes\n",
    "    df['cpt_lateral_approach'] = df['procedure_codes'].str.contains(\n",
    "        '22533|22534'\n",
    "    ).astype(bool)\n",
    "\n",
    "    # Posterior approach codes\n",
    "    df['cpt_posterior_approach'] = df['procedure_codes'].str.contains(\n",
    "        '22610|22612|22800|22802|22804|22630|22632|22633|22634|27279|27280'\n",
    "    ).astype(bool)\n",
    "\n",
    "    # Convert surgery_start_datetime to datetime type if it isn't already\n",
    "    df['surgery_start_datetime_date'] = pd.to_datetime(df['surgery_start_datetime'])\n",
    "    df['surgery_end_datetime_date'] = pd.to_datetime(df['surgery_end_datetime'])\n",
    "    df['patient_in_or_datetime_date'] = pd.to_datetime(df['patient_in_or_datetime'])\n",
    "    df['patient_out_or_datetime_date'] = pd.to_datetime(df['patient_out_or_datetime'])\n",
    "    df['anesthesia_start_datetime_date'] = pd.to_datetime(df['anesthesia_start_datetime'])\n",
    "    df['anesthesia_stop_datetime_date'] = pd.to_datetime(df['anesthesia_stop_datetime'])\n",
    "    \n",
    "    # Create date filters\n",
    "    start_date = pd.to_datetime('2003-01-01')\n",
    "    end_date = pd.to_datetime('2022-10-01')\n",
    "    \n",
    "    df = df[\n",
    "        # Date conditions\n",
    "        (df['surgery_start_datetime_date'] >= start_date) & \n",
    "        (df['surgery_start_datetime_date'] < end_date) &\n",
    "        # Age filter - exclude patients under 18\n",
    "        (df['age_at_procedure'] >= 18) &\n",
    "        # Previous conditions (negated)\n",
    "        ~(df['spine_preop_tumor'] | \n",
    "          df['spine_preop_trauma'] | \n",
    "          df['spine_preop_infection'] |\n",
    "          df['cpt_tumor'] |\n",
    "          df['cpt_trauma'] | \n",
    "          df['spine_preop_curvature'] |\n",
    "          df['cpt_deformity']|\n",
    "          df['cpt_infection'])\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "    # Remove neg los patient 1338489,\"2012-05-02 09:43:00\"\n",
    "    df = df[~((df['ir_id'] == 1338489) & \n",
    "                   (df['surgery_start_datetime'] == \"2012-05-02 09:43:00\"))]\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    ### Clean BMI: Make NA for >100 and =0\n",
    "    df.loc[(df['BMI'] > 100) | (df['BMI'] == 0), 'BMI'] = np.nan\n",
    "\n",
    "    ### Clean Anesthesia: Make NA for >=20\n",
    "    df.loc[df['anesthesia_duration_hours'] >= 20, 'anesthesia_duration_hours'] = np.nan\n",
    "\n",
    "\n",
    "    # Make columns in hours and minutes for surgery length\n",
    "    # Calculate lengths\n",
    "    df['OR_length_hours'] = ((df['patient_out_or_datetime_date'] - \n",
    "                                df['patient_in_or_datetime_date']).dt.total_seconds() / 3600).round()\n",
    "    df['OR_length_minutes'] = ((df['patient_out_or_datetime_date'] - \n",
    "                                    df['patient_in_or_datetime_date']).dt.total_seconds() / 60).round()\n",
    "\n",
    "    df['anesthesia_length_hours'] = ((df['anesthesia_stop_datetime_date'] - \n",
    "                                    df['anesthesia_start_datetime_date']).dt.total_seconds() / 3600).round()\n",
    "    df['anesthesia_length_minutes'] = ((df['anesthesia_stop_datetime_date'] - \n",
    "                                        df['anesthesia_start_datetime_date']).dt.total_seconds() / 60).round()\n",
    "    \n",
    "    df['surgery_length_hours'] = ((df['surgery_end_datetime_date'] -\n",
    "                                    df['surgery_start_datetime_date']).dt.total_seconds() / 3600).round()\n",
    "    df['surgery_length_minutes'] = ((df['surgery_end_datetime_date'] -\n",
    "                                    df['surgery_start_datetime_date']).dt.total_seconds() / 60).round()\n",
    "\n",
    "    # Handle missing values\n",
    "    OR_missing = df['patient_in_or_datetime_date'].isna() | df['patient_out_or_datetime_date'].isna()\n",
    "    anesthesia_missing = df['anesthesia_start_datetime_date'].isna() | df['anesthesia_stop_datetime_date'].isna()\n",
    "    surgery_missing = df['surgery_start_datetime_date'].isna() | df['surgery_end_datetime_date'].isna()\n",
    "\n",
    "    df.loc[OR_missing, ['OR_length_hours', 'OR_length_minutes']] = np.nan\n",
    "    df.loc[anesthesia_missing, ['anesthesia_length_hours', 'anesthesia_length_minutes']] = np.nan\n",
    "    df.loc[surgery_missing, ['surgery_length_hours', 'surgery_length_minutes']] = np.nan\n",
    "\n",
    "    # Convert to integer type (while preserving NaN values)\n",
    "    length_columns = ['OR_length_hours', 'OR_length_minutes',\n",
    "                    'anesthesia_length_hours', 'anesthesia_length_minutes',\n",
    "                    'surgery_length_hours', 'surgery_length_minutes']\n",
    "    df[length_columns] = df[length_columns].astype('Int64')  # Int64 allows for NaN values\n",
    "\n",
    "     ### Clean Anesthesia: Make NA for >=20\n",
    "    df.loc[df['anesthesia_length_hours'] >= 20, 'anesthesia_length_hours'] = np.nan\n",
    "    df.loc[df['anesthesia_length_minutes'] >= 20*60, 'anesthesia_length_minutes'] = np.nan\n",
    "\n",
    "    ### clean surgery: make NA for > 1000 hours or eqivalent minutes\n",
    "    df.loc[df['surgery_length_hours'] >= 20, 'surgery_length_hours'] = np.nan\n",
    "    df.loc[df['surgery_length_minutes'] >= 20*60, 'surgery_length_minutes'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_labs_90(df):\n",
    "\n",
    "    input_df = df.copy()\n",
    "\n",
    "    # Create columns lists for days_before\n",
    "    CBC_cols = [\"CBC_MONOCYTES\", \"CBC_NEUTROPHILS\", \"CBC_BASOPHILS\", \"CBC_PLATELET_COUNT\",\n",
    "                    \"CBC_WBC_COUNT\", \"CBC_HEMOGLOBIN\", \"CBC_RBC_COUNT\",\n",
    "                    \"CBC_RDW\", \"CBC_HEMATOCRIT\", \"CBC_MCH\", \"CBC_MCHC\",\n",
    "                    \"CBC_ABSOLUTE_LYMPHOCYTES\", \"CBC_ABSOLUTE_NEUTROPHILS\",\n",
    "                    \"CBC_LYMPHOCYTE\", \"CBC_EOSINOPHILS\", \"CBC_ABSOLUTE_EOSINOPHILS\",\n",
    "                    \"CBC_ABSOLUTE_BASOPHILS\", \"CBC_ABSOLUTE_MONOCYTES\"]\n",
    "    \n",
    "    CBC_date_cols = [col + \"_days_before_surgery\" for col in CBC_cols]\n",
    "        \n",
    "    BMP_cols = [\"BMP_POTASSIUM\", \"BMP_CREATININE\", \"BMP_BUN\", \"BMP_CALCIUM\", \"BMP_CHLORIDE\", \n",
    "                    \"BMP_SODIUM\", \"BMP_CO2\", \"BMP_GLUCOSE\"]\n",
    "    BMP_date_cols = [col + \"_days_before_surgery\" for col in BMP_cols]\n",
    "\n",
    "    lab_cols = CBC_cols + BMP_cols\n",
    "    lab_days_before = CBC_date_cols + BMP_date_cols\n",
    "    lab_pairs = [(lab_cols[i], lab_days_before[i]) for i in range(len(lab_cols))]\n",
    "    print(lab_pairs)\n",
    "\n",
    "    def extract_days(x):\n",
    "        if pd.isna(x):\n",
    "            return np.nan\n",
    "        # Extract just the number before \"days\"\n",
    "        try:\n",
    "            return float(str(x).split()[0])\n",
    "        except:\n",
    "            return np.nan\n",
    "    # Process each pair of columns\n",
    "    for lab_col, days_col in lab_pairs:\n",
    "        # Convert the days strings to numbers\n",
    "        days = input_df[days_col].apply(extract_days)\n",
    "\n",
    "        # Create a mask for values > 90 days\n",
    "        mask = days > 90\n",
    "        \n",
    "        # Set the lab values to NaN where mask is True\n",
    "        input_df[lab_col] = input_df[lab_col].mask(mask)\n",
    "\n",
    "\n",
    "    return input_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_columns(data, outcome, pofI):\n",
    "    individual_features_shap_full = []\n",
    "    # Basic demographics = age, sex, race (not present), BMI\n",
    "    basic_demographics = [\"ir_id\", \"surgery_start_datetime\", \"age_at_procedure\", \"gender_female\", \"BMI\"]\n",
    "\n",
    "    #Med hx: include all of the comorbidities with the elix_ prefix. \n",
    "    # Those are based on the Elixhauser comorbidity guidelines and \n",
    "    # are the most comprehensive. We broke out several other frailty\n",
    "    #  tools (CCI, MFI, etc) but these are ultimately duplicative \n",
    "    # and not as comprehensive (i.e. don’t worry about including). \n",
    "    # I do not believe elixhauser has anything on tobacco. \n",
    "    # If ther isn’t, then use validation_fmr_tobacco and \n",
    "    # validation_cur_tobacco.\n",
    "\n",
    "    Medhx = [\"elix_aids_hiv\", \"elix_lymphoma\", \"elix_paralysis\",\n",
    "            \"elix_psychoses\", \"elix_depression\", \"elix_drug_abuse\", \"elix_weight_loss\",\n",
    "            \"elix_coagulopathy\", \"elix_alcohol_abuse\", \"elix_liver_disease\", \"elix_renal_failure\",\n",
    "            \"elix_hypothyroidism\", \"elix_valvular_disease\", \"elix_blood_loss_anemia\",\n",
    "            \"elix_deficiency_anemia\", \"elix_metastatic_cancer\", \"elix_cardiac_arrhythmia\",\n",
    "            \"elix_rheumatoid_arhritis\", \"elix_diabetes_complicated\", \"elix_diabetes_uncomplicated\", \n",
    "            \"elix_congestive_heart_failure\", \"elix_hypertension_complicated\", \"elix_chronic_pulmonary_disease\",\n",
    "            \"elix_solid_tumor_wo_metastasis\", \"elix_hypertension_uncomplicated\", \"elix_other_neurological_disorder\",\n",
    "            \"elix_peripheral vascular_disorder\", \"elix_pulmonary_circulation_disorder\", \"elix_fluid_and_electrolyte_disorders\",\n",
    "            \"elix_peptic_ulcer_disease_excluding_bleeding\", \"validation_cur_tobacco\", \"validation_fmr_tobacco\"]\n",
    "    \n",
    "    #Surg hx: look at the shx_ prefix variables and include those\n",
    "\n",
    "    Surghx = [\"shx_cervical_fusion\", \"shx_cervical_surgery\", \"shx_thoracolumbar_fusion\",\n",
    "                \"shx_thoracolumbar_surgery\", \"shx_unspecified_spine_fusion\", \"shx_unspecified_spine_surgery\"]\n",
    "    \n",
    "    #Spine-specific preop pathology: lumbar stenosis, lumbar spondy, \n",
    "    # lumbar disc disorders, lumbar disc herniation (all binary columns)\n",
    "    SpineSpecific = [\"lumbar_stenosis\", \"lumbar_spondy\", \"lumbar_disc_disorders\",\n",
    "                        \"cervical_disc_diorders\", \"cervical_stenosis\", \"cervical_spondy\",\n",
    "                        \"cervical_disc_herniation\", \"lumbar_disc_herniation\", \"spine_preop_pseudoarthrosis_post_fusion\", \"spine_preop_post_laminectomy_syndrome\"]\n",
    "\n",
    "    #Medication hx: look for preop_med_ suffix. Also just focus on 90\n",
    "    #  days preop for this analysis. Exclude anything with _sorg in the\n",
    "    #  name (that is for a separate validation analysis)\n",
    "\n",
    "    Medicationhx = [\"preop_med_90days_ace_inhibitor\", \"preop_med_90days_arb\", \"preop_med_90days_antidepressant\",\n",
    "                \"preop_med_90days_beta_2_agonist\", \"preop_med_90days_beta_blocker\", \"preop_med_90days_benzodiazepine\",\n",
    "                \"preop_med_90days_immunosuppresant\", \"preop_med_90days_nsaid\", \"preop_med_90days_opioid\", \"preop_med_90days_anti_psychotic\",\n",
    "                \"preop_med_90days_neuromodulator\", \"preop_med_90days_biphosphonate\", \"preop_med_90days_loop_diuretic\",\n",
    "                \"preop_med_90days_thiazide_diuretic\", \"preop_med_90days_cinacalcet\", \"preop_med_90days_insulin\", \n",
    "                \"preop_med_90days_oral_diabetes\", \"preop_med_90days_calcium_supplement\", \"preop_med_90days_vit_d_supplement\"]\n",
    "\n",
    "    #Surgical characteristics: inpatient versus outpatient, type of anesthesia \n",
    "    # (should almost always be general, but a few weird ones here and there), \n",
    "    # OR duration, anesthesia duration, cpt_multilevel, cpt_grafts, \n",
    "    # cpt_instrumentation (tell us more about what was done during the case)\n",
    "\n",
    "    SurgCharsNumeric = [\"asa_class\", \"OR_length_minutes\",\n",
    "                        \"cpt_multilevel\", \"cpt_instrumentation\", \n",
    "                        \"cohort_query_microdisc\", \"anesthesia_type_General\", \"procedure_setting_Inpatient\"]\n",
    "    \n",
    "    Approaches = [\"cpt_anterior_approach\", \"cpt_lateral_approach\", \"cpt_posterior_approach\"]\n",
    "\n",
    "    #Add approach columns if Fusion\n",
    "    if pofI == \"Fusion\":\n",
    "        SurgCharsNumeric = SurgCharsNumeric + Approaches\n",
    "\n",
    "    #SurgCharsCat = [\"anesthesia_type\", \"procedure_setting\"]\n",
    "\n",
    "    # CBC and BMP, all with <50% missing values\n",
    "\n",
    "    CBC_cols = [\"CBC_MONOCYTES\", \"CBC_NEUTROPHILS\", \"CBC_BASOPHILS\", \"CBC_PLATELET_COUNT\",\n",
    "                \"CBC_WBC_COUNT\", \"CBC_HEMOGLOBIN\", \"CBC_RBC_COUNT\",\n",
    "                \"CBC_RDW\", \"CBC_HEMATOCRIT\", \"CBC_MCH\", \"CBC_MCHC\",\n",
    "                \"CBC_ABSOLUTE_LYMPHOCYTES\", \"CBC_ABSOLUTE_NEUTROPHILS\",\n",
    "                \"CBC_LYMPHOCYTE\", \"CBC_EOSINOPHILS\", \"CBC_ABSOLUTE_EOSINOPHILS\",\n",
    "                \"CBC_ABSOLUTE_BASOPHILS\", \"CBC_ABSOLUTE_MONOCYTES\"]\n",
    "    \n",
    "    BMP_cols = [\"BMP_POTASSIUM\", \"BMP_CREATININE\", \"BMP_BUN\", \"BMP_CALCIUM\", \"BMP_CHLORIDE\", \n",
    "                \"BMP_SODIUM\", \"BMP_CO2\", \"BMP_GLUCOSE\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    outcome = [outcome]\n",
    "    ## Set Lab columns\n",
    "    labCols = BMP_cols + CBC_cols\n",
    "    if pickle_folder_name == \"NoLabs\":\n",
    "        all_columns = basic_demographics + Medhx + Surghx + SpineSpecific + Medicationhx + SurgCharsNumeric + outcome\n",
    "    elif pickle_folder_name == \"Labs\":\n",
    "        all_columns = basic_demographics + BMP_cols + CBC_cols + Medhx + Surghx + SpineSpecific + Medicationhx + SurgCharsNumeric + outcome\n",
    "    elif pickle_folder_name == \"Testing\":\n",
    "        all_columns = basic_demographics + Medhx + Surghx + SpineSpecific + Medicationhx + SurgCharsNumeric + outcome\n",
    "    elif pickle_folder_name == \"TestingLabs\":\n",
    "        all_columns = basic_demographics + BMP_cols + CBC_cols + Medhx + Surghx + SpineSpecific + Medicationhx + SurgCharsNumeric + outcome\n",
    "\n",
    "    df = data[all_columns].copy()\n",
    "\n",
    "    ## Fix ASA class\n",
    "    df['asa_class'] = df['asa_class'].replace(0, np.nan)\n",
    "\n",
    "    \n",
    "    #df['asa_above_2'] = np.where(df['asa_class'] >= 3, 1, 0)\n",
    "    \n",
    "\n",
    "    #dum_cols = [\"anesthesia_type\", \"procedure_setting\"]\n",
    "\n",
    "    numeric_features = [\"age_at_procedure\", \"BMI\", \"OR_length_minutes\"]\n",
    "    \n",
    "        # Convert preop columns to boolean\n",
    "    preop_columns = [col for col in df.columns if col.startswith('preop')]\n",
    "    print(f\"{len(preop_columns)} Preop Columns\")\n",
    "\n",
    "    \n",
    "    for col in preop_columns:\n",
    "        trueBefore = sum(df[col] == True)\n",
    "        df[col] = df[col].astype('boolean')\n",
    "        # df[col] = df[col].astype('float')\n",
    "        df[col] = df[col].astype('Int64') # Just convert to Int64\n",
    "        # df[col] = df[col].fillna(0) #fill na as 0 in binary conversion\n",
    "        trueAfter = sum(df[col] == True)\n",
    "        if trueBefore != trueAfter:\n",
    "            raise ValueError(f\"\"\"\n",
    "            Column {col} has different number of True values after conversion!\n",
    "            Before: {trueBefore} True values\n",
    "            After: {trueAfter} True values\n",
    "            Difference: {trueAfter - trueBefore}\n",
    "            \"\"\")\n",
    "        else: \n",
    "            print(\"All preop conversions good!\")\n",
    "    \n",
    "\n",
    "    ## Change these float columns to ints\n",
    "\n",
    "    to_int_cols = [\"age_at_procedure\", 'OR_length_minutes']\n",
    "\n",
    "    for col in to_int_cols:\n",
    "        df[col] = df[col].astype(\"Int64\")\n",
    "\n",
    "    \n",
    "    ## ADD Lab columns to numeric_features\n",
    "    if pickle_folder_name in [\"Labs\", \"TestingLabs\"]:\n",
    "        numeric_features = numeric_features + labCols\n",
    "        print(\"adding lab columns to numeric_features\") \n",
    "        for col in labCols:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            # Ensure the column dtype is float\n",
    "            df[col] = df[col].astype('float')\n",
    "    \n",
    "    #Convert \"object\" columns to categorical (NO CATEGORICAL COLUMNS NOW)\n",
    "    '''\n",
    "    objectcols = SurgCharsCat\n",
    "    for col in objectcols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    '''\n",
    "\n",
    "    # Create ASA df\n",
    "    df_asa = df[['ir_id', 'surgery_start_datetime', 'asa_class', outcome[0]]].copy()\n",
    "    df_asa['asa_class'] = df_asa['asa_class'].astype(\"Int64\")\n",
    "\n",
    "    #remove ASA from df\n",
    "    df = df.drop('asa_class', axis=1)\n",
    "    \n",
    "        \n",
    "    return df, df_asa, numeric_features, individual_features_shap_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new dfs for predictors, preds+dummies, and ys\n",
    "\n",
    "def separate_dfs(df, outcome):\n",
    "    \"\"\"\n",
    "    Separates a dataframe into three separate dataframes: predictors, dummies, and ys.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input dataframe.\n",
    "        dum_cols (list): A list of column names that are dummy variables. NO MORE DUM COLUMNS\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing three dataframes: (df_preds, dum_df, y).\n",
    "    \"\"\"\n",
    "    #df = df.dropna().reset_index(drop=True) # drop missing variables\n",
    "    \n",
    "    y = df[outcome].values\n",
    "\n",
    "    df_preds = df.drop(columns = [outcome])\n",
    "\n",
    "    #dum_df = pd.get_dummies(df_preds, columns= dum_cols)\n",
    "\n",
    "    return df_preds, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef full_feature_outcome_test(feature, outcome):\\n   \\n   Function to do the entire test for a feature + outcome combo\\n   Inputs: feature (string), outcome (string)\\n   \\n   n = len(df)\\n   label_n = sum(y)\\n   return \\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for feature + outcome combo NOT USED YET\n",
    "'''\n",
    "def full_feature_outcome_test(feature, outcome):\n",
    "   \n",
    "   Function to do the entire test for a feature + outcome combo\n",
    "   Inputs: feature (string), outcome (string)\n",
    "   \n",
    "   n = len(df)\n",
    "   label_n = sum(y)\n",
    "   return \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to be repeated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Formulating the preprocessor for scaling and stratified folds\n",
    "\n",
    "def scaleAnd_skf(numeric_features, outcome, rep, fulldataset = False):\n",
    "     # Formulating the preprocessor for scaling\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "\n",
    "    if fulldataset:\n",
    "        preprocessor = ColumnTransformer([('robust', scaler, numeric_features)], remainder = 'passthrough', verbose_feature_names_out=False)\n",
    "    else:\n",
    "        preprocessor = ColumnTransformer([('minmax', scaler, numeric_features)], remainder = 'passthrough')\n",
    "\n",
    "    if outcome in binary_outcomes:\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5, shuffle = True, random_state = rep) #TODO: Change back to 5\n",
    "\n",
    "    elif outcome in continuous_outcomes:\n",
    "        \n",
    "        print(\"In Progress\")\n",
    "    \n",
    "    return preprocessor, skf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do within each traintest split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the dtypes for the xtrain_std and x_test_std\n",
    "\n",
    "def save_dtypes(df, original_df, preprocessor):\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "    df = pd.DataFrame(df, columns=feature_names, index=original_df.index)\n",
    "    df.columns = [col.replace('minmax__', '') for col in df.columns]\n",
    "    df.columns = [col.replace('remainder__', '') for col in df.columns]\n",
    "    for col in df.columns:\n",
    "        if col in original_df.columns:\n",
    "            #print(\"Good\")\n",
    "            #print(col)\n",
    "\n",
    "            #df[col] = df[col].astype(original_df[col].dtype)\n",
    "            df[col] = df[col].astype('float64')\n",
    "\n",
    "        else:\n",
    "            print(\"ERROR\")\n",
    "            #print(col)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Any extra missing values filled in using mode/median of same dataset\n",
    "\n",
    "def post_imputation_cleanup(data):\n",
    "    total_replaced = 0\n",
    "    for col in data.columns:\n",
    "        if data[col].isnull().any():\n",
    "            nan_count_before = data[col].isnull().sum()\n",
    "            if data[col].dtype.name == 'category':\n",
    "                # For categorical data, use mode if it exists\n",
    "                if not data[col].mode().empty:\n",
    "                    data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "            elif data[col].dtype.kind in 'biufc':  # boolean, integer, unsigned integer, float, complex\n",
    "                # For numeric data, use median if it exists and is not null\n",
    "                median = data[col].median()\n",
    "                if pd.notnull(median):\n",
    "                    data[col].fillna(median, inplace=True)\n",
    "            else:\n",
    "                # For other types (like object), use mode if it exists\n",
    "                if not data[col].mode().empty:\n",
    "                    data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "            \n",
    "            nan_count_after = data[col].isnull().sum()\n",
    "            replaced = nan_count_before - nan_count_after\n",
    "            total_replaced += replaced\n",
    "\n",
    "            print(f\"Column '{col}': {replaced} NaN values replaced\")\n",
    "\n",
    "            \n",
    "            # Check if there are still NaN values after imputation\n",
    "            if data[col].isnull().any():\n",
    "                print(f\"Warning: Column '{col}' still contains NaN values after imputation.\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeData(x_train, y_train, x_test, y_test, rep, impute_number):\n",
    "    # Combine x_train and y_train for imputation\n",
    "    x_train = x_train.reset_index(drop=True)\n",
    "    x_test = x_test.reset_index(drop=True)\n",
    "\n",
    "    train_data = x_train.copy()\n",
    "    train_data['target'] = y_train\n",
    "\n",
    "    # Create and fit the imputation kernel\n",
    "    \n",
    "    kernel = mf.ImputationKernel(\n",
    "        train_data,\n",
    "        random_state=rep,\n",
    "        variable_schema = NaNColumn_list\n",
    "    )\n",
    "    \n",
    "    # Use sklearn pipeline method (as in examples)\n",
    "    pipe = Pipeline([('impute', kernel)])\n",
    "    \n",
    "    # Perform imputation\n",
    "    #kernel.mice(impute_number, verbose=True)  # Run 5 iterations, adjust as needed\n",
    "    \n",
    "    # Get the imputed training data\n",
    "    #imputed_train = kernel.complete_data()\n",
    "\n",
    "    imputed_train = pipe.fit_transform(train_data, impute__iterations = impute_number,\n",
    "                                       impute__verbose=True)\n",
    "    \n",
    "    #imputed_train = post_imputation_cleanup(imputed_train)\n",
    "\n",
    "    assert not np.any(np.isnan(imputed_train))\n",
    "\n",
    "    # Separate features and target\n",
    "    x_train_imputed = imputed_train.drop('target', axis=1)\n",
    "    y_train_imputed = imputed_train['target']\n",
    "\n",
    "    # Combine Test data\n",
    "    test_data = x_test.copy()\n",
    "    #test_data['target'] = y_test\n",
    "    test_data['target'] = np.nan \n",
    "    test_data['target'] = test_data['target'].astype('bool')# add dummy target column\n",
    "    # Impute test data\n",
    "    test_imputed = pipe.transform(test_data)\n",
    "    #test_imputed = kernel.transform(test_data)\n",
    "    #test_imputed = post_imputation_cleanup(test_imputed)\n",
    "    x_test_imputed = test_imputed.drop('target', axis=1)\n",
    "\n",
    "    assert not np.any(np.isnan(x_test_imputed))\n",
    "\n",
    "    y_test_imputed = y_test\n",
    "\n",
    "    \n",
    "    return x_train_imputed, y_train_imputed, x_test_imputed, y_test_imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create training, test, validation sets and additional sets\n",
    "def set_train_test(input_df, y, train_index, test_index, rep, preprocessor, impute_number,\n",
    "                   want_val = False):\n",
    "    # Split into train and test\n",
    "\n",
    "    # NEED TO HAVE DUMMYS HERE AFTER IMPUTATION! do in impute_data\n",
    "\n",
    "    # dum_df cut out asa_class column\n",
    "    # x_train_asa = asa_class.iloc[train_index].copy()\n",
    "    # x_test_asa = asa_class.iloc[test_index].copy()\n",
    "    # add these two to the output of set_train_test\n",
    "        \n",
    "    x_train_split = input_df.iloc[train_index].copy()\n",
    "    x_test_split = input_df.iloc[test_index].copy()\n",
    "    y_train_split = y[train_index].copy()\n",
    "    y_test_split = y[test_index].copy()\n",
    "    \n",
    "    \n",
    "    # Peel off validation set\n",
    "\n",
    "    x_train_actual_split, x_val_split, y_train_actual_split, y_val_split = train_test_split(x_train_split,\n",
    "                                                                                            y_train_split, stratify = y_train_split,\n",
    "                                                                                            test_size = 0.1, random_state = rep) # random process\n",
    "\n",
    "\n",
    "    # Remove mrn and surgery start datetime and include that as the actual train and test\n",
    "        \n",
    "        \n",
    "    #if feature == mainfeature:\n",
    "        \n",
    "    print(\"Test\")\n",
    "\n",
    "    if want_val:\n",
    "\n",
    "        x_train_actual = x_train_actual_split.drop(columns = [\"ir_id\", \"surgery_start_datetime\"])\n",
    "        x_val = x_val_split.drop(columns = [\"ir_id\", \"surgery_start_datetime\"])\n",
    "        y_train_actual = y_train_actual_split.copy()\n",
    "        y_val = y_val_split.copy()\n",
    "\n",
    "        # IMPUTED VALUES\n",
    "        x_train_actual, y_train_actual, x_val, y_val = imputeData(x_train_actual, y_train_actual, x_val, y_val, rep, impute_number)\n",
    "    else:\n",
    "        x_train_actual = None\n",
    "        x_val = None\n",
    "        y_train_actual = None\n",
    "        y_val = None\n",
    "\n",
    "\n",
    "\n",
    "    x_train = x_train_split.drop(columns = [\"ir_id\", \"surgery_start_datetime\"])\n",
    "    x_test = x_test_split.drop(columns = [\"ir_id\", \"surgery_start_datetime\"])\n",
    "    x_test_id_cols = x_test_split[[\"ir_id\", \"surgery_start_datetime\"]]\n",
    "    x_test_id_cols = x_test_id_cols.reset_index(drop=True)\n",
    "    y_train = y_train_split.copy()\n",
    "    y_test = y_test_split.copy()\n",
    "\n",
    "    #IMPUTED VALUES\n",
    "    x_train, y_train, x_test, y_test = imputeData(x_train, y_train, x_test, y_test, rep, impute_number)\n",
    "    \n",
    "    \n",
    "    x_train_std = preprocessor.fit_transform(x_train)\n",
    "    x_train_std = save_dtypes(x_train_std, x_train, preprocessor)\n",
    "    x_test_std = preprocessor.transform(x_test)\n",
    "    x_test_std = save_dtypes(x_test_std, x_test, preprocessor)\n",
    "\n",
    "\n",
    "\n",
    "    # Keep a version that has those values as index columns \n",
    "\n",
    "    x_test_features = x_test.copy() #use imputed data\n",
    "    # Add back the identifier columns\n",
    "    x_test_features = pd.concat([x_test_id_cols, x_test_features], axis=1)\n",
    "\n",
    "    x_test_features[\"Patient_ID\"]=  np.arange(len(x_test_features))\n",
    "\n",
    "    x_test_features_long = pd.melt(x_test_features, id_vars = [\"ir_id\", \"Patient_ID\", \"surgery_start_datetime\"], var_name = \"Feature_Name\", value_name = \"Feature_Actual_Value\" )\n",
    "    \n",
    "    x_test_features_long['Feature_Actual_Value'] = pd.to_numeric(x_test_features_long['Feature_Actual_Value'])\n",
    "\n",
    "    x_cols = x_test.columns\n",
    "\n",
    "    n_features = len(x_cols)\n",
    "    \n",
    "    return x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, x_test_features_long, n_features, x_cols, x_train_std, x_test_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ASA model - only works for binary outcomes\n",
    "\n",
    "def ASA_model(x_train, x_test, y_train, rep):\n",
    "\n",
    "    '''\n",
    "    Input: x_train: training data from train-test set\n",
    "           x_test: test data from train-test set\n",
    "           y_train: training labels from train-test set\n",
    "           rep: random state for reproducibility\n",
    "\n",
    "    Output: cv_model: trained logistic regression model\n",
    "            y_pred: predicted labels for test set\n",
    "            y_prob_vec: predicted probabilities for test set\n",
    "    '''\n",
    "\n",
    "    # Extract ASA class feature\n",
    "    trim_train = x_train[[\"asa_class\"]].copy()\n",
    "    trim_test = x_test[[\"asa_class\"]].copy()\n",
    "\n",
    "    # Fit logistic regression model\n",
    "    cv_model = linear_model.LogisticRegression(penalty=None, random_state=rep)\n",
    "    cv_model.fit(trim_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = cv_model.predict(trim_test)\n",
    "    y_prob = cv_model.predict_proba(trim_test)\n",
    "    y_prob_vec = y_prob[:, 1]\n",
    "\n",
    "    return cv_model, y_pred, y_prob_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ASA Categorical model -> <=2 and >2\n",
    "def ASA_categorical_model(x_test):\n",
    "    \n",
    "    x_test['asa_above_2'] = np.where(x_test['asa_class'] >= 3, 1, 0)\n",
    "\n",
    "    trim_test_categorical = x_test[\"asa_above_2\"]\n",
    "\n",
    "\n",
    "    y_pred = trim_test_categorical.values.reshape(-1,1)\n",
    "    y_prob = trim_test_categorical.values.reshape(-1,1)\n",
    "    y_prob_vec = trim_test_categorical.values.reshape(-1,1)\n",
    "    #print(y_prob_vec)\n",
    "    return y_pred, y_prob_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ENet_model(outcome, preprocessor, x_train, y_train, x_test, x_train_std, x_test_std, rep):\n",
    "    '''\n",
    "    Inputs: outcome (str): column_name of outcome variable\n",
    "            preprocessor (obj): standardizing preprocessing object\n",
    "            x_train (df): training data from train-test set\n",
    "            y_train (df): training outcome variable from train-test set\n",
    "            x_test (df): test data from train-test set\n",
    "            x_train_std (df): standardized training data\n",
    "            x_test_std (df): standardized test data\n",
    "\n",
    "    Outputs: cv_model (obj): best model from bayesian optimization\n",
    "             y_pred (arr): predicted values for test set\n",
    "             y_prob_vec (arr): predicted probability values for test set\n",
    "             shap_values (arr): shap values for test set\n",
    "    '''\n",
    "    if outcome in binary_outcomes:\n",
    "        '''\n",
    "        y_train_df = pd.DataFrame(y_train, columns = [\"y_train\"])\n",
    "        All_train = pd.concat([x_train, y_train_df], axis = 1)\n",
    "\n",
    "        kernel = mf.ImputationKernel(\n",
    "            All_train,\n",
    "            random_state=rep,\n",
    "            variable_schema = NaNColumn_list\n",
    "        )\n",
    "        '''\n",
    "        pipe = Pipeline([   #('impute', kernel),\n",
    "                            ('processing', preprocessor), \n",
    "                            ('estimator', linear_model.LogisticRegression(penalty = 'elasticnet', \n",
    "                                                                        solver='saga', \n",
    "                                                                        class_weight = 'balanced',\n",
    "                                                                        random_state = rep, \n",
    "                                                                        max_iter = 1000\n",
    "                                                                        ))])\n",
    "\n",
    "        fit_params = {'impute__iterations': impute_iterations,\n",
    "                      'impute__verbose': True}\n",
    "        model_params = {'estimator__C': Real(1e-2, 1e2, prior = 'log-uniform'),\n",
    "                        'estimator__l1_ratio': Real(0, 1)\n",
    "                        }\n",
    "        hyperopt_model_params = {\n",
    "            'estimator__C': hp.loguniform('estimator__C', np.log(1e-2), np.log(1e2)),\n",
    "            'estimator__l1_ratio': hp.uniform('estimator__l1_ratio', 0, 1)\n",
    "                                 }\n",
    "\n",
    "        cv_model = TuneSearchCV(pipe, \n",
    "                                param_distributions = hyperopt_model_params, \n",
    "                                search_optimization=\"hyperopt\",\n",
    "                                verbose = 2,\n",
    "                                scoring='roc_auc', # auc is most important metric\n",
    "                                refit=True,\n",
    "                                cv=5,\n",
    "                                n_jobs = 7,\n",
    "                                n_trials = tunesearch_iterations, \n",
    "                                random_state = rep\n",
    "                                )\n",
    "\n",
    "        cv_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "        y_pred = cv_model.predict(x_test)\n",
    "        y_prob = cv_model.predict_proba(x_test)\n",
    "        y_prob_vec = y_prob[:,1]\n",
    "\n",
    "\n",
    "    elif outcome in continuous_outcomes:\n",
    "\n",
    "        print(\"In Progress\")\n",
    "\n",
    "\n",
    "    if Get_shaps:\n",
    "        explainer = shap.LinearExplainer(cv_model.best_estimator_.named_steps['estimator'], x_train_std)\n",
    "        shap_values = explainer.shap_values(x_test_std)\n",
    "        print(\"SHAPS DONE\")\n",
    "    else:\n",
    "        shap_values = None\n",
    "        print(\"NO SHAPS FOOR YOU\")\n",
    "\n",
    "    return cv_model, y_pred, y_prob_vec, shap_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost_model(outcome, preprocessor, x_train, y_train, x_test, x_train_std, x_test_std, rep):\n",
    "    '''\n",
    "    Inputs: outcome (str): name of the outcome variable\n",
    "            preprocessor (sklearn.preprocessing): standardizing preprocessor object\n",
    "            x_train (pd.DataFrame): training data from train-test set\n",
    "            y_train (pd.Series): training outcome variable from train-test set\n",
    "            x_test (pd.DataFrame): test data\n",
    "            rep (int): random state for reproducibility\n",
    "\n",
    "    Outputs: y_pred : predicted class for test data\n",
    "             y_prob_vec : predicted probability for test data\n",
    "             cv_model : trained model object\n",
    "             shap_values: SHAP values for the model\n",
    "    '''\n",
    "\n",
    "    if outcome in binary_outcomes:\n",
    "\n",
    "        weight_vec = wt.compute_sample_weight(class_weight = \"balanced\", y = y_train) # compute weights using sklearn\n",
    "#        eval_weight = wt.compute_sample_weight(class_weight = \"balanced\", y = y_val)\n",
    "\n",
    "        pipe = Pipeline([('processing', preprocessor), \n",
    "                            ('estimator', xgb.XGBClassifier(#n_estimators = 500,\n",
    "                                                            #eval_metric = \"auc\",\n",
    "                                                            use_label_encoder=False,\n",
    "                                                            verbosity = 1, random_state = rep\n",
    "                                                        ))]) \n",
    "\n",
    "\n",
    "        es = xgb.callback.EarlyStopping(\n",
    "            rounds = 10,\n",
    "            save_best=True,\n",
    "        )\n",
    "        print(f\"XShape: {x_train.shape}\")\n",
    "\n",
    "        model_params = {\n",
    "            'estimator__n_estimators': hp.uniformint('estimator__n_estimators', 50, 250),\n",
    "            'estimator__max_depth': hp.uniformint('estimator__max_depth', 2, 10),\n",
    "            'estimator__subsample': hp.uniform('estimator__subsample', 0.5, 1.0),\n",
    "            'estimator__learning_rate': hp.uniform('estimator__learning_rate', 0.1, 0.5),\n",
    "            'estimator__colsample_bytree': hp.uniform('estimator__colsample_bytree', 0.5, 1.0),\n",
    "            'estimator__colsample_bylevel': hp.uniform('estimator__colsample_bylevel', 0.5, 1.0),\n",
    "            'estimator__min_child_weight': hp.uniformint('estimator__min_child_weight', 1, 10),\n",
    "            'estimator__gamma': hp.uniform('estimator__gamma', 0, 1.0),\n",
    "            'estimator__reg_lambda': hp.loguniform('estimator__reg_lambda', np.log(1e-2), np.log(1e2)),\n",
    "            'estimator__reg_alpha': hp.loguniform('estimator__reg_alpha', np.log(1e-2), np.log(1e2)),\n",
    "        }\n",
    "\n",
    "        fit_params = {#'estimator__sample_weight_eval_set': [eval_weight],\n",
    "#                                          'estimator__eval_set': [(x_val_std, y_val)],\n",
    "#                                          'estimator__callbacks': [es],\n",
    "                        'estimator__sample_weight': weight_vec,\n",
    "#                                          'estimator__early_stopping_rounds': 10\n",
    "\n",
    "        }\n",
    "\n",
    "        cv_model = TuneSearchCV(pipe, \n",
    "                                param_distributions = model_params, n_trials = tunesearch_iterations,\n",
    "                                scoring='roc_auc', \n",
    "                                refit=True, cv= 5, \n",
    "                                n_jobs = 7, random_state = rep, \n",
    "                                search_optimization = \"hyperopt\",\n",
    "                                verbose = 2)\n",
    "\n",
    "        cv_model.fit(x_train, y_train, **fit_params)\n",
    "\n",
    "\n",
    "\n",
    "        y_pred = cv_model.predict(x_test)\n",
    "        y_prob = cv_model.predict_proba(x_test) # generate prediction probability ([0,1])\n",
    "        y_prob_vec = y_prob[:,1]\n",
    "\n",
    "    elif outcome in continuous_outcomes:\n",
    "\n",
    "        print(\"In Progress\")\n",
    "\n",
    "\n",
    "\n",
    "    if Get_shaps:\n",
    "        explainer = shap.TreeExplainer(cv_model.best_estimator_.named_steps['estimator'], data=x_train_std, model_output = \"probability\")\n",
    "        shap_values = explainer.shap_values(x_test_std)\n",
    "        print(shap_values.shape)\n",
    "        test = shap_values[0] # TODO: Check if 0 is correct here if needed\n",
    "        print(test.shape)\n",
    "        print(\"SHAPS DONE\")\n",
    "    else:\n",
    "        shap_values = None\n",
    "        print(\"NO SHAPS FOR YOU\")\n",
    "\n",
    "    return cv_model, y_pred, y_prob_vec, shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_model(outcome, preprocessor, x_train, y_train, x_test, x_train_std, x_test_std, rep, n_features_in, Interventional):\n",
    "    '''\n",
    "    Inputs: outcome (str): name of the outcome variable\n",
    "            preprocessor (sklearn.preprocessing): standardizing preprocessor object\n",
    "            x_train (pd.DataFrame): training data from train-test set\n",
    "            y_train (pd.Series): training outcome variable from train-test set\n",
    "            x_test (pd.DataFrame): test data\n",
    "            rep (int): random state for reproducibility\n",
    "\n",
    "    Outputs: y_pred : predicted class for test data\n",
    "             y_prob_vec : predicted probability for test data\n",
    "             cv_model : trained model object\n",
    "             shap_values: SHAP values for the model\n",
    "    '''\n",
    "\n",
    "    if outcome in binary_outcomes:\n",
    "\n",
    "        pipe = Pipeline([('processing', preprocessor), \n",
    "                            ('estimator', BalancedRandomForestClassifier(random_state = rep,\n",
    "                                                                         sampling_strategy='all',\n",
    "                                                                         replacement=True,\n",
    "                                                                         bootstrap=False\n",
    "                                                                         ))]) \n",
    "\n",
    "        model_params = {\n",
    "            'estimator__n_estimators': hp.uniformint('estimator__n_estimators', 50, 250),\n",
    "            'estimator__max_features': hp.uniformint('estimator__max_features', 2, n_features_in),\n",
    "            'estimator__max_depth': hp.uniformint('estimator__max_depth', 1, 25),\n",
    "            'estimator__min_samples_split': hp.uniformint('estimator__min_samples_split', 2, 10),\n",
    "            'estimator__min_samples_leaf': hp.uniformint('estimator__min_samples_leaf', 1, 5),\n",
    "        }\n",
    "\n",
    "        cv_model = TuneSearchCV(pipe,\n",
    "                                param_distributions = model_params, n_trials = tunesearch_iterations,\n",
    "                                scoring='roc_auc', # AUC is most important metric\n",
    "                                refit=True, cv=5, n_jobs = 7,\n",
    "                                random_state = rep,\n",
    "                                search_optimization = \"hyperopt\",\n",
    "                                verbose = 2)\n",
    "\n",
    "        cv_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "        y_pred = cv_model.predict(x_test) # generate prediction (0 or 1)\n",
    "        y_prob = cv_model.predict_proba(x_test) # generate prediction probability ([0,1])\n",
    "        y_prob_vec = y_prob[:,1]\n",
    "\n",
    "    elif outcome in continuous_outcomes:\n",
    "\n",
    "        print(\"In Progress\")\n",
    "\n",
    "    if Get_shaps:\n",
    "        if Interventional:\n",
    "            print(\"DOING INTERVENTIONAL\")\n",
    "            explainer = shap.TreeExplainer(cv_model.best_estimator_.named_steps['estimator'], data=x_train_std, feature_perturbation= \"interventional\",\n",
    "                                       model_output = \"probability\")\n",
    "        else:\n",
    "            print(\"DOING PATH DEPENDENT\")\n",
    "            explainer = shap.TreeExplainer(cv_model.best_estimator_.named_steps['estimator'], feature_perturbation= \"tree_path_dependent\")\n",
    "        shap_values = explainer.shap_values(x_test_std)\n",
    "        print(shap_values.shape)\n",
    "        shap_values = shap_values[:, :, 1]\n",
    "        print(shap_values.shape)\n",
    "        print(\"GET SHAPS\")\n",
    "    else:\n",
    "        shap_values = None\n",
    "        print(\"NO SHAPS FOR YOU\")\n",
    "\n",
    "    return cv_model, y_pred, y_prob_vec, shap_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dummy_model(outcome, x_train, y_train, x_test):\n",
    "    '''\n",
    "    Inputs: outcome (str): name of the outcome variable\n",
    "            preprocessor (sklearn.preprocessing): standardizing preprocessor object\n",
    "            x_train (pd.DataFrame): training data from train-test set\n",
    "            y_train (pd.Series): training outcome variable from train-test set\n",
    "            x_test (pd.DataFrame): test data\n",
    "            rep (int): random state for reproducibility\n",
    "\n",
    "    Outputs: y_pred : predicted class for test data\n",
    "             y_prob_vec : predicted probability for test data\n",
    "             cv_model : trained model object\n",
    "             shap_values: SHAP values for the model\n",
    "    '''\n",
    "    if outcome in binary_outcomes:\n",
    "\n",
    "        dummy_clf = DummyClassifier(strategy=\"prior\")\n",
    "        dummy_clf.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = dummy_clf.predict(x_test)\n",
    "        y_prob = dummy_clf.predict_proba(x_test)\n",
    "        y_prob_vec = y_prob[:,1]\n",
    "\n",
    "    elif outcome in continuous_outcomes:\n",
    "\n",
    "        dummy_clf = DummyRegressor(strategy=\"median\")\n",
    "        dummy_clf.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = np.round(dummy_clf.predict(x_test))\n",
    "\n",
    "    return dummy_clf, y_pred, y_prob_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model(outcome, preprocessor, x_train_actual, y_train_actual, x_val, y_val, x_test, n_features, rep):\n",
    "    '''\n",
    "    Inputs: outcome (str): name of the outcome variable\n",
    "            preprocessor (sklearn.preprocessing): standardizing preprocessor object\n",
    "            x_train (pd.DataFrame): training data from train-test set\n",
    "            y_train (pd.Series): training outcome variable from train-test set\n",
    "            x_test (pd.DataFrame): test data\n",
    "            rep (int): random state for reproducibility\n",
    "\n",
    "    Outputs: y_pred : predicted class for test data\n",
    "             y_prob_vec : predicted probability for test data\n",
    "             cv_model : trained model object\n",
    "             shap_values: SHAP values for the model\n",
    "    '''\n",
    "\n",
    "    #tf.config.run_functions_eagerly(True)\n",
    "\n",
    "    if outcome in binary_outcomes:\n",
    "\n",
    "        x_train_actual_std = preprocessor.fit_transform(x_train_actual)\n",
    "        x_train_actual_std = save_dtypes(x_train_actual_std, x_train_actual, preprocessor)\n",
    "        x_val_std = preprocessor.transform(x_val)\n",
    "        x_val_std = save_dtypes(x_val_std, x_val, preprocessor)\n",
    "\n",
    "#       x_train_std = preprocessor.fit_transform(x_train)\n",
    "        x_test_std = preprocessor.transform(x_test)\n",
    "        x_test_std = save_dtypes(x_test_std, x_test, preprocessor)\n",
    "\n",
    "        reset_random_seed(rep)\n",
    "\n",
    "\n",
    "        metric_set=[tf.keras.metrics.AUC(name=\"auc\")]\n",
    "\n",
    "\n",
    "\n",
    "        weight_vec = wt.compute_sample_weight(class_weight = \"balanced\", y = y_train_actual) # compute weights using sklearn\n",
    "        eval_weight = wt.compute_sample_weight(class_weight = \"balanced\", y = y_val)\n",
    "\n",
    "\n",
    "        # Convert data to TensorFlow datasets\n",
    "        #train_dataset = tf.data.Dataset.from_tensor_slices((x_train_actual_std, y_train_actual, weight_vec))\n",
    "        #train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32)\n",
    "\n",
    "        #val_dataset = tf.data.Dataset.from_tensor_slices((x_val_std, y_val, eval_weight))\n",
    "        #val_dataset = val_dataset.batch(32)\n",
    "\n",
    "\n",
    "        nn_model = tf.keras.Sequential(name=\"DeepNN_CLF\", layers=[\n",
    "\n",
    "            # Input layer is implicitly defined here\n",
    "\n",
    "            ### hidden layer 1\n",
    "            tf.keras.layers.Dense(name=\"h1\", input_dim=n_features,\n",
    "                            units=int(round((n_features+1)/2)), \n",
    "                            activation='relu'),\n",
    "\n",
    "            ### dropout layer 1\n",
    "            tf.keras.layers.Dropout(name=\"drop1\", rate=0.2, seed = rep),\n",
    "\n",
    "            ### hidden layer 2\n",
    "            tf.keras.layers.Dense(name=\"h2\", units=int(round((n_features+1)/4)), \n",
    "                            activation='relu'),\n",
    "\n",
    "            ### dropout layer 2\n",
    "            tf.keras.layers.Dropout(name=\"drop2\", rate=0.2, seed = rep),\n",
    "\n",
    "            ### layer output\n",
    "            tf.keras.layers.Dense(name=\"output\", units=1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        nn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics = metric_set)\n",
    "\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_auc', \n",
    "            verbose=1,\n",
    "            patience=10,\n",
    "            mode='max',\n",
    "            restore_best_weights=True)\n",
    "\n",
    "        history = nn_model.fit(\n",
    "            x_train_actual_std,\n",
    "            y_train_actual,\n",
    "            epochs= 100, #TODO: Change back to 100\n",
    "            sample_weight=weight_vec,\n",
    "            batch_size=32, #added\n",
    "            callbacks=[early_stopping],\n",
    "            validation_data=(x_val_std, y_val, eval_weight),\n",
    "        )\n",
    "\n",
    "        y_prob = nn_model.predict(x_test_std) \n",
    "        y_pred = (y_prob > 0.5).astype(\"int32\")                 \n",
    "        y_prob_vec = y_prob.flatten()\n",
    "\n",
    "        nn_model.summary()\n",
    "\n",
    "        # Plot training history\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['auc'], label='Training AUC')\n",
    "        plt.plot(history.history['val_auc'], label='Validation AUC')\n",
    "        plt.title('Model AUC')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('AUC')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    elif outcome in continuous_outcomes:\n",
    "\n",
    "        print(\"In Progress\")\n",
    "\n",
    "\n",
    "    # SHAP values calculation\n",
    "    '''\n",
    "    tf.config.run_functions_eagerly(False)\n",
    "    print(tf.executing_eagerly())\n",
    "    background = shap.sample(x_train_actual_std, 100)  # Use a subset of training data as background\n",
    "    explainer = shap.DeepExplainer(nn_model, background)\n",
    "    shap_values = explainer.shap_values(x_test_std.values)\n",
    "    shap_values = shap_values[:, :, 0]\n",
    "    print(shap_values.shape)\n",
    "    tf.config.run_functions_eagerly(True)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    #explainer = shap.DeepExplainer(nn_model, data=x_train_actual_std)\n",
    "    #print(type(x_test_std))\n",
    "    #shap_values = explainer.shap_values(x_test_std)\n",
    "    #print(shap_values.shape)\n",
    "\n",
    "    return nn_model, y_pred, y_prob_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Linear_SVC_model(outcome, preprocessor, x_train, y_train, x_test, x_train_std, x_test_std, rep):\n",
    "    '''\n",
    "    Inputs: outcome (str): name of the outcome variable\n",
    "            preprocessor (sklearn.preprocessing): standardizing preprocessor object\n",
    "            x_train (pd.DataFrame): training data from train-test set\n",
    "            y_train (pd.Series): training outcome variable from train-test set\n",
    "            x_test (pd.DataFrame): test data\n",
    "            x_train_std (pd.DataFrame): standardized training data\n",
    "            x_test_std (pd.DataFrame): standardized test data\n",
    "            rep (int): random state for reproducibility\n",
    "\n",
    "    Outputs: y_pred : predicted class for test data\n",
    "             y_prob_vec : predicted probability for test data\n",
    "             cv_model : trained model object\n",
    "             shap_values: SHAP values for the model\n",
    "    '''\n",
    "\n",
    "    if outcome in binary_outcomes:\n",
    "\n",
    "\n",
    "        pipe = Pipeline([('processing', preprocessor),\n",
    "                         ('estimator', sklearn.svm.LinearSVC(random_state=rep,\n",
    "                                                             dual=False,\n",
    "                                                             max_iter=1000,\n",
    "                                                             class_weight='balanced' ))])\n",
    "\n",
    "        model_params = {\n",
    "            'estimator__C': hp.loguniform('estimator__C', np.log(1e-2), np.log(1e2)),\n",
    "        }\n",
    "\n",
    "        cv_model = TuneSearchCV(pipe, \n",
    "                                param_distributions = model_params, \n",
    "                                scoring='roc_auc', # auc is most important metric\n",
    "                                refit=True, \n",
    "                                cv=5, n_jobs = 7,\n",
    "                                n_trials = tunesearch_iterations, \n",
    "                                random_state = rep,\n",
    "                                search_optimization = \"hyperopt\",\n",
    "                                verbose = 2\n",
    "                                )        \n",
    "        \n",
    "        cv_model.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = cv_model.predict(x_test)\n",
    "        y_prob = cv_model.decision_function(x_test)\n",
    "        y_prob_vec = 1 / (1 + np.exp(-y_prob))\n",
    "\n",
    "    elif outcome in continuous_outcomes:\n",
    "        print(\"In Progress\")\n",
    "\n",
    "    if Get_shaps:\n",
    "        print(\"GET SHAPS\")\n",
    "        explainer = shap.LinearExplainer(cv_model.best_estimator_.named_steps['estimator'], x_train_std)\n",
    "        shap_values = explainer.shap_values(x_test_std)\n",
    "    else:\n",
    "        shap_values = None\n",
    "        print(\"NO SHAPS FOR YOU\")\n",
    "\n",
    "    return cv_model, y_pred, y_prob_vec, shap_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "\n",
    "def SVC_model_with_kernels(outcome, preprocessor, x_train, y_train, x_test, x_train_std, x_test_std, rep):\n",
    "    '''\n",
    "    Inputs: outcome (str): name of the outcome variable\n",
    "            preprocessor (sklearn.preprocessing): standardizing preprocessor object\n",
    "            x_train (pd.DataFrame): training data from train-test set\n",
    "            y_train (pd.Series): training outcome variable from train-test set\n",
    "            x_test (pd.DataFrame): test data\n",
    "            x_train_std (pd.DataFrame): standardized training data\n",
    "            x_test_std (pd.DataFrame): standardized test data\n",
    "            rep (int): random state for reproducibility\n",
    "\n",
    "    Outputs: y_pred : predicted class for test data\n",
    "             y_prob_vec : predicted probability for test data\n",
    "             cv_model : trained model object\n",
    "             shap_values: SHAP values for the model\n",
    "    '''\n",
    "\n",
    "    if outcome in binary_outcomes:\n",
    "        pipe = Pipeline([\n",
    "            ('processing', preprocessor),\n",
    "            ('nystroem', Nystroem(random_state=rep)),\n",
    "            ('estimator', LinearSVC(random_state=rep, dual=False, max_iter=1000, class_weight='balanced'))\n",
    "        ])\n",
    "\n",
    "        model_params = {\n",
    "            'nystroem__kernel': hp.choice('nystroem__kernel', ['rbf', 'poly', 'sigmoid']),\n",
    "            'nystroem__n_components': hp.uniformint('nystroem__n_components', 50, 200),\n",
    "            'nystroem__gamma': hp.loguniform('nystroem__gamma', np.log(1e-3), np.log(1e1)),\n",
    "            'nystroem__degree': hp.uniformint('nystroem__degree', 2, 6),  # Integer values from 2 to 5\n",
    "            'nystroem__coef0': hp.uniform('nystroem__coef0', 0, 1),  # Uniform distribution between 0 and 1\n",
    "            'estimator__C': hp.loguniform('estimator__C', np.log(1e-2), np.log(1e2)),\n",
    "        }\n",
    "        '''\n",
    "        # Define separate search spaces for each kernel\n",
    "        linear_params = {}  # No additional parameters for linear kernel\n",
    "        rbf_params = {\n",
    "            'nystroem__gamma': Real(1e-3, 1e1, prior='log-uniform'),\n",
    "        }\n",
    "        poly_params = {\n",
    "            'nystroem__degree': Integer(2, 5),\n",
    "            'nystroem__gamma': Real(1e-3, 1e1, prior='log-uniform'),\n",
    "            'nystroem__coef0': Real(0, 1),\n",
    "        }\n",
    "        sigmoid_params = {\n",
    "            'nystroem__gamma': Real(1e-3, 1e1, prior='log-uniform'),\n",
    "            'nystroem__coef0': Real(0, 1),\n",
    "        }\n",
    "\n",
    "        # Combine the search spaces based on the kernel\n",
    "        search_spaces = model_params.copy()\n",
    "        search_spaces.update(linear_params if 'linear' in search_spaces['nystroem__kernel'] else {})\n",
    "        search_spaces.update(rbf_params if 'rbf' in search_spaces['nystroem__kernel'] else {})\n",
    "        search_spaces.update(poly_params if 'poly' in search_spaces['nystroem__kernel'] else {})\n",
    "        search_spaces.update(sigmoid_params if 'sigmoid' in search_spaces['nystroem__kernel'] else {})\n",
    "        '''\n",
    "        \n",
    "        cv_model = TuneSearchCV(\n",
    "            pipe, \n",
    "            param_distributions=model_params, \n",
    "            scoring='roc_auc',\n",
    "            refit=True, \n",
    "            cv=5,\n",
    "            n_jobs=7,\n",
    "            n_trials=tunesearch_iterations,  # Increased due to larger search space\n",
    "            random_state=rep,\n",
    "            search_optimization = \"hyperopt\",\n",
    "            verbose = 2\n",
    "        )        \n",
    "        \n",
    "        cv_model.fit(x_train, y_train)\n",
    "        best_params = cv_model.best_params_\n",
    "        best_kernel = best_params['nystroem__kernel']\n",
    "        #best_gamma = best_params['nystroem__gamma']\n",
    "        print(f\"Best kernel: {best_kernel}\")\n",
    "        #print(f\"Best gamma: {best_gamma}\")\n",
    "\n",
    "        y_pred = cv_model.predict(x_test)\n",
    "        y_prob = cv_model.decision_function(x_test)\n",
    "        y_prob_vec = 1 / (1 + np.exp(-y_prob))\n",
    "\n",
    "    elif outcome in continuous_outcomes:\n",
    "        print(\"In Progress\")\n",
    "        return\n",
    "\n",
    "    # Transform the data using the fitted Nystroem approximation\n",
    "    nystroem = cv_model.best_estimator_.named_steps['nystroem']\n",
    "    x_train_nystroem = nystroem.transform(x_train_std)\n",
    "    x_test_nystroem = nystroem.transform(x_test_std)\n",
    "    print(type(nystroem.components_))\n",
    "    print(nystroem.components_.shape)\n",
    "\n",
    "    if Get_shaps:\n",
    "        print(\"GET SHAPS\")\n",
    "        #For SHAP values, we'll use KernelExplainer as LinearExplainer won't work with the kernel approximation\n",
    "        explainer = shap.LinearExplainer(cv_model.best_estimator_.named_steps['estimator'], x_train_nystroem)\n",
    "        shap_values = explainer.shap_values(x_test_nystroem)\n",
    "        print(shap_values.shape)\n",
    "    else:\n",
    "        print(\"NO SHAPS FOR YOU\")\n",
    "        shap_values = None\n",
    "\n",
    "    return cv_model, y_pred, y_prob_vec, shap_values, best_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46.0\n"
     ]
    }
   ],
   "source": [
    "print(shap.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "def log_execution(csv_path, name_of_model, start_time):\n",
    "    end_time = time.time()\n",
    "    total_seconds = end_time - start_time\n",
    "    \n",
    "    # Calculate minutes and seconds\n",
    "    minutes = math.floor(total_seconds / 60)  # Get complete minutes\n",
    "    seconds = round(total_seconds % 60)  # Get remaining seconds, rounded\n",
    "    \n",
    "    # Create new row\n",
    "    new_row = {\n",
    "        'model_name': name_of_model,\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'execution_time_minutes': minutes,\n",
    "        'execution_time_seconds': seconds\n",
    "    }\n",
    "    \n",
    "    # Read existing CSV, append new row, and save\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    except FileNotFoundError:\n",
    "        # If file doesn't exist, create new DataFrame\n",
    "        df = pd.DataFrame([new_row])\n",
    "    \n",
    "    df.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_results(results_list, auc_plot_list, outcome, procedure, feature, model_name, rep, i, n, label_n, y_test, y_prob_vec, y_pred):\n",
    "    \"\"\"\n",
    "    Collects and computes performance metrics for binary classification models.\n",
    "\n",
    "    This function calculates various performance metrics for binary classification models and stores them in a results dataframe.\n",
    "    It also generates ROC curve data for plotting.\n",
    "\n",
    "    Parameters:\n",
    "        results_list (list): List to store performance metric results\n",
    "        auc_plot_list (list): List to store ROC curve plotting data\n",
    "        outcome (str): Name of the outcome being predicted\n",
    "        procedure (str): Name of the procedure being analyzed\n",
    "        feature (str): Name/description of features used\n",
    "        model_name (str): Name of the model used\n",
    "        rep (int): Repetition number\n",
    "        i (int): Fold number for cross-validation\n",
    "        n (int): Total number of samples\n",
    "        label_n (int): Number of labeled samples\n",
    "        y_test (array-like): True labels\n",
    "        y_prob_vec (array-like): Predicted probabilities\n",
    "        y_pred (array-like): Predicted labels\n",
    "\n",
    "    Returns:\n",
    "        None - Updates results_list and auc_plot_list in place\n",
    "\n",
    "    Metrics calculated:\n",
    "    - AUC (Area Under ROC Curve)\n",
    "    - Sensitivity/Recall\n",
    "    - Specificity\n",
    "    - PPV (Positive Predictive Value)\n",
    "    - NPV (Negative Predictive Value) \n",
    "    - Log Loss\n",
    "    - Brier Score\n",
    "    - Weighted F1 Score\n",
    "    - Accuracy\n",
    "    - Balanced Accuracy\n",
    "    - Confusion Matrix\n",
    "\n",
    "    The function only processes binary classification outcomes (checks if outcome is in binary_outcomes).\n",
    "    Results are stored in a pandas DataFrame and appended to the input lists.\n",
    "    \"\"\"\n",
    "\n",
    "    if outcome in binary_outcomes:\n",
    "        # Computing AUC\n",
    "        fpr, tpr, threshold = metrics.roc_curve(y_test, y_prob_vec, pos_label = 1)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        AUC = metrics.auc(fpr, tpr)\n",
    "\n",
    "        print(f\"AUC: {AUC}\")\n",
    "        logging.info(f\"AUC, Logging: {AUC}\")\n",
    "        # Sensitivity, Specificity\n",
    "\n",
    "        recall_score_0 = metrics.recall_score(y_test,y_pred, pos_label=0)\n",
    "        recall_score_1 = metrics.recall_score(y_test,y_pred, pos_label=1)\n",
    "\n",
    "        # PPV, NPV\n",
    "        precision_score_0 = metrics.precision_score(y_test,y_pred, pos_label=0)\n",
    "        precision_score_1 = metrics.precision_score(y_test,y_pred, pos_label=1)\n",
    "\n",
    "        # Computing Log Loss\n",
    "        log_loss = metrics.log_loss(y_test, y_prob_vec, labels = [0,1])\n",
    "\n",
    "        # Computing Brier score\n",
    "        brier_loss = metrics.brier_score_loss(y_test, y_prob_vec, pos_label = 1)\n",
    "\n",
    "        # Computing WF1\n",
    "        W_F1= metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        # Computing Accuracy\n",
    "        accuracy_score = metrics.accuracy_score(y_test,y_pred)\n",
    "        B_accuracy_score = metrics.balanced_accuracy_score(y_test,y_pred)\n",
    "\n",
    "\n",
    "        # Confusion Matrix\n",
    "        c_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        new_results = pd.DataFrame(\n",
    "            {\n",
    "                \"Procedure\": [procedure],\n",
    "                \"Outcome\": [outcome],\n",
    "                \"Features\": [feature],\n",
    "                \"Model\": [model_name],\n",
    "                \"Rep\": [rep],\n",
    "                \"Fold\": [i],\n",
    "                \"W_F1\": [W_F1],\n",
    "                \"AUC\": [AUC],\n",
    "                \"MAE\": [\"NA\"],\n",
    "                \"R2\": [\"NA\"],\n",
    "                \"RMSE\": [\"NA\"],\n",
    "                \"Log-Loss\": [log_loss],\n",
    "                \"Brier-Loss\": [brier_loss],\n",
    "                \"Accuracy\": [accuracy_score],\n",
    "                \"Balanced_Accuracy\": [B_accuracy_score],\n",
    "                \"Sensitivity\": [recall_score_1],\n",
    "                \"Specificity\": [recall_score_0],\n",
    "                \"NPV\": [precision_score_0],\n",
    "                \"PPV\": [precision_score_1],\n",
    "                \"c_matrix\": [c_mat],\n",
    "                \"n\":[n],\n",
    "                \"label_n\": [label_n]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        auc_plot_results_new = pd.DataFrame(\n",
    "            {\n",
    "                \"Procedure\": np.repeat(procedure, len(fpr)),\n",
    "                \"Outcome\": np.repeat(outcome, len(fpr)),\n",
    "                \"Features\": np.repeat(feature, len(fpr)),\n",
    "                \"Model\": np.repeat(model_name, len(fpr)),\n",
    "                \"Rep\": np.repeat(rep, len(fpr)),\n",
    "                \"Fold\": np.repeat(i, len(fpr)),\n",
    "                \"FPR\": fpr,\n",
    "                \"TPR\": tpr,\n",
    "                \"Thresholds\": threshold\n",
    "            }\n",
    "        )\n",
    "        #print(len(fpr))\n",
    "        auc_plot_list.append(auc_plot_results_new)\n",
    "\n",
    "        results_list.append(new_results)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_shap_results(individual_features_shap_full_list, feature_results_list, shap_values, y_test, x_cols, x_test_features_long, outcome, procedure,\n",
    "                         feature, model_name, rep, i, svcKernel = False):\n",
    "    \n",
    "    '''\n",
    "    Inputs: individual_features_shap_full: empty shap list\n",
    "\n",
    "    Outputs: shap_file_results: dataframe of shap values for each patient and feature\n",
    "    '''\n",
    "    mod_shap = shap_values.copy()\n",
    "    #mod_shap = shap_values[0]\n",
    "\n",
    "    test_length = len(y_test)\n",
    "\n",
    "    row_vec = list(range(0, test_length))\n",
    "    shap_features_row = []\n",
    "    if svcKernel:\n",
    "        print(x_cols)\n",
    "    for row in row_vec:\n",
    "\n",
    "        shap_values_row = mod_shap[row]\n",
    "\n",
    "        temp_feature_names = list(x_cols) #CHECK here\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        new_shap_features_row = pd.DataFrame(\n",
    "            {\n",
    "                \"Patient_ID\": np.repeat(row, len(x_cols)),\n",
    "                \"Feature_Name\": temp_feature_names,\n",
    "                \"Feature_Value\": shap_values_row,\n",
    "                \"Feature_Abs_Value\": np.abs(shap_values_row),\n",
    "\n",
    "            }\n",
    "        )\n",
    "\n",
    "        shap_features_row.append(new_shap_features_row)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    shap_features_tabular = pd.concat(shap_features_row)\n",
    "\n",
    "\n",
    "\n",
    "    individual_features_shap = x_test_features_long.merge(shap_features_tabular, how = \"left\", on = [\"Patient_ID\", \"Feature_Name\"])\n",
    "\n",
    "    individual_features_shap[\"Procedure\"]=  procedure\n",
    "    individual_features_shap[\"Outcome\"]=  outcome\n",
    "    individual_features_shap[\"Model\"]=  model_name\n",
    "    individual_features_shap[\"Rep\"]=  rep\n",
    "    individual_features_shap[\"Fold\"]=  i\n",
    "\n",
    "\n",
    "    individual_features_shap_full_list.append(individual_features_shap)\n",
    "\n",
    "    summarized_features_shap = shap_features_tabular.groupby(['Feature_Name']).agg(   \n",
    "        Feature_Mean_Abs = ('Feature_Abs_Value','mean'),\n",
    "    ).reset_index()\n",
    "\n",
    "\n",
    "    feature_coef = summarized_features_shap['Feature_Mean_Abs'].values\n",
    "    feature_names = summarized_features_shap['Feature_Name'].values\n",
    "\n",
    "\n",
    "    new_features = pd.DataFrame(\n",
    "        {\n",
    "            \"Procedure\": np.repeat(procedure, len(feature_names)),\n",
    "            \"Outcome\": np.repeat(outcome, len(feature_names)),\n",
    "            \"Features\": np.repeat(feature, len(feature_names)),\n",
    "            \"Model\": np.repeat(model_name, len(feature_names)),\n",
    "            \"Rep\": np.repeat(rep, len(feature_names)),\n",
    "            \"Fold\": np.repeat(i, len(feature_names)),\n",
    "            \"Feature_Name\": feature_names,\n",
    "            \"Feature_Mean_Abs_Value\": feature_coef,\n",
    "\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "#                    feature_results = feature_results.append(new_features, ignore_index=True)\n",
    "    feature_results_list.append(new_features)\n",
    "\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46.0\n"
     ]
    }
   ],
   "source": [
    "#pip install shap==0.41.0 --user\n",
    "print(shap.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decompression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/92/tt9zk05n4qd65slhpygj9v4r0000gr/T/ipykernel_26204/3567218305.py:2: DtypeWarning: Columns (73,74,75,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,455,456,460,462,464,466,468,470,471,474,476,478,480,481,482,490,492,493,494,495,496,497,498,499,500,502,504,506,508,510,511,512,516,518,520,522,523,524,526,528,529,531,532,534,537,538,539,540,541,542,544,545,546,547,548,550,551,552,553,554,555,557,560,561,562,563,564,566,568,570,571,574,575,576,577,583,585,586,587,588,589,590,591,592,593,596,600,601,605,606,607,609,610,612,613,614,616,618,619,620,622,624,625,626,628,629,634,635,636,637,638,642,643,646,650,652,653,654,658,660,662,664,666,668,671,673,675,677,679,681,682,683,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,708,709,710,711,714,716,717,719,720,722,725,728,729,732,736,737,740,743,744,746,747,750,751,754,766,767,768,769,772,773,782,783,784,785,786,787,788,789,792,793,794,795,796,797,814,815,822,823,830,831,836,837,838,839,842,843,844,845,848,849,850,851,852,853) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  readdata = pd.read_csv(r\"122124_Spine_Reports.csv\", sep=',')\n"
     ]
    }
   ],
   "source": [
    "# Load data \n",
    "## TEST WITH FUSION FIRST\n",
    "\n",
    "print(procedure_of_interest)\n",
    "data_non_binary = load_data(procedure_of_interest)\n",
    "#data = pd.read_csv(r\"081524_Spine_reports_vf.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['High_Health_Utilizer']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 66 preop columns\n",
      "\n",
      "Column: preop_med_90days_ace_inhibitor\n",
      "Original value counts:\n",
      "preop_med_90days_ace_inhibitor\n",
      "0    10118\n",
      "1      652\n",
      "2       33\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_ace_inhibitor\n",
      "False    10118\n",
      "True       685\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_arb\n",
      "Original value counts:\n",
      "preop_med_90days_arb\n",
      "0    10273\n",
      "1      494\n",
      "2       36\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_arb\n",
      "False    10273\n",
      "True       530\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_antidepressant\n",
      "Original value counts:\n",
      "preop_med_90days_antidepressant\n",
      "0    9832\n",
      "1     865\n",
      "2      95\n",
      "3      11\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_antidepressant\n",
      "False    9832\n",
      "True      971\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_beta_2_agonist\n",
      "Original value counts:\n",
      "preop_med_90days_beta_2_agonist\n",
      "0    9779\n",
      "1     772\n",
      "2     202\n",
      "3      45\n",
      "4       5\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_beta_2_agonist\n",
      "False    9779\n",
      "True     1024\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_beta_blocker\n",
      "Original value counts:\n",
      "preop_med_90days_beta_blocker\n",
      "0    7197\n",
      "1    2825\n",
      "2     681\n",
      "3      95\n",
      "4       5\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_beta_blocker\n",
      "False    7197\n",
      "True     3606\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_benzodiazepine\n",
      "Original value counts:\n",
      "preop_med_90days_benzodiazepine\n",
      "0    6957\n",
      "1    3179\n",
      "2     629\n",
      "3      36\n",
      "4       2\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_benzodiazepine\n",
      "False    6957\n",
      "True     3846\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_immunosuppresant\n",
      "Original value counts:\n",
      "preop_med_90days_immunosuppresant\n",
      "0     5185\n",
      "1     2631\n",
      "2     1969\n",
      "3      706\n",
      "4      241\n",
      "5       59\n",
      "6        6\n",
      "7        3\n",
      "8        2\n",
      "10       1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_immunosuppresant\n",
      "True     5618\n",
      "False    5185\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_sorg_steroids\n",
      "Original value counts:\n",
      "preop_med_90days_sorg_steroids\n",
      "0    5215\n",
      "1    2672\n",
      "2    1952\n",
      "3     700\n",
      "4     217\n",
      "5      41\n",
      "6       5\n",
      "7       1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_sorg_steroids\n",
      "True     5588\n",
      "False    5215\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_nsaid\n",
      "Original value counts:\n",
      "preop_med_90days_nsaid\n",
      "0    7106\n",
      "1    3047\n",
      "2     599\n",
      "3      45\n",
      "4       6\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_nsaid\n",
      "False    7106\n",
      "True     3697\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_opioid\n",
      "Original value counts:\n",
      "preop_med_90days_opioid\n",
      "0     4234\n",
      "4     1610\n",
      "3     1459\n",
      "5     1110\n",
      "1      839\n",
      "6      642\n",
      "2      506\n",
      "7      266\n",
      "8      112\n",
      "9       19\n",
      "10       5\n",
      "11       1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_opioid\n",
      "True     6569\n",
      "False    4234\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_sorg_opioid\n",
      "Original value counts:\n",
      "preop_med_90days_sorg_opioid\n",
      "0     4234\n",
      "3     2009\n",
      "4     1572\n",
      "5      857\n",
      "1      852\n",
      "2      737\n",
      "6      367\n",
      "7      142\n",
      "8       26\n",
      "9        6\n",
      "10       1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_sorg_opioid\n",
      "True     6569\n",
      "False    4234\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_anti_psychotic\n",
      "Original value counts:\n",
      "preop_med_90days_anti_psychotic\n",
      "0    6999\n",
      "2    1949\n",
      "1    1815\n",
      "3      37\n",
      "5       2\n",
      "4       1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_anti_psychotic\n",
      "False    6999\n",
      "True     3804\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_neuromodulator\n",
      "Original value counts:\n",
      "preop_med_90days_neuromodulator\n",
      "0    8968\n",
      "1    1624\n",
      "2     188\n",
      "3      20\n",
      "4       3\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_neuromodulator\n",
      "False    8968\n",
      "True     1835\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_biphosphonate\n",
      "Original value counts:\n",
      "preop_med_90days_biphosphonate\n",
      "0    10786\n",
      "1       17\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_biphosphonate\n",
      "False    10786\n",
      "True        17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_loop_diuretic\n",
      "Original value counts:\n",
      "preop_med_90days_loop_diuretic\n",
      "0    10622\n",
      "1      180\n",
      "2        1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_loop_diuretic\n",
      "False    10622\n",
      "True       181\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_thiazide_diuretic\n",
      "Original value counts:\n",
      "preop_med_90days_thiazide_diuretic\n",
      "0    10350\n",
      "1      412\n",
      "2       41\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_thiazide_diuretic\n",
      "False    10350\n",
      "True       453\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_cinacalcet\n",
      "Original value counts:\n",
      "preop_med_90days_cinacalcet\n",
      "0    10802\n",
      "1        1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_cinacalcet\n",
      "False    10802\n",
      "True         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_insulin\n",
      "Original value counts:\n",
      "preop_med_90days_insulin\n",
      "0    10414\n",
      "1      302\n",
      "2       85\n",
      "3        2\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_insulin\n",
      "False    10414\n",
      "True       389\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_oral_diabetes\n",
      "Original value counts:\n",
      "preop_med_90days_oral_diabetes\n",
      "0    10395\n",
      "1      288\n",
      "2      101\n",
      "3       13\n",
      "4        6\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_oral_diabetes\n",
      "False    10395\n",
      "True       408\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_calcium_supplement\n",
      "Original value counts:\n",
      "preop_med_90days_calcium_supplement\n",
      "0    9471\n",
      "1    1243\n",
      "2      87\n",
      "3       2\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_calcium_supplement\n",
      "False    9471\n",
      "True     1332\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_vit_d_supplement\n",
      "Original value counts:\n",
      "preop_med_90days_vit_d_supplement\n",
      "0    10544\n",
      "1      258\n",
      "2        1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_vit_d_supplement\n",
      "False    10544\n",
      "True       259\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_90days_sorg_gabapentin\n",
      "Original value counts:\n",
      "preop_med_90days_sorg_gabapentin\n",
      "0    9470\n",
      "1    1333\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_90days_sorg_gabapentin\n",
      "False    9470\n",
      "True     1333\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_ace_inhibitor\n",
      "Original value counts:\n",
      "preop_med_6mo_ace_inhibitor\n",
      "0    10536\n",
      "1      258\n",
      "2        9\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_ace_inhibitor\n",
      "False    10536\n",
      "True       267\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_arb\n",
      "Original value counts:\n",
      "preop_med_6mo_arb\n",
      "0    10594\n",
      "1      201\n",
      "2        7\n",
      "3        1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_arb\n",
      "False    10594\n",
      "True       209\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_antidepressant\n",
      "Original value counts:\n",
      "preop_med_6mo_antidepressant\n",
      "0    10417\n",
      "1      339\n",
      "2       40\n",
      "3        5\n",
      "4        2\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_antidepressant\n",
      "False    10417\n",
      "True       386\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_beta_2_agonist\n",
      "Original value counts:\n",
      "preop_med_6mo_beta_2_agonist\n",
      "0    10582\n",
      "1      172\n",
      "2       38\n",
      "3        9\n",
      "4        2\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_beta_2_agonist\n",
      "False    10582\n",
      "True       221\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_beta_blocker\n",
      "Original value counts:\n",
      "preop_med_6mo_beta_blocker\n",
      "0    10453\n",
      "1      316\n",
      "2       28\n",
      "3        6\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_beta_blocker\n",
      "False    10453\n",
      "True       350\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_benzodiazepine\n",
      "Original value counts:\n",
      "preop_med_6mo_benzodiazepine\n",
      "0    10296\n",
      "1      449\n",
      "2       54\n",
      "3        4\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_benzodiazepine\n",
      "False    10296\n",
      "True       507\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_immunosuppresant\n",
      "Original value counts:\n",
      "preop_med_6mo_immunosuppresant\n",
      "0    9433\n",
      "1     999\n",
      "2     273\n",
      "3      75\n",
      "4      15\n",
      "5       8\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_immunosuppresant\n",
      "False    9433\n",
      "True     1370\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_sorg_steroids\n",
      "Original value counts:\n",
      "preop_med_6mo_sorg_steroids\n",
      "0    9487\n",
      "1     974\n",
      "2     264\n",
      "3      62\n",
      "4      11\n",
      "5       5\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_sorg_steroids\n",
      "False    9487\n",
      "True     1316\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_nsaid\n",
      "Original value counts:\n",
      "preop_med_6mo_nsaid\n",
      "0    10093\n",
      "1      604\n",
      "2       96\n",
      "3        9\n",
      "4        1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_nsaid\n",
      "False    10093\n",
      "True       710\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_opioid\n",
      "Original value counts:\n",
      "preop_med_6mo_opioid\n",
      "0    9597\n",
      "1     794\n",
      "2     201\n",
      "3      86\n",
      "4      53\n",
      "5      36\n",
      "6      24\n",
      "7      11\n",
      "8       1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_opioid\n",
      "False    9597\n",
      "True     1206\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_sorg_opioid\n",
      "Original value counts:\n",
      "preop_med_6mo_sorg_opioid\n",
      "0    9601\n",
      "1     795\n",
      "2     206\n",
      "3      93\n",
      "4      61\n",
      "5      25\n",
      "6      19\n",
      "7       3\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_sorg_opioid\n",
      "False    9601\n",
      "True     1202\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_anti_psychotic\n",
      "Original value counts:\n",
      "preop_med_6mo_anti_psychotic\n",
      "0    10618\n",
      "1       97\n",
      "2       83\n",
      "4        3\n",
      "3        2\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_anti_psychotic\n",
      "False    10618\n",
      "True       185\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_neuromodulator\n",
      "Original value counts:\n",
      "preop_med_6mo_neuromodulator\n",
      "0    10199\n",
      "1      544\n",
      "2       53\n",
      "3        7\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_neuromodulator\n",
      "False    10199\n",
      "True       604\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_biphosphonate\n",
      "Original value counts:\n",
      "preop_med_6mo_biphosphonate\n",
      "0    10789\n",
      "1       13\n",
      "2        1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_biphosphonate\n",
      "False    10789\n",
      "True        14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_loop_diuretic\n",
      "Original value counts:\n",
      "preop_med_6mo_loop_diuretic\n",
      "0    10724\n",
      "1       77\n",
      "2        2\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_loop_diuretic\n",
      "False    10724\n",
      "True        79\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_thiazide_diuretic\n",
      "Original value counts:\n",
      "preop_med_6mo_thiazide_diuretic\n",
      "0    10600\n",
      "1      183\n",
      "2       20\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_thiazide_diuretic\n",
      "False    10600\n",
      "True       203\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_cinacalcet\n",
      "Original value counts:\n",
      "preop_med_6mo_cinacalcet\n",
      "0    10803\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_cinacalcet\n",
      "False    10803\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_insulin\n",
      "Original value counts:\n",
      "preop_med_6mo_insulin\n",
      "0    10707\n",
      "1       83\n",
      "2       13\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_insulin\n",
      "False    10707\n",
      "True        96\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_oral_diabetes\n",
      "Original value counts:\n",
      "preop_med_6mo_oral_diabetes\n",
      "0    10620\n",
      "1      139\n",
      "2       33\n",
      "3       10\n",
      "4        1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_oral_diabetes\n",
      "False    10620\n",
      "True       183\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_calcium_supplement\n",
      "Original value counts:\n",
      "preop_med_6mo_calcium_supplement\n",
      "0    10466\n",
      "1      323\n",
      "2       13\n",
      "3        1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_calcium_supplement\n",
      "False    10466\n",
      "True       337\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_vit_d_supplement\n",
      "Original value counts:\n",
      "preop_med_6mo_vit_d_supplement\n",
      "0    10759\n",
      "1       43\n",
      "2        1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_vit_d_supplement\n",
      "False    10759\n",
      "True        44\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_6mo_sorg_gabapentin\n",
      "Original value counts:\n",
      "preop_med_6mo_sorg_gabapentin\n",
      "0    10369\n",
      "1      434\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_6mo_sorg_gabapentin\n",
      "False    10369\n",
      "True       434\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_ace_inhibitor\n",
      "Original value counts:\n",
      "preop_med_1yr_ace_inhibitor\n",
      "0    10414\n",
      "1      383\n",
      "2        6\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_ace_inhibitor\n",
      "False    10414\n",
      "True       389\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_arb\n",
      "Original value counts:\n",
      "preop_med_1yr_arb\n",
      "0    10477\n",
      "1      306\n",
      "2       18\n",
      "3        2\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_arb\n",
      "False    10477\n",
      "True       326\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_antidepressant\n",
      "Original value counts:\n",
      "preop_med_1yr_antidepressant\n",
      "0    10284\n",
      "1      448\n",
      "2       62\n",
      "3        8\n",
      "4        1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_antidepressant\n",
      "False    10284\n",
      "True       519\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_beta_2_agonist\n",
      "Original value counts:\n",
      "preop_med_1yr_beta_2_agonist\n",
      "0    10468\n",
      "1      249\n",
      "2       69\n",
      "3       13\n",
      "4        3\n",
      "5        1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_beta_2_agonist\n",
      "False    10468\n",
      "True       335\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_beta_blocker\n",
      "Original value counts:\n",
      "preop_med_1yr_beta_blocker\n",
      "0    10251\n",
      "1      495\n",
      "2       46\n",
      "3       10\n",
      "4        1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_beta_blocker\n",
      "False    10251\n",
      "True       552\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_benzodiazepine\n",
      "Original value counts:\n",
      "preop_med_1yr_benzodiazepine\n",
      "0    10246\n",
      "1      479\n",
      "2       71\n",
      "3        7\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_benzodiazepine\n",
      "False    10246\n",
      "True       557\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_immunosuppresant\n",
      "Original value counts:\n",
      "preop_med_1yr_immunosuppresant\n",
      "0    9457\n",
      "1     906\n",
      "2     314\n",
      "3      89\n",
      "4      24\n",
      "5      10\n",
      "6       3\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_immunosuppresant\n",
      "False    9457\n",
      "True     1346\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_sorg_steroids\n",
      "Original value counts:\n",
      "preop_med_1yr_sorg_steroids\n",
      "0    9527\n",
      "1     883\n",
      "2     301\n",
      "3      69\n",
      "4      16\n",
      "5       6\n",
      "6       1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_sorg_steroids\n",
      "False    9527\n",
      "True     1276\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_nsaid\n",
      "Original value counts:\n",
      "preop_med_1yr_nsaid\n",
      "0    9986\n",
      "1     665\n",
      "2     131\n",
      "3      17\n",
      "4       4\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_nsaid\n",
      "False    9986\n",
      "True      817\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_opioid\n",
      "Original value counts:\n",
      "preop_med_1yr_opioid\n",
      "0    9501\n",
      "1     760\n",
      "2     204\n",
      "3     111\n",
      "4      92\n",
      "5      71\n",
      "6      40\n",
      "7      17\n",
      "8       7\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_opioid\n",
      "False    9501\n",
      "True     1302\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_sorg_opioid\n",
      "Original value counts:\n",
      "preop_med_1yr_sorg_opioid\n",
      "0    9506\n",
      "1     759\n",
      "2     214\n",
      "3     135\n",
      "4      92\n",
      "5      59\n",
      "6      26\n",
      "7      12\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_sorg_opioid\n",
      "False    9506\n",
      "True     1297\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_anti_psychotic\n",
      "Original value counts:\n",
      "preop_med_1yr_anti_psychotic\n",
      "0    10532\n",
      "1      136\n",
      "2      131\n",
      "3        4\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_anti_psychotic\n",
      "False    10532\n",
      "True       271\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_neuromodulator\n",
      "Original value counts:\n",
      "preop_med_1yr_neuromodulator\n",
      "0    10171\n",
      "1      546\n",
      "2       79\n",
      "3        7\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_neuromodulator\n",
      "False    10171\n",
      "True       632\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_biphosphonate\n",
      "Original value counts:\n",
      "preop_med_1yr_biphosphonate\n",
      "0    10782\n",
      "1       20\n",
      "2        1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_biphosphonate\n",
      "False    10782\n",
      "True        21\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_loop_diuretic\n",
      "Original value counts:\n",
      "preop_med_1yr_loop_diuretic\n",
      "0    10706\n",
      "1       94\n",
      "2        3\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_loop_diuretic\n",
      "False    10706\n",
      "True        97\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_thiazide_diuretic\n",
      "Original value counts:\n",
      "preop_med_1yr_thiazide_diuretic\n",
      "0    10470\n",
      "1      305\n",
      "2       28\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_thiazide_diuretic\n",
      "False    10470\n",
      "True       333\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_cinacalcet\n",
      "Original value counts:\n",
      "preop_med_1yr_cinacalcet\n",
      "0    10803\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_cinacalcet\n",
      "False    10803\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_insulin\n",
      "Original value counts:\n",
      "preop_med_1yr_insulin\n",
      "0    10674\n",
      "1       98\n",
      "2       31\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_insulin\n",
      "False    10674\n",
      "True       129\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_oral_diabetes\n",
      "Original value counts:\n",
      "preop_med_1yr_oral_diabetes\n",
      "0    10518\n",
      "1      194\n",
      "2       70\n",
      "3       18\n",
      "4        3\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_oral_diabetes\n",
      "False    10518\n",
      "True       285\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_calcium_supplement\n",
      "Original value counts:\n",
      "preop_med_1yr_calcium_supplement\n",
      "0    10247\n",
      "1      535\n",
      "2       19\n",
      "3        2\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_calcium_supplement\n",
      "False    10247\n",
      "True       556\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_vit_d_supplement\n",
      "Original value counts:\n",
      "preop_med_1yr_vit_d_supplement\n",
      "0    10718\n",
      "1       85\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_vit_d_supplement\n",
      "False    10718\n",
      "True        85\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: preop_med_1yr_sorg_gabapentin\n",
      "Original value counts:\n",
      "preop_med_1yr_sorg_gabapentin\n",
      "0    10389\n",
      "1      413\n",
      "2        1\n",
      "Name: count, dtype: int64\n",
      "New value counts:\n",
      "preop_med_1yr_sorg_gabapentin\n",
      "False    10389\n",
      "True       414\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "##Convert to binary preop_meds\n",
    "data = preop_to_binary(data_non_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Decompression_01_14_25_'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "file_name_base = procedure_of_interest+\"_\"+date+\"_\"\n",
    "file_name_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10803, 985)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#full_feature_outcome_test(feature=\"PLS_features\", outcome=\"Post_lam_syndrome\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['gender'] == 'U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High_Health_Utilizer\n",
      "(10128, 1005)\n"
     ]
    }
   ],
   "source": [
    "### Set up what columns to use \n",
    "## Testing with fusion first\n",
    "# Set feature, outcome\n",
    "mainfeature = \"Health_Util_Features\"\n",
    "outcome = outcomes[0]\n",
    "print(outcome)\n",
    "data_new = add_columns_remove_rows(data)\n",
    "print(data_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMP missing columns\n",
    "\n",
    "bmp_columns = [col for col in data_new.columns if col.startswith('BMP')]\n",
    "# Calculate the percentage of missing values for each of these columns\n",
    "missing_percentages = data_new[bmp_columns].isnull().mean() * 100\n",
    "\n",
    "# Convert the result to a DataFrame for better readability\n",
    "BMP_missing_df = pd.DataFrame({'Column': missing_percentages.index, 'Percent Missing': missing_percentages.values})\n",
    "BMP_missing_df.to_csv(f\"{procedure_of_interest}_{pickle_folder_name}_BMP_missing.csv\", index=False)\n",
    "\n",
    "# CBC missing columns\n",
    "\n",
    "cbc_columns = [col for col in data_new.columns if col.startswith('CBC')]\n",
    "# Calculate the percentage of missing values for each of these columns\n",
    "missing_percentages = data_new[cbc_columns].isnull().mean() * 100\n",
    "\n",
    "# Convert the result to a DataFrame for better readability\n",
    "CBC_missing_df = pd.DataFrame({'Column': missing_percentages.index, 'Percent Missing': missing_percentages.values})\n",
    "CBC_missing_df.to_csv(f\"{procedure_of_interest}_{pickle_folder_name}_CBC_missing.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CBC_MONOCYTES', 'CBC_MONOCYTES_days_before_surgery'), ('CBC_NEUTROPHILS', 'CBC_NEUTROPHILS_days_before_surgery'), ('CBC_BASOPHILS', 'CBC_BASOPHILS_days_before_surgery'), ('CBC_PLATELET_COUNT', 'CBC_PLATELET_COUNT_days_before_surgery'), ('CBC_WBC_COUNT', 'CBC_WBC_COUNT_days_before_surgery'), ('CBC_HEMOGLOBIN', 'CBC_HEMOGLOBIN_days_before_surgery'), ('CBC_RBC_COUNT', 'CBC_RBC_COUNT_days_before_surgery'), ('CBC_RDW', 'CBC_RDW_days_before_surgery'), ('CBC_HEMATOCRIT', 'CBC_HEMATOCRIT_days_before_surgery'), ('CBC_MCH', 'CBC_MCH_days_before_surgery'), ('CBC_MCHC', 'CBC_MCHC_days_before_surgery'), ('CBC_ABSOLUTE_LYMPHOCYTES', 'CBC_ABSOLUTE_LYMPHOCYTES_days_before_surgery'), ('CBC_ABSOLUTE_NEUTROPHILS', 'CBC_ABSOLUTE_NEUTROPHILS_days_before_surgery'), ('CBC_LYMPHOCYTE', 'CBC_LYMPHOCYTE_days_before_surgery'), ('CBC_EOSINOPHILS', 'CBC_EOSINOPHILS_days_before_surgery'), ('CBC_ABSOLUTE_EOSINOPHILS', 'CBC_ABSOLUTE_EOSINOPHILS_days_before_surgery'), ('CBC_ABSOLUTE_BASOPHILS', 'CBC_ABSOLUTE_BASOPHILS_days_before_surgery'), ('CBC_ABSOLUTE_MONOCYTES', 'CBC_ABSOLUTE_MONOCYTES_days_before_surgery'), ('BMP_POTASSIUM', 'BMP_POTASSIUM_days_before_surgery'), ('BMP_CREATININE', 'BMP_CREATININE_days_before_surgery'), ('BMP_BUN', 'BMP_BUN_days_before_surgery'), ('BMP_CALCIUM', 'BMP_CALCIUM_days_before_surgery'), ('BMP_CHLORIDE', 'BMP_CHLORIDE_days_before_surgery'), ('BMP_SODIUM', 'BMP_SODIUM_days_before_surgery'), ('BMP_CO2', 'BMP_CO2_days_before_surgery'), ('BMP_GLUCOSE', 'BMP_GLUCOSE_days_before_surgery')]\n",
      "(10128, 1005)\n"
     ]
    }
   ],
   "source": [
    "# Remove Labs\n",
    "data_null_labs = remove_labs_90(data_new)\n",
    "print(data_null_labs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specialist_visits: 2.0\n",
      "emergency_visits: 0.0\n",
      "Number_of_imaging_orders: 1.0\n",
      "Number_pain_meds: 4.0\n",
      "Number_referrals: 1.0\n"
     ]
    }
   ],
   "source": [
    "## Create outcome variable\n",
    "data_w_outcome = data_null_labs.copy()\n",
    "\n",
    "data_w_outcome['specialist_visits'] = data_w_outcome['Number_of_neurosurgery_visits'] + data_w_outcome['Number_of_orthopaedic_visits']\n",
    "data_w_outcome['emergency_visits'] = data_w_outcome['Number_of_ED'] + data_w_outcome['Number_of_urgent_care_visits']\n",
    "data_w_outcome['Number_pain_meds'] = data_w_outcome['Number_of_opioids_prescriptions'] + data_w_outcome['Number_of_benzodiazepine_prescriptions'] + data_w_outcome['Number_of_neuromodulator_prescriptions']\n",
    "data_w_outcome['Number_referrals'] = data_w_outcome['Number_of_PT_referrals'] + data_w_outcome['Number_of_other_referrals'] \n",
    "\n",
    "count_columns = ['specialist_visits', 'emergency_visits', 'Number_of_imaging_orders', 'Number_pain_meds', 'Number_referrals']\n",
    "\n",
    "\n",
    "for column in count_columns:\n",
    "    p75 = data_w_outcome[column].quantile(0.75)\n",
    "    print(f\"{column}: {p75}\")\n",
    "\n",
    "percentiles = data_w_outcome[count_columns].quantile(0.75)\n",
    "data_w_outcome['High_physician_time'] = ((data_w_outcome['specialist_visits'] > percentiles['specialist_visits']) | \n",
    "                                            (data_w_outcome['Number_referrals'] > percentiles['Number_referrals'])).astype('Int64')\n",
    "data_w_outcome['High_medication_time'] = ((data_w_outcome['emergency_visits'] >= 1) | \n",
    "                                               (data_w_outcome['Number_pain_meds'] > percentiles['Number_pain_meds']) |\n",
    "                                               (data_w_outcome['Number_of_imaging_orders'] > percentiles['Number_of_imaging_orders'])).astype('Int64')\n",
    "\n",
    "\n",
    "# Convert to DataFrame (makes it easier to save to CSV)\n",
    "count_stats = []\n",
    "for col in count_columns:\n",
    "    col_type = data_w_outcome[col].dtype\n",
    "    missing = data_w_outcome[col].isna().sum()\n",
    "    total = len(data_w_outcome[col])\n",
    "    \n",
    "    # Create stats dictionary for each column\n",
    "    col_stats = {\n",
    "        'column': col,\n",
    "        'dtype': str(col_type),\n",
    "        'missing_count': missing,\n",
    "        'missing_pct': (missing/total * 100).round(2),\n",
    "        'mean': data_w_outcome[col].mean(),\n",
    "        'std': data_w_outcome[col].std(),\n",
    "        'min': data_w_outcome[col].min(),\n",
    "        '25%': data_w_outcome[col].quantile(0.25),\n",
    "        'median': data_w_outcome[col].median(),\n",
    "        '75%': data_w_outcome[col].quantile(0.75),\n",
    "        'max': data_w_outcome[col].max()\n",
    "    }\n",
    "    count_stats.append(col_stats)\n",
    "\n",
    "extra_cols = ['High_physician_time', 'High_medication_time']\n",
    "\n",
    "for col in extra_cols:\n",
    "    col_type = data_w_outcome[col].dtype\n",
    "    missing = data_w_outcome[col].isna().sum()\n",
    "    total = len(data_w_outcome[col])\n",
    "\n",
    "    # Handle both boolean and binary integer columns\n",
    "    non_null = total - missing\n",
    "    true_count = data_w_outcome[col].sum()\n",
    "    false_count = non_null - true_count\n",
    "    \n",
    "    col_stats = {\n",
    "        'column': col,\n",
    "        'dtype': str(col_type),\n",
    "        'missing_count': missing,\n",
    "        'missing_pct': (missing/total * 100).round(2),\n",
    "        'true_count': true_count,\n",
    "        'true_pct': (true_count/non_null * 100).round(2) if non_null > 0 else 0,\n",
    "        'false_count': false_count,\n",
    "        'false_pct': (false_count/non_null * 100).round(2) if non_null > 0 else 0\n",
    "    }\n",
    "    count_stats.append(col_stats)\n",
    "\n",
    "# Convert to DataFrame\n",
    "count_summary_df = pd.DataFrame(count_stats)\n",
    "\n",
    "# Save to CSV\n",
    "count_summary_df.to_csv(f'{procedure_of_interest}_{pickle_folder_name}_percentile_75_thresholds.csv', index=False)\n",
    "\n",
    "''' OR\n",
    "# Create the classification\n",
    "# If threshold or more counts are above their 75th percentile -> high utilizer (1)\n",
    "# Otherwise -> low/normal utilizer (0)\n",
    "def classify_utilizer(row, threshold=2):  # Added threshold parameter\n",
    "    count_above_75 = 0  # Counter for columns exceeding 75th percentile\n",
    "    for column in count_columns:\n",
    "        if row[column] > percentiles[column]:\n",
    "            count_above_75 += 1\n",
    "    return 1 if count_above_75 >= threshold else 0  # Return 1 if meets or exceeds threshold\n",
    "'''\n",
    "# Create the classification\n",
    "# If ALL counts are above their 75th percentiles -> high utilizer (1)\n",
    "# If ANY count is below its 75th percentile -> low/normal utilizer (0)\n",
    "''' AND\n",
    "def classify_utilizer(row):\n",
    "    for column in count_columns:\n",
    "        if row[column] <= percentiles[column]:  # Changed > to <= and flipped the logic\n",
    "            return 0  # Low/normal utilizer\n",
    "    return 1  # High utilizer - only reached if ALL counts are above 75th percentile\n",
    "'''\n",
    "\n",
    "# Apply the classification with threshold of 2\n",
    "threshold = 1  # You can adjust this number as needed\n",
    "#data_w_outcome['High_Health_Utilizer'] = data_w_outcome.apply(lambda x: classify_utilizer(x, threshold=threshold), axis=1)\n",
    "#data_w_outcome['High_Health_Utilizer'] = data_w_outcome.apply(classify_utilizer, axis=1)\n",
    "data_w_outcome['High_Health_Utilizer'] = ((data_w_outcome['High_physician_time'] == 1) &\n",
    "                                          (data_w_outcome['High_medication_time'] == 1)).astype(\"Int64\")\n",
    "data_w_outcome['High_Health_Utilizer'] = data_w_outcome['High_Health_Utilizer'].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 Preop Columns\n",
      "All preop conversions good!\n",
      "All preop conversions good!\n",
      "All preop conversions good!\n",
      "All preop conversions good!\n",
      "All preop conversions good!\n",
      "All preop conversions good!\n",
      "All preop conversions good!\n",
      "All preop conversions good!\n",
      "All preop conversions good!\n",
      "All preop conversions good!\n",
      "All preop conversions good!\n",
      "All preop conversions good!\n",
      "All preop conversions good!\n",
      "All preop conversions good!\n",
      "All preop conversions good!\n",
      "All preop conversions good!\n",
      "All preop conversions good!\n",
      "All preop conversions good!\n",
      "All preop conversions good!\n",
      "adding lab columns to numeric_features\n"
     ]
    }
   ],
   "source": [
    "df, df_asa, numeric_features, individual_features_shap_full = set_columns(data=data_w_outcome, outcome=outcome,\n",
    "                                                                          pofI= procedure_of_interest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10128, 105)\n"
     ]
    }
   ],
   "source": [
    "column_info = pd.DataFrame({\n",
    "    'Column Name': df.columns,\n",
    "    'Data Type': df.dtypes    \n",
    "})\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age_at_procedure', 'BMI', 'OR_length_minutes', 'BMP_POTASSIUM', 'BMP_CREATININE', 'BMP_BUN', 'BMP_CALCIUM', 'BMP_CHLORIDE', 'BMP_SODIUM', 'BMP_CO2', 'BMP_GLUCOSE', 'CBC_MONOCYTES', 'CBC_NEUTROPHILS', 'CBC_BASOPHILS', 'CBC_PLATELET_COUNT', 'CBC_WBC_COUNT', 'CBC_HEMOGLOBIN', 'CBC_RBC_COUNT', 'CBC_RDW', 'CBC_HEMATOCRIT', 'CBC_MCH', 'CBC_MCHC', 'CBC_ABSOLUTE_LYMPHOCYTES', 'CBC_ABSOLUTE_NEUTROPHILS', 'CBC_LYMPHOCYTE', 'CBC_EOSINOPHILS', 'CBC_ABSOLUTE_EOSINOPHILS', 'CBC_ABSOLUTE_BASOPHILS', 'CBC_ABSOLUTE_MONOCYTES']\n"
     ]
    }
   ],
   "source": [
    "print(numeric_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Separate df into three new dfs using separate_dfs\n",
    "# original dum_df shape (with dropnan): 11709, 102\n",
    "\n",
    "df_preds, y = separate_dfs(df, outcome=outcome)\n",
    "n = len(df_preds)\n",
    "label_n = sum(y)\n",
    "df_preds.shape\n",
    "\n",
    "#Fusion shape (3581, 81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get a list of all columns with nan values\n",
    "nan_df = df_preds.isna()\n",
    "NaNColumn_list = nan_df.any().loc[nan_df.any() == True].index.tolist()\n",
    "print(len(NaNColumn_list))\n",
    "print(NaNColumn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary stats\n",
    "df_for_summary = df.copy()\n",
    "df_for_summary['surgery_start_datetime'] = pd.to_datetime(df_for_summary['surgery_start_datetime'])\n",
    "(df_for_summary.dtypes).unique()\n",
    "\n",
    "def get_summary_stats(df):\n",
    "    # Initialize lists to store results\n",
    "    stats = []\n",
    "    nrow, ncol = df.shape\n",
    "    shape_stats = {\n",
    "        'column': 'DataFrame Shape',\n",
    "        'dtype': 'info',\n",
    "        'missing_count': nrow,\n",
    "        'missing_pct': ncol\n",
    "    }\n",
    "    stats.append(shape_stats)\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        missing = df[col].isna().sum()\n",
    "        total = len(df[col])\n",
    "        \n",
    "        # Create base stats dictionary\n",
    "        col_stats = {\n",
    "            'column': col,\n",
    "            'dtype': str(col_type),\n",
    "            'missing_count': missing,\n",
    "            'missing_pct': (missing/total * 100).round(2)\n",
    "        }\n",
    "        # Check if Int64/int64 column is binary (0,1,NA only)\n",
    "        is_binary = False\n",
    "        if col_type in ['Int64']:\n",
    "            unique_vals = df[col].dropna().unique()\n",
    "            is_binary = set(unique_vals).issubset({0, 1})\n",
    "\n",
    "        # Add type-specific statistics\n",
    "        if (col_type in ['int64', 'Int64', 'float64']) and not is_binary:\n",
    "            col_stats.update({\n",
    "                'mean': df[col].mean(),\n",
    "                'std': df[col].std(),\n",
    "                'min': df[col].min(),\n",
    "                '25%': df[col].quantile(0.25),\n",
    "                'median': df[col].median(),\n",
    "                '75%': df[col].quantile(0.75),\n",
    "                'max': df[col].max()\n",
    "            })\n",
    "        elif col_type == 'datetime64[ns]':\n",
    "             # For datetime, calculate days from the minimum date\n",
    "            min_date = df[col].min()\n",
    "            days_from_min = (df[col] - min_date).dt.total_seconds() / (24*60*60)\n",
    "            \n",
    "            col_stats.update({\n",
    "                'min': df[col].min(),\n",
    "                'max': df[col].max(),\n",
    "                'mean': df[col].mean(),\n",
    "                'std': days_from_min.std(),  # Standard deviation in days\n",
    "                '25%': df[col].quantile(0.25),\n",
    "                'median': df[col].quantile(0.50),\n",
    "                '75%': df[col].quantile(0.75),\n",
    "                'range_days': (df[col].max() - df[col].min()).days\n",
    "            })\n",
    "        elif col_type == 'bool' or is_binary:\n",
    "            # Handle both boolean and binary integer columns\n",
    "            non_null = total - missing\n",
    "            true_count = df[col].sum()\n",
    "            false_count = non_null - true_count\n",
    "            \n",
    "            col_stats.update({\n",
    "                'true_count': true_count,\n",
    "                'true_pct': (true_count/non_null * 100).round(2) if non_null > 0 else 0,\n",
    "                'false_count': false_count,\n",
    "                'false_pct': (false_count/non_null * 100).round(2) if non_null > 0 else 0\n",
    "            })\n",
    "        stats.append(col_stats)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    summary_df = pd.DataFrame(stats)\n",
    "    return summary_df\n",
    "\n",
    "# Use the function\n",
    "summary_stats = get_summary_stats(df_for_summary)\n",
    "\n",
    "summary_stats.to_csv(f'{procedure_of_interest}_{pickle_folder_name}_summary_stats.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cell\n",
    "csv_path = f'{procedure_of_interest}_{date}_model_execution_log.csv'\n",
    "if not os.path.exists(csv_path):\n",
    "    pd.DataFrame(columns=['model_name', 'timestamp', \n",
    "                        'execution_time_minutes', 'execution_time_seconds']).to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Negative LOS patients\n",
    "df_LOS_neg = df_for_summary[df_for_summary['LOS_days'] < 0]\n",
    "df_LOS_neg.to_csv('df_LOS_neg.csv', index=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Where graft is true\n",
    "df_graft_true = data[data['cpt_graft'] == True]\n",
    "# Split the strings and get unique values\n",
    "unique_numbers = set()\n",
    "\n",
    "# Assuming your column name is 'column_name' - replace with actual column name\n",
    "for string in df_graft_true['procedure_codes'].dropna():  # dropna() to handle any NaN values\n",
    "    numbers = string.split('; ')  # split on '; '\n",
    "    unique_numbers.update(numbers)\n",
    "\n",
    "# Convert to sorted list for better viewing\n",
    "unique_numbers_sorted = sorted(unique_numbers)\n",
    "\n",
    "print(\"Unique numbers found:\")\n",
    "print(unique_numbers_sorted)\n",
    "print(f\"\\nTotal unique numbers: {len(unique_numbers_sorted)}\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot out number of missing by surgery year\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "want_missingcharts = False\n",
    "if want_missingcharts:\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    output_dir = f'preop_missing_{procedure_of_interest}'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Extract year from datetime column\n",
    "    df_for_summary['surgery_year'] = df_for_summary['surgery_start_datetime'].dt.year\n",
    "\n",
    "    # Get all preop columns\n",
    "    preop_columns = [col for col in df_for_summary.columns if col.startswith('preop')]\n",
    "\n",
    "    # Create a plot for each preop column\n",
    "    for col in preop_columns:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Calculate missing values by year\n",
    "        missing_by_year = df_for_summary.groupby('surgery_year')[col].apply(lambda x: x.isna().sum()).reset_index()\n",
    "        missing_by_year.columns = ['Year', 'Missing Count']\n",
    "        \n",
    "        # Create bar plot\n",
    "        sns.barplot(data=missing_by_year, x='Year', y='Missing Count')\n",
    "        \n",
    "        # Customize plot\n",
    "        plt.title(f'Missing Values by Year: {col}')\n",
    "        plt.xlabel('Surgery Year')\n",
    "        plt.ylabel('Number of Missing Values')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for i, v in enumerate(missing_by_year['Missing Count']):\n",
    "            plt.text(i, v, str(v), ha='center', va='bottom')\n",
    "        \n",
    "        # Adjust layout and save\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/{col}_missing.png')\n",
    "        plt.close()\n",
    "\n",
    "    # Optional: Create a summary plot with all preop columns\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Melt the data for all preop columns\n",
    "    melted_df_for_summary = df_for_summary.melt(id_vars=['surgery_year'], \n",
    "                        value_vars=preop_columns, \n",
    "                        var_name='Preop Variable', \n",
    "                        value_name='Value')\n",
    "\n",
    "    # Calculate missing values\n",
    "    missing_summary = (melted_df_for_summary.groupby(['surgery_year', 'Preop Variable'])\n",
    "                    .apply(lambda x: x['Value'].isna().sum())\n",
    "                    .reset_index(name='Missing Count'))\n",
    "\n",
    "    # Create summary plot\n",
    "    sns.barplot(data=missing_summary, \n",
    "                x='surgery_year', \n",
    "                y='Missing Count', \n",
    "                hue='Preop Variable')\n",
    "\n",
    "    plt.title('Missing Values by Year: All Preop Variables')\n",
    "    plt.xlabel('Surgery Year')\n",
    "    plt.ylabel('Number of Missing Values')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/all_preop_missing.png')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting and Results DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_set)\n",
    "print(n)\n",
    "print(procedure_of_interest)\n",
    "print(label_n)\n",
    "print(df_preds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later, when you need to use the data for a specific model:\n",
    "def load_split_data(rep, fold):\n",
    "    print(f'Loading split data for {pickle_folder_name}, {procedure_of_interest}, rep {rep} and fold {fold}')\n",
    "    with open(f'{pickle_folder_name}_{procedure_of_interest}_SavedSplits/split_data_rep{rep}_fold{fold}.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save TrainTests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Create a directory to store the pickled data\n",
    "traintest_start_time = time.time()\n",
    "os.makedirs(f'{pickle_folder_name}_{procedure_of_interest}_SavedSplits', exist_ok=True)\n",
    "for rep in repetitions:\n",
    "    preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "        \n",
    "        # Create all the different train_test splits\n",
    "        print(f'Creating train_test split for {pickle_folder_name}, procedure {procedure_of_interest}, rep {rep} fold {i}')\n",
    "        split_data = set_train_test(input_df= df_preds, y=y, train_index=train_index, test_index=test_index, rep=rep, preprocessor=preprocessor,\n",
    "                                    impute_number=impute_iterations, want_val=True)\n",
    "        with open(f'{pickle_folder_name}_{procedure_of_interest}_SavedSplits/split_data_rep{rep}_fold{i}.pkl', 'wb') as f:\n",
    "            pickle.dump(split_data, f)\n",
    "\n",
    "log_execution(csv_path, 'TrainTestSplit', traintest_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ASA\n",
    "'''\n",
    "def ASA_train_test(procedure):\n",
    "\n",
    "    # Create results lists\n",
    "    ASA_results_list = []\n",
    "    ASA_auc_list = []\n",
    "\n",
    "    for rep in repetitions:\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "            # Create all the different train_test splits\n",
    "            ASA_split_data = load_split_data(rep, i)\n",
    "            x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "            x_test_features_long, n_features, x_cols, x_train_std, x_test_std = ASA_split_data\n",
    "\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "            \n",
    "            \n",
    "         \n",
    "            asa_model_fitted, y_pred, y_prob_vec = ASA_model(x_train, x_test, y_train, rep)\n",
    "            collect_results(ASA_results_list, ASA_auc_list, outcome, procedure, feature, \"ASA\", rep, i, n, label_n,\n",
    "                                                            y_test, y_prob_vec, y_pred)\n",
    "\n",
    "    ASA_results = pd.concat(ASA_results_list, ignore_index=True)\n",
    "    ASA_auc_results = pd.concat(ASA_auc_list, ignore_index=True)\n",
    "\n",
    "    return ASA_results, ASA_auc_results\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW ASA USING LOGISTIC REGRESSION!\n",
    "def ASA_train_test(procedure):\n",
    "\n",
    "    # Create results lists\n",
    "    ASA_results_list = []\n",
    "    ASA_auc_list = []\n",
    "\n",
    "    for rep in repetitions:\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_asa, y)):\n",
    "            # Create all the different train_test splits\n",
    "\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "\n",
    "            X_train_asa = df_asa.iloc[train_index].copy()\n",
    "            X_train_asa = X_train_asa.reset_index(drop=True)\n",
    "            X_test_asa = df_asa.iloc[test_index].copy()\n",
    "            X_test_asa = X_test_asa.reset_index(drop=True)\n",
    "            y_train = y[train_index].copy()\n",
    "            y_test = y[test_index].copy()\n",
    "\n",
    "\n",
    "            # Impute ASA class with mode of training set\n",
    "            train_mode = X_train_asa['asa_class'].mode()[0]\n",
    "            X_train_asa['asa_class'] = X_train_asa['asa_class'].fillna(train_mode)\n",
    "            X_test_asa['asa_class'] = X_test_asa['asa_class'].fillna(train_mode)\n",
    "\n",
    "            # Extract features and reshape for sklearn\n",
    "            X_train = X_train_asa['asa_class'].values.reshape(-1, 1)\n",
    "            X_test = X_test_asa['asa_class'].values.reshape(-1, 1)\n",
    "\n",
    "            # No need to scale since it's a single ordinal variable\n",
    "            # Train logistic regression\n",
    "            lr_model = LogisticRegression(random_state=rep)\n",
    "            lr_model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get predictions\n",
    "            y_pred = lr_model.predict(X_test)\n",
    "            y_prob_vec = lr_model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            \n",
    "            collect_results(ASA_results_list, ASA_auc_list, outcome, procedure, feature, \"ASA\", rep, i, n, label_n,\n",
    "                                                            y_test, y_prob_vec, y_pred)\n",
    "\n",
    "    ASA_results = pd.concat(ASA_results_list, ignore_index=True)\n",
    "    ASA_auc_results = pd.concat(ASA_auc_list, ignore_index=True)\n",
    "\n",
    "    return ASA_results, ASA_auc_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run ASA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASA_start_time = time.time()\n",
    "ASA_results, ASA_auc_results = ASA_train_test(procedure_of_interest)\n",
    "log_execution(csv_path, \"ASA\", ASA_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASA_auc_results.to_csv(procedure_of_interest+ \"_\" + pickle_folder_name + \"_ASA_\" + \"auc_data.csv\")\n",
    "ASA_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name + \"_ASA_\"+ \"model_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASA Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ASA categorical\n",
    "'''\n",
    "def ASA_categorical_train(procedure):\n",
    "    asa_cat_results_list = []\n",
    "    asa_cat_auc_list = []\n",
    "    for rep in repetitions:\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "            # Create all the different train_test splits\n",
    "\n",
    "            ASA_cat_split_data = load_split_data(rep, i)\n",
    "            x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "            x_test_features_long, n_features, x_cols, x_train_std, x_test_std = ASA_cat_split_data\n",
    "\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "\n",
    "            y_pred, y_prob_vec_two = ASA_categorical_model(x_test)\n",
    "            #print(y_prob_vec_two)\n",
    "            collect_results(asa_cat_results_list, asa_cat_auc_list, outcome, procedure, feature,\n",
    "                            \"ASA_Categorical\", rep, i, n, label_n, y_test, y_prob_vec_two, y_pred)\n",
    "\n",
    "    ASA_cat_results = pd.concat(asa_cat_results_list, ignore_index=True)\n",
    "    ASA_cat_auc_results = pd.concat(asa_cat_auc_list, ignore_index=True)\n",
    "\n",
    "    return ASA_cat_results, ASA_cat_auc_results\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run ASA Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ASA_cat_results, ASA_cat_auc_results = ASA_categorical_train(procedure_of_interest)\n",
    "ASA_cat_auc_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_ASACat_\" + \"auc_data.csv\")\n",
    "ASA_cat_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_ASACat_\"+ \"model_results.csv\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENet\n",
    "\n",
    "import numpy as np\n",
    "def ENet_model_train_test(procedure):\n",
    "\n",
    "    ENet_results_list = []\n",
    "    ENet_auc_list = []\n",
    "    ENet_shap_full_list = []\n",
    "    ENet_shap_summary_list = []\n",
    "\n",
    "    for rep in repetitions:\n",
    "        #rep = 4\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "            #if i != 3: \n",
    "            #    continue\n",
    "            # Create all the different train_test splits\n",
    "            Enet_split_data = load_split_data(rep, i)\n",
    "            x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "            x_test_features_long, n_features, x_cols, x_train_std, x_test_std = Enet_split_data\n",
    "\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "            print(f\"SizeData {x_train.shape}\")\n",
    "            #x_train = x_train.reset_index(drop=True)\n",
    "\n",
    "            ENet_model_fitted, y_pred, y_prob_vec, shap_values = ENet_model(outcome, preprocessor, x_train, y_train,\n",
    "                                                                            x_test, x_train_std, x_test_std, rep)\n",
    "            \n",
    "            collect_results(ENet_results_list, ENet_auc_list, outcome, procedure, feature,\n",
    "                            \"ENet\", rep, i, n, label_n, y_test, y_prob_vec, y_pred)\n",
    "            \n",
    "            if Get_shaps:\n",
    "                print(\"Collecting Shaps\")\n",
    "                collect_shap_results(ENet_shap_full_list, ENet_shap_summary_list, shap_values, \n",
    "                                    y_test, x_cols, x_test_features_long, outcome, procedure, feature, \"ENet\",\n",
    "                                    rep, i)\n",
    "            else:\n",
    "                print(\"Not collecting shaps\")\n",
    "            \n",
    "            ENET_temp_results = pd.concat(ENet_results_list, ignore_index=True)\n",
    "            ENET_temp_auc_results = pd.concat(ENet_auc_list, ignore_index=True)\n",
    "            \n",
    "            ENET_temp_auc_results.to_csv(\"TEMP_\" + procedure_of_interest+\"_\" + pickle_folder_name +\"_ENET_\" + \"auc_data.csv\")\n",
    "            ENET_temp_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_ENET_\"+ \"model_results.csv\")\n",
    "\n",
    "            if Get_shaps:\n",
    "                print(\"Saving temp shaps\")\n",
    "                ENET_temp_shap_long_results = pd.concat(ENet_shap_full_list, ignore_index=True)\n",
    "                ENET_temp_shap_summary_results = pd.concat(ENet_shap_summary_list, ignore_index=True)\n",
    "                ENET_temp_shap_long_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_ENET_\"+\"feature_importance_full.csv\")\n",
    "                ENET_temp_shap_summary_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_ENET_\"+\"feature_importance.csv\")\n",
    "            else:\n",
    "                print(\"Not saving temp Shaps\")\n",
    "            \n",
    "            \n",
    "\n",
    "    ENet_results = pd.concat(ENet_results_list, ignore_index=True)\n",
    "    ENet_auc_results = pd.concat(ENet_auc_list, ignore_index=True)\n",
    "    if Get_shaps:\n",
    "        print(\"Saving final shaps\")\n",
    "        ENet_shap_long_results = pd.concat(ENet_shap_full_list, ignore_index=True)\n",
    "        ENet_shap_summary_results = pd.concat(ENet_shap_summary_list, ignore_index=True)\n",
    "    else:\n",
    "        print(\"Not saving final shaps\")\n",
    "        ENet_shap_long_results = None\n",
    "        ENet_shap_summary_results = None\n",
    "\n",
    "    return ENet_results, ENet_auc_results, ENet_shap_long_results, ENet_shap_summary_results, shap_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enet Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results, AUC results, shaps, and shap summaries\n",
    "import time\n",
    "ENet_start_time = time.time()\n",
    "ENet_results, ENet_auc_results, ENet_shap_long_results, ENet_shap_summary_results, shap_values_Enet = ENet_model_train_test(procedure_of_interest)\n",
    "log_execution(csv_path, 'ENet', ENet_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enet Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENet_auc_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_Enet_\" + \"auc_data.csv\")\n",
    "ENet_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_Enet_\"+ \"model_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Get_shaps:\n",
    "    print(\"Saving Shap vals to CSV\")\n",
    "    ENet_shap_summary_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_Enet_\"+\"feature_importance.csv\")\n",
    "    ENet_shap_long_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_Enet_\"+\"feature_importance_full.csv\")\n",
    "else:\n",
    "    print(\"Not saving Shap vals to CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBoost\n",
    "def XGB_model_train_test(procedure):\n",
    "    XGB_results_list = []\n",
    "    XGB_auc_list = []\n",
    "    XGB_shap_full_list = []\n",
    "    XGB_shap_summary_list = []\n",
    "\n",
    "    for rep in repetitions:\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "            # Create all the different train_test splits\n",
    "            split_data = load_split_data(rep, i)\n",
    "            x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "            x_test_features_long, n_features, x_cols, x_train_std, x_test_std = split_data\n",
    "\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "\n",
    "            XGBoost_model_fitted, y_pred, y_prob_vec, shap_values_two = XGBoost_model(outcome, preprocessor, x_train,\n",
    "                                                                                y_train, x_test, x_train_std, x_test_std,\n",
    "                                                                                rep)\n",
    "            collect_results(XGB_results_list, XGB_auc_list, outcome, procedure, feature, \"XGB\", rep, i, n,\n",
    "                            label_n, y_test, y_prob_vec, y_pred)\n",
    "            \n",
    "            if Get_shaps:\n",
    "                print(\"Collecting Shaps\")\n",
    "                collect_shap_results(XGB_shap_full_list, XGB_shap_summary_list, shap_values_two, y_test,\n",
    "                                 x_cols, x_test_features_long, outcome, procedure, feature, \n",
    "                                 \"XGB\", rep, i)\n",
    "            else:\n",
    "                print(\"Not collecting shaps\")\n",
    "            \n",
    "            XGB_temp_results = pd.concat(XGB_results_list, ignore_index=True)\n",
    "            XGB_temp_auc_results = pd.concat(XGB_auc_list, ignore_index=True)\n",
    "            XGB_temp_auc_results.to_csv(\"TEMP_\" + procedure_of_interest+\"_\" + pickle_folder_name +\"_XGB_\" + \"auc_data.csv\")\n",
    "            XGB_temp_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_XGB_\"+ \"model_results.csv\")\n",
    "\n",
    "\n",
    "            if Get_shaps:\n",
    "                print(\"Saving temp shaps\")\n",
    "                XGB_temp_shap_full_results = pd.concat(XGB_shap_full_list, ignore_index=True)\n",
    "                XGB_temp_shap_summary_results = pd.concat(XGB_shap_summary_list, ignore_index=True)\n",
    "                XGB_temp_shap_full_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_XGB_\"+\"feature_importance_full.csv\")\n",
    "                XGB_temp_shap_summary_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_XGB_\"+\"feature_importance.csv\")\n",
    "            else:\n",
    "                print(\"Not saving temp shaps\")\n",
    "\n",
    "\n",
    "    XGB_results = pd.concat(XGB_results_list, ignore_index=True)\n",
    "    XGB_auc_results = pd.concat(XGB_auc_list, ignore_index=True)\n",
    "\n",
    "    if Get_shaps:\n",
    "        print(\"Saving final shaps\")\n",
    "        XGB_shap_full_results = pd.concat(XGB_shap_full_list, ignore_index=True)\n",
    "        XGB_shap_summary_results = pd.concat(XGB_shap_summary_list, ignore_index=True)\n",
    "    else:\n",
    "        print(\"Not Saving Final shaps\")\n",
    "        XGB_shap_full_results = None\n",
    "        XGB_shap_summary_results = None\n",
    "\n",
    "    return XGB_results, XGB_auc_results, XGB_shap_full_results, XGB_shap_summary_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_start_time = time.time()\n",
    "XGB_results, XGB_auc_results, XGB_shap_full_results, XGB_shap_summary_results = XGB_model_train_test(procedure_of_interest)\n",
    "log_execution(csv_path, 'XGB', XGB_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XBG Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_auc_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_XGB_\" + \"auc_data.csv\")\n",
    "XGB_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_XGB_\"+ \"model_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Get_shaps:\n",
    "    print(\"Saving shap csv\")\n",
    "    XGB_shap_summary_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_XGB_\"+\"feature_importance.csv\")\n",
    "    XGB_shap_full_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_XGB_\"+\"feature_importance_full.csv\")\n",
    "else:\n",
    "    print(\"Not saving shap csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XGB_shap_summary_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RF\n",
    "Get_shaps = True\n",
    "InterventionalBool = False\n",
    "def RF_model_train_test(procedure):\n",
    "    RF_results_list = []\n",
    "    RF_auc_list = []\n",
    "    RF_shap_full_list = []\n",
    "    RF_shap_summary_list = []\n",
    "\n",
    "    for rep in repetitions:\n",
    "       # if rep != 1:\n",
    "        #    continue\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "            # Create all the different train_test splits\n",
    "         #   if i != 1:\n",
    "          #      continue\n",
    "            RF_split_data = load_split_data(rep, i)\n",
    "            x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "            x_test_features_long, n_features, x_cols, x_train_std, x_test_std = RF_split_data\n",
    "\n",
    "            print(f\"XShape {x_train.shape}\")\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "\n",
    "            RF_model_fitted, y_pred, y_prob_vec, shap_values = RF_model(outcome, preprocessor, x_train,\n",
    "                                                                        y_train, x_test, x_train_std, x_test_std,\n",
    "                                                                        rep, n_features, InterventionalBool)\n",
    "            \n",
    "            collect_results(RF_results_list, RF_auc_list, outcome, procedure, feature, \"RF\", rep, i,\n",
    "                            n, label_n, y_test, y_prob_vec, y_pred)\n",
    "            \n",
    "            if Get_shaps:\n",
    "                print(\"Collect Shaps\")\n",
    "                collect_shap_results(RF_shap_full_list, RF_shap_summary_list, shap_values, y_test, \n",
    "                                    x_cols, x_test_features_long, outcome, procedure, feature, \"RF\", rep,\n",
    "                                    i)\n",
    "            else:\n",
    "                print(\"Not collecting Shaps\")\n",
    "            \n",
    "            RF_temp_results = pd.concat(RF_results_list, ignore_index=True)\n",
    "            RF_temp_auc_results = pd.concat(RF_auc_list, ignore_index=True)\n",
    "            RF_temp_auc_results.to_csv(\"TEMP_\" + procedure_of_interest+\"_\" + pickle_folder_name +\"_RF_\" + \"auc_data.csv\")\n",
    "            RF_temp_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_RF_\"+ \"model_results.csv\")\n",
    "\n",
    "            if Get_shaps:\n",
    "                print(\"Saving temp shaps\")\n",
    "                RF_temp_shap_full_results = pd.concat(RF_shap_full_list, ignore_index=True)\n",
    "                RF_temp_shap_summary_results = pd.concat(RF_shap_summary_list, ignore_index=True)\n",
    "                RF_temp_shap_full_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_RF_\"+ \"feature_importance_full.csv\")\n",
    "                RF_temp_shap_summary_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_RF_\"+\"feature_importance.csv\")\n",
    "            else:\n",
    "                print(\"Not Saving Temp Shaps\")\n",
    "\n",
    "    RF_results = pd.concat(RF_results_list, ignore_index=True)\n",
    "    RF_auc_results = pd.concat(RF_auc_list, ignore_index=True)\n",
    "\n",
    "    if Get_shaps:\n",
    "        print(\"Save full shaps\")\n",
    "        RF_shap_full_results = pd.concat(RF_shap_full_list, ignore_index=True)\n",
    "        RF_shap_summary_results = pd.concat(RF_shap_summary_list, ignore_index=True)\n",
    "    else:\n",
    "        print(\"Not saving full shaps\")\n",
    "        RF_shap_full_results = None\n",
    "        RF_shap_summary_results = None\n",
    "\n",
    "    return RF_results, RF_auc_results, RF_shap_full_results, RF_shap_summary_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_start_time = time.time()\n",
    "RF_results, RF_auc_results, RF_shap_full_results, RF_shap_summary_results = RF_model_train_test(procedure_of_interest)\n",
    "log_execution(csv_path, 'RF', RF_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_auc_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_RF_\" + \"auc_data.csv\")\n",
    "RF_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_RF_\"+ \"model_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Get_shaps:\n",
    "    print(\"Save shaps to csv\")\n",
    "    RF_shap_summary_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_RF_\"+\"feature_importance.csv\")\n",
    "    RF_shap_full_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_RF_\"+\"feature_importance_full.csv\")\n",
    "else:\n",
    "    print(\"Not saving shaps to csv\")\n",
    "\n",
    "Get_shaps = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dummy\n",
    "\n",
    "def Dummy_model_train_test(procedure):\n",
    "    Dummy_results_list = []\n",
    "    Dummy_auc_list = []\n",
    "    for rep in repetitions:\n",
    "        #rep = 1\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "            #if i != 2:\n",
    "            #    continue\n",
    "            # Create all the different train_test splits\n",
    "\n",
    "            Dummy_split_data = load_split_data(rep, i)\n",
    "            x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "            x_test_features_long, n_features, x_cols, x_train_std, x_test_std = Dummy_split_data\n",
    "\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "\n",
    "            Dummy_model_fitted, y_pred, y_prob_vec = Dummy_model(outcome, x_train, y_train, x_test)\n",
    "            collect_results(Dummy_results_list, Dummy_auc_list, outcome, procedure, feature, \"Dummy\", rep, i, n, \n",
    "                            label_n, y_test, y_prob_vec, y_pred)\n",
    "    \n",
    "    Dummy_results = pd.concat(Dummy_results_list, ignore_index=True)\n",
    "    Dummy_auc_results = pd.concat(Dummy_auc_list, ignore_index=True) \n",
    "\n",
    "    return Dummy_results, Dummy_auc_results\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dummy_start_time = time.time()\n",
    "Dummy_results, Dummy_auc_results = Dummy_model_train_test(procedure_of_interest)\n",
    "log_execution(csv_path, 'Dummy', Dummy_start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dummy_auc_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_Dummy_\" + \"auc_data.csv\")\n",
    "Dummy_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_Dummy_\"+ \"model_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN, no shap values right now to save runtime\n",
    "def NN_model_train_test(procedure):\n",
    "    NN_results_list = []\n",
    "    NN_auc_results_list = []\n",
    "    NN_shap_results_list = []\n",
    "    NN_shap_summary_list = []\n",
    "    for rep in repetitions:\n",
    "        #rep = 4\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "            # Create all the different train_test splits\n",
    "            #if i != 3:\n",
    "            #    continue\n",
    "            NN_split_data = load_split_data(rep, i)\n",
    "\n",
    "            x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "            x_test_features_long, n_features, x_cols, x_train_std, x_test_std = NN_split_data\n",
    "\n",
    "            nn_n_features = x_train_actual.shape[1]\n",
    "            \n",
    "            y_train_actual = y_train_actual.values if isinstance(y_train_actual, pd.Series) else y_train_actual\n",
    "            y_val = y_val.values if isinstance(y_val, pd.Series) else y_val\n",
    "\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "            \n",
    "            \n",
    "            nn_model_fitted, y_pred, y_prob_vec = NN_model(outcome, preprocessor, x_train_actual, \n",
    "                                                        y_train_actual, x_val, y_val, x_test, nn_n_features,\n",
    "                                                        rep)\n",
    "            collect_results(NN_results_list, NN_auc_results_list, outcome, procedure, feature, \"NN\", rep, i,\n",
    "                            n, label_n, y_test, y_prob_vec, y_pred)\n",
    "            \n",
    "            NN_temp_results = pd.concat(NN_results_list, ignore_index=True)\n",
    "            NN_temp_auc_results = pd.concat(NN_auc_results_list, ignore_index=True)\n",
    "            #RF_shap_full_results = pd.concat(RF_shap_full_list, ignore_index=True)\n",
    "            #NN_temp_shap_summary_results = pd.concat(RF_shap_summary_list, ignore_index=True)\n",
    "            \n",
    "            NN_temp_auc_results.to_csv(\"TEMP_\" + procedure_of_interest+\"_\" + pickle_folder_name +\"_NN_\" + \"auc_data.csv\")\n",
    "            NN_temp_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_NN_\"+ \"model_results.csv\")\n",
    "            #RF_temp_shap_summary_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_RF_\"+\"feature_importance.csv\")\n",
    "            #collect_shap_results(NN_shap_results_list, NN_shap_summary_list, shap_values, y_test, x_cols, x_test_features_long,\n",
    "             #                    outcome, procedure, feature, \"NN\", rep, i)\n",
    "            \n",
    "    NN_results = pd.concat(NN_results_list, ignore_index=True)\n",
    "    NN_auc_results = pd.concat(NN_auc_results_list, ignore_index=True)\n",
    "    #NN_shap_full_results = pd.concat(NN_shap_results_list, ignore_index=True)\n",
    "    #NN_shap_summary_results = pd.concat(NN_shap_summary_list, ignore_index=True)\n",
    "    \n",
    "    return NN_results, NN_auc_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_start_time = time.time()\n",
    "NN_results, NN_auc_results = NN_model_train_test(procedure_of_interest)\n",
    "log_execution(csv_path, 'NN', NN_start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_auc_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_NN_\" + \"auc_data.csv\")\n",
    "NN_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_NN_\"+ \"model_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVC\n",
    "def linear_svc_train_test(procedure):\n",
    "    \n",
    "    SVC_results_list = []\n",
    "    SVC_auc_list = []\n",
    "    SVC_shap_full_list = []\n",
    "    SVC_shap_summary_list = []\n",
    "\n",
    "    for rep in repetitions:\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "            # Create all the different train_test splits\n",
    "\n",
    "            LinSVC_split_data = load_split_data(rep, i)\n",
    "            x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "            x_test_features_long, n_features, x_cols, x_train_std, x_test_std = LinSVC_split_data\n",
    "\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "\n",
    "            SVC_model_fitted, y_pred, y_prob_vec, shap_values = Linear_SVC_model(outcome, preprocessor, x_train, y_train,\n",
    "                                                                            x_test, x_train_std, x_test_std, rep)\n",
    "            \n",
    "            collect_results(SVC_results_list, SVC_auc_list, outcome, procedure, feature,\n",
    "                            \"LinearSVC\", rep, i, n, label_n, y_test, y_prob_vec, y_pred)\n",
    "            \n",
    "            if Get_shaps:\n",
    "                print(\"Collecting Shaps\")\n",
    "                collect_shap_results(SVC_shap_full_list, SVC_shap_summary_list, shap_values, \n",
    "                                    y_test, x_cols, x_test_features_long, outcome, procedure, feature, \"LinearSVC\",\n",
    "                                    rep, i)\n",
    "            else:\n",
    "                print(\"Not Collecting Shaps\")\n",
    "            \n",
    "            LinSVC_temp_results = pd.concat(SVC_results_list, ignore_index=True)\n",
    "            LinSVC_temp_auc_results = pd.concat(SVC_auc_list, ignore_index=True)\n",
    "            LinSVC_temp_auc_results.to_csv(\"TEMP_\" + procedure_of_interest+\"_\" + pickle_folder_name +\"_SVC_\" + \"auc_data.csv\")\n",
    "            LinSVC_temp_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_SVC_\"+ \"model_results.csv\")\n",
    "\n",
    "            if Get_shaps:\n",
    "                print(\"Saving temp shaps\")\n",
    "                LinSVC_temp_shap_long_results = pd.concat(SVC_shap_full_list, ignore_index=True)\n",
    "                LinSVC_temp_shap_summary_results = pd.concat(SVC_shap_summary_list, ignore_index=True)\n",
    "                LinSVC_temp_shap_long_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_SVC_\"+\"feature_importance_full.csv\")\n",
    "                LinSVC_temp_shap_summary_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_SVC_\"+\"feature_importance.csv\")\n",
    "            else:\n",
    "                print(\"Not saving temp shaps\")\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    SVC_results = pd.concat(SVC_results_list, ignore_index=True)\n",
    "    SVC_auc_results = pd.concat(SVC_auc_list, ignore_index=True)\n",
    "    if Get_shaps:\n",
    "        print(\"Saving final shaps\")\n",
    "        SVC_shap_long_results = pd.concat(SVC_shap_full_list, ignore_index=True)\n",
    "        SVC_shap_summary_results = pd.concat(SVC_shap_summary_list, ignore_index=True)\n",
    "    else:\n",
    "        print(\"NOT saving final shaps\")\n",
    "        SVC_shap_long_results = None\n",
    "        SVC_shap_summary_results = None\n",
    "\n",
    "    return SVC_results, SVC_auc_results, SVC_shap_long_results, SVC_shap_summary_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinSVC run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinSVC_start_time = time.time()\n",
    "LinSVC_results, LinSVC_auc_results, LinSVC_shap_long_results, LinSVC_shap_summary_results = linear_svc_train_test(procedure_of_interest)\n",
    "log_execution(csv_path, 'LinSVC', LinSVC_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinSVC Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinSVC_auc_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_LinSVC_\" + \"auc_data.csv\")\n",
    "LinSVC_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_LinSVC_\"+ \"model_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Get_shaps:\n",
    "    print(\"Saving shap to csv\")\n",
    "    LinSVC_shap_summary_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_LinSVC_\"+\"feature_importance.csv\")\n",
    "    LinSVC_shap_long_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_LinSVC_\"+\"feature_importance_full.csv\")\n",
    "else:\n",
    "    print(\"NOT saving shap to csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC with Kernels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lin SVC w Kernels\n",
    "#TODO: Fix Shap results collection with Nystroem\n",
    "def LinSVC_Kernel_model_train_test(procedure):\n",
    "    SVCKern_results_list = []\n",
    "    SVCKern_auc_list = []\n",
    "    SVCKern_shap_full_list = []\n",
    "    SVCKern_shap_summary_list = []\n",
    "    SVCKern_kernel_list = []\n",
    "\n",
    "    for rep in repetitions:\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "            # Create all the different train_test splits\n",
    "\n",
    "            LinSVCKernel_split_data = load_split_data(rep, i)\n",
    "            x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "            x_test_features_long, n_features, x_cols, x_train_std, x_test_std = LinSVCKernel_split_data\n",
    "\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "\n",
    "            SVC_model_fitted, y_pred, y_prob_vec, shap_values, best_kernel = SVC_model_with_kernels(outcome, preprocessor, x_train, y_train,\n",
    "                                                                            x_test, x_train_std, x_test_std, rep)\n",
    "            \n",
    "            collect_results(SVCKern_results_list, SVCKern_auc_list, outcome, procedure_of_interest, feature,\n",
    "                            \"LinSVC_Kernel\", rep, i, n, label_n, y_test, y_prob_vec, y_pred)\n",
    "            \n",
    "            kernel_row = pd.DataFrame(\n",
    "                {\n",
    "                    \"Procedure\": [procedure],\n",
    "                    \"Outcome\": [outcome],\n",
    "                    \"Features\": [feature],\n",
    "                    \"Model\": [\"LinSVC_Kernel\"],\n",
    "                    \"Rep\": [rep],\n",
    "                    \"Fold\": [i],\n",
    "                    \"Best_Kernel\": [best_kernel]\n",
    "                }\n",
    "            )\n",
    "\n",
    "            SVCKern_kernel_list.append(kernel_row)\n",
    "\n",
    "\n",
    "            \n",
    "            LinSVCKern_temp_results = pd.concat(SVCKern_results_list, ignore_index=True)\n",
    "            LinSVCKern_temp_auc_results = pd.concat(SVCKern_auc_list, ignore_index=True)\n",
    "            #RF_shap_full_results = pd.concat(RF_shap_full_list, ignore_index=True)\n",
    "            #RF_temp_shap_summary_results = pd.concat(RF_shap_summary_list, ignore_index=True)\n",
    "            \n",
    "            LinSVCKern_temp_auc_results.to_csv(\"TEMP_\" + procedure_of_interest+\"_\" + pickle_folder_name +\"_LinSVCKern_\" + \"auc_data.csv\")\n",
    "            LinSVCKern_temp_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_LinSVCKern_\"+ \"model_results.csv\")\n",
    "            #RF_temp_shap_summary_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_RF_\"+\"feature_importance.csv\")\n",
    "            \n",
    "            \n",
    "            '''\n",
    "            collect_shap_results(SVCKern_shap_full_list, SVCKern_shap_summary_list, shap_values, \n",
    "                                    y_test, x_cols, x_test_features_long, outcome, procedure_of_interest, feature, \"LinSVC_Kernel\",\n",
    "                                    rep, i)\n",
    "            '''\n",
    "            \n",
    "            \n",
    "\n",
    "    LinSVC_Kernel_results = pd.concat(SVCKern_results_list, ignore_index=True)\n",
    "    LinSVC_Kernel_auc = pd.concat(SVCKern_auc_list, ignore_index=True)\n",
    "    LinSVC_Kernel_kernels = pd.concat(SVCKern_kernel_list, ignore_index=True)\n",
    "    #LinSVC_Kernel_shap_full = pd.concat(SVCKern_shap_full_list, ignore_index=True)\n",
    "    #LinSVC_Kernel_shap_summary = pd.concat(SVCKern_shap_summary_list, ignore_index=True)\n",
    "\n",
    "    return LinSVC_Kernel_results, LinSVC_Kernel_auc, LinSVC_Kernel_kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinSVC Kernel Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinSVC w/ Kernel no shap implementation right now TODO\n",
    "import time\n",
    "LinSVC_Kernel_start_time = time.time()\n",
    "LinSVC_Kernel_results, LinSVC_Kernel_auc, LinSVC_Kernel_kernels = LinSVC_Kernel_model_train_test(procedure_of_interest)\n",
    "log_execution(csv_path, \"LinSVC_Kernel\", LinSVC_Kernel_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinSVC Kernel Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinSVC_Kernel_auc.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_LinSVCKernel_\" + \"auc_data.csv\")\n",
    "LinSVC_Kernel_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_LinSVCKernel_\"+ \"model_results.csv\")\n",
    "LinSVC_Kernel_kernels.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_LinSVCKernel_\"+ \"kernelstested.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shap Stuff for full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeData_FullDataset(x_train, y_train, rep, impute_number):\n",
    "    # Combine x_train and y_train for imputation\n",
    "    x_train = x_train.reset_index(drop=True)\n",
    "\n",
    "    train_data = x_train.copy()\n",
    "    train_data['target'] = y_train\n",
    "\n",
    "    # Create and fit the imputation kernel\n",
    "    \n",
    "    kernel = mf.ImputationKernel(\n",
    "        train_data,\n",
    "        random_state=rep,\n",
    "        variable_schema = NaNColumn_list\n",
    "    )\n",
    "    \n",
    "    # Use sklearn pipeline method (as in examples)\n",
    "    pipe = Pipeline([('impute', kernel)])\n",
    "    \n",
    "    # Perform imputation\n",
    "    #kernel.mice(impute_number, verbose=True)  # Run 5 iterations, adjust as needed\n",
    "    \n",
    "    # Get the imputed training data\n",
    "    #imputed_train = kernel.complete_data()\n",
    "\n",
    "    imputed_train = pipe.fit_transform(train_data, impute__iterations = impute_number,\n",
    "                                       impute__verbose=True)\n",
    "    \n",
    "    #imputed_train = post_imputation_cleanup(imputed_train)\n",
    "\n",
    "    assert not np.any(np.isnan(imputed_train))\n",
    "\n",
    "    # Separate features and target\n",
    "    x_train_imputed = imputed_train.drop('target', axis=1)\n",
    "    y_train_imputed = imputed_train['target']\n",
    "    \n",
    "    return x_train_imputed, y_train_imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataFrameConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, numeric_features, original_dtypes=None):\n",
    "        self.numeric_features = numeric_features\n",
    "        self.original_dtypes = original_dtypes #actually all Int64\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # We don't want to get dtypes from X here since it's already transformed\n",
    "        # Instead, we'll pass in the original dtypes when creating the transformer\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame(X, columns=self.original_dtypes.index)\n",
    "        \n",
    "        # Restore original dtypes for non-numeric columns\n",
    "        non_numeric_cols = [col for col in df.columns if col not in self.numeric_features]\n",
    "        for col in non_numeric_cols:\n",
    "            # Force the conversion using round() for integers\n",
    "            df[col] = df[col].round()\n",
    "            df[col] = df[col].astype('Int64')\n",
    "            \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get code ready for imputation\n",
    "# Create standardized datasets\n",
    "def preImpute_Full(input_X, input_y, rep, preprocessor, impute_number):\n",
    "    '''\n",
    "    input_X: X_data (df_preds)\n",
    "    input_y: y_data (outcomes, no need to impute)\n",
    "\n",
    "    Outputs:\n",
    "    x_train: imputed X_data (df_preds)\n",
    "    y_train: y_data (outcomes, no need to impute)\n",
    "    x_train_features_long: long form of imputed X_data (each feature each patient)\n",
    "    n_features: number of features\n",
    "    x_cols: list of features\n",
    "    x_train_std: standardized imputed X_data (df_preds)\n",
    "    \n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    X_train = input_X.copy()\n",
    "    y_train = input_y.copy()    \n",
    "    \n",
    "\n",
    "\n",
    "    # remove the identifier columns and save them separately\n",
    "    x_train = X_train.drop(columns = [\"ir_id\", \"surgery_start_datetime\"])\n",
    "    x_train_id_cols = X_train[[\"ir_id\", \"surgery_start_datetime\"]]\n",
    "    x_train_id_cols = x_train_id_cols.reset_index(drop=True)\n",
    "    y_train = y_train.copy()\n",
    "    \n",
    "    print(f\"Shape of X_train: {x_train.shape}\")\n",
    "    #IMPUTED VALUES\n",
    "    x_train, y_train = imputeData_FullDataset(x_train, y_train, rep, impute_number)\n",
    "    \n",
    "    print(f'Shape of imputed x_train: {x_train.shape}')\n",
    "    x_train_std = preprocessor.fit_transform(x_train)\n",
    "    '''\n",
    "    testingConverter = DataFrameConverter(\n",
    "                            numeric_features=numeric_features, \n",
    "                            original_dtypes=x_train.dtypes\n",
    "                        )\n",
    "    x_train_std = testingConverter.fit_transform(x_train_std)\n",
    "    '''\n",
    "    x_train_std = save_dtypes(x_train_std, x_train, preprocessor)\n",
    "    # Keep a version that has those values as index columns \n",
    "\n",
    "    x_train_features = x_train.copy() #use imputed data \n",
    "    # Add back the identifier columns\n",
    "    x_train_features = pd.concat([x_train_id_cols, x_train_features], axis=1)\n",
    "\n",
    "    x_train_features[\"Patient_ID\"]=  np.arange(len(x_train_features))\n",
    "\n",
    "    x_train_features_long = pd.melt(x_train_features, id_vars = [\"ir_id\", \"Patient_ID\", \"surgery_start_datetime\"], var_name = \"Feature_Name\", value_name = \"Feature_Actual_Value\" )\n",
    "    \n",
    "    x_train_features_long['Feature_Actual_Value'] = pd.to_numeric(x_train_features_long['Feature_Actual_Value'])\n",
    "\n",
    "    x_cols = x_train.columns\n",
    "\n",
    "    n_features = len(x_cols)\n",
    "    print(f'Number of Features: {n_features}')\n",
    "\n",
    "    \n",
    "    return x_train, y_train, x_train_features_long, n_features, x_cols, x_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_full_dataset_model(outcome, preprocessor, x_train, y_train, x_train_std, rep, n_features_in):\n",
    "    '''\n",
    "    Actual RF model\n",
    "    Inputs: outcome (str): name of the outcome variable\n",
    "            preprocessor (sklearn.preprocessing): standardizing preprocessor object\n",
    "            x_train (pd.DataFrame): full X data\n",
    "            y_train (pd.Series): full y data\n",
    "            x_train_std (np.array): standardized X data\n",
    "            rep (int): random state for reproducibility\n",
    "\n",
    "    Outputs: \n",
    "             cv_model : fitted model object\n",
    "             y_pred : predicted class for test data\n",
    "             y_prob_vec : predicted probability for test data\n",
    "    '''\n",
    "    print(f\"Size of X is: {x_train.shape}\")\n",
    "    print(f\"Size of y is: {y_train.shape}\")\n",
    "\n",
    "    if outcome in binary_outcomes:\n",
    "        original_dtypes = x_train.dtypes\n",
    "        pipe = Pipeline([('processing', preprocessor), \n",
    "                         #('dtype_converter', DataFrameConverter(numeric_features=numeric_features, original_dtypes=original_dtypes)),\n",
    "                            ('estimator', BalancedRandomForestClassifier(random_state = rep,\n",
    "                                                                         sampling_strategy='all',\n",
    "                                                                         replacement=True,\n",
    "                                                                         bootstrap=False\n",
    "                                                                         ))]) \n",
    "\n",
    "        model_params = {\n",
    "            'estimator__n_estimators': hp.uniformint('estimator__n_estimators', 50, 250),\n",
    "            'estimator__max_features': hp.uniformint('estimator__max_features', 2, n_features_in),\n",
    "            'estimator__max_depth': hp.uniformint('estimator__max_depth', 1, 25),\n",
    "            'estimator__min_samples_split': hp.uniformint('estimator__min_samples_split', 2, 10),\n",
    "            'estimator__min_samples_leaf': hp.uniformint('estimator__min_samples_leaf', 1, 5),\n",
    "        }\n",
    "\n",
    "        cv_model = TuneSearchCV(pipe,\n",
    "                                param_distributions = model_params, n_trials = tunesearch_iterations,\n",
    "                                scoring='roc_auc', # AUC is most important metric\n",
    "                                refit=True, cv=5, n_jobs = 7,\n",
    "                                random_state = rep,\n",
    "                                search_optimization = \"hyperopt\",\n",
    "                                verbose = 2)\n",
    "\n",
    "        cv_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "        y_pred = cv_model.predict(x_train) # generate prediction (0 or 1) on input dataset\n",
    "        y_prob = cv_model.predict_proba(x_train) # generate prediction probability ([0,1])\n",
    "        y_prob_vec = y_prob[:,1]\n",
    "    \n",
    "    elif outcome in continuous_outcomes:\n",
    "\n",
    "        print(\"In Progress\")\n",
    "\n",
    "    \n",
    "\n",
    "    return cv_model, y_pred, y_prob_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def booltoInt(df):\n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Get all boolean columns\n",
    "    bool_columns = df.select_dtypes(include=['bool']).columns\n",
    "    if len(bool_columns) > 0:\n",
    "        print(\"Converting the following columns from boolean to int64:\")\n",
    "        for col in bool_columns:\n",
    "            print(f\"- {col}\")\n",
    "            df[col] = df[col].astype('Int64')\n",
    "    else:\n",
    "        print(\"No boolean columns found to convert\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTUAL CODE\n",
    "# Get all columns with NA values\n",
    "# Get X and y and impute (copy code from train test)\n",
    "import pickle\n",
    "label_vec = {\n",
    "    \"ir_id\": \"Patient ID\",\n",
    "    \"surgery_start_datetime\": \"Surgery Start Time\",\n",
    "    \"age_at_procedure\": \"Age at Procedure\",\n",
    "    \"gender_female\": \"Gender: Female\",\n",
    "    \"BMI\": \"Body Mass Index (BMI)\",\n",
    "    \"elix_aids_hiv\": \"Elix: AIDS/HIV\",\n",
    "    \"elix_lymphoma\": \"Elix: Lymphoma\",\n",
    "    \"elix_paralysis\": \"Elix: Paralysis\",\n",
    "    \"elix_psychoses\": \"Elix: Psychoses\",\n",
    "    \"elix_depression\": \"Elix: Depression\",\n",
    "    \"elix_drug_abuse\": \"Elix: Drug Abuse\",\n",
    "    \"elix_weight_loss\": \"Elix: Weight Loss\",\n",
    "    \"elix_coagulopathy\": \"Elix: Coagulopathy\",\n",
    "    \"elix_alcohol_abuse\": \"Elix: Alcohol Abuse\",\n",
    "    \"elix_liver_disease\": \"Elix: Liver Disease\",\n",
    "    \"elix_renal_failure\": \"Elix: Renal Failure\",\n",
    "    \"elix_hypothyroidism\": \"Elix: Hypothyroidism\",\n",
    "    \"elix_valvular_disease\": \"Elix: Valvular Disease\",\n",
    "    \"elix_blood_loss_anemia\": \"Elix: Blood Loss Anemia\",\n",
    "    \"elix_deficiency_anemia\": \"Elix: Deficiency Anemia\",\n",
    "    \"elix_metastatic_cancer\": \"Elix: Metastatic Cancer\",\n",
    "    \"elix_cardiac_arrhythmia\": \"Elix: Cardiac Arrhythmia\",\n",
    "    \"elix_rheumatoid_arhritis\": \"Elix: Rheumatoid Arthritis\",\n",
    "    \"elix_diabetes_complicated\": \"Elix: Complicated Diabetes\",\n",
    "    \"elix_diabetes_uncomplicated\": \"Elix: Uncomplicated Diabetes\",\n",
    "    \"elix_congestive_heart_failure\": \"Elix: Congestive Heart Failure\",\n",
    "    \"elix_hypertension_complicated\": \"Elix: Complicated Hypertension\",\n",
    "    \"elix_chronic_pulmonary_disease\": \"Elix: Chronic Pulmonary Disease\",\n",
    "    \"elix_solid_tumor_wo_metastasis\": \"Elix: Solid Tumor (Without Metastasis)\",\n",
    "    \"elix_hypertension_uncomplicated\": \"Elix: Uncomplicated Hypertension\",\n",
    "    \"elix_other_neurological_disorder\": \"Elix: Other Neurological Disorder\",\n",
    "    \"elix_peripheral vascular_disorder\": \"Elix: Peripheral Vascular Disorder\",\n",
    "    \"elix_pulmonary_circulation_disorder\": \"Elix: Pulmonary Circulation Disorder\",\n",
    "    \"elix_fluid_and_electrolyte_disorders\": \"Elix: Fluid and Electrolyte Disorders\",\n",
    "    \"elix_peptic_ulcer_disease_excluding_bleeding\": \"Elix: Peptic Ulcer Disease (Excluding Bleeding)\",\n",
    "    \"validation_cur_tobacco\": \"Current Tobacco Use Validation\",\n",
    "    \"validation_fmr_tobacco\": \"Former Tobacco Use Validation\",\n",
    "    \"shx_cervical_fusion\": \"History of Cervical Fusion\",\n",
    "    \"shx_cervical_surgery\": \"History of Cervical Surgery\",\n",
    "    \"shx_thoracolumbar_fusion\": \"History of Thoracolumbar Fusion\",\n",
    "    \"shx_thoracolumbar_surgery\": \"History of Thoracolumbar Surgery\",\n",
    "    \"shx_unspecified_spine_fusion\": \"History of Unspecified Spine Fusion\",\n",
    "    \"shx_unspecified_spine_surgery\": \"History of Unspecified Spine Surgery\",\n",
    "    \"lumbar_stenosis\": \"Lumbar Stenosis\",\n",
    "    \"lumbar_spondy\": \"Lumbar Spondylolisthesis\",\n",
    "    \"lumbar_disc_disorders\": \"Lumbar Disc Disorders\",\n",
    "    \"cervical_disc_diorders\": \"Cervical Disc Disorders\",\n",
    "    \"cervical_stenosis\": \"Cervical Stenosis\",\n",
    "    \"cervical_spondy\": \"Cervical Spondylolisthesis\",\n",
    "    \"cervical_disc_herniation\": \"Cervical Disc Herniation\",\n",
    "    \"lumbar_disc_herniation\": \"Lumbar Disc Herniation\",\n",
    "    \"preop_med_90days_ace_inhibitor\": \"Preoperative ACE Inhibitor Use (90 Days)\",\n",
    "    \"preop_med_90days_arb\": \"Preoperative ARB Use (90 Days)\",\n",
    "    \"preop_med_90days_antidepressant\": \"Preoperative Antidepressant Use (90 Days)\",\n",
    "    \"preop_med_90days_beta_2_agonist\": \"Preoperative Beta-2 Agonist Use (90 Days)\",\n",
    "    \"preop_med_90days_beta_blocker\": \"Preoperative Beta Blocker Use (90 Days)\",\n",
    "    \"preop_med_90days_benzodiazepine\": \"Preoperative Benzodiazepine Use (90 Days)\",\n",
    "    \"preop_med_90days_immunosuppresant\": \"Preoperative Immunosuppressant Use (90 Days)\",\n",
    "    \"preop_med_90days_nsaid\": \"Preoperative NSAID Use (90 Days)\",\n",
    "    \"preop_med_90days_opioid\": \"Preoperative Opioid Use (90 Days)\",\n",
    "    \"preop_med_90days_anti_psychotic\": \"Preoperative Antipsychotic Use (90 Days)\",\n",
    "    \"preop_med_90days_neuromodulator\": \"Preoperative Neuromodulator Use (90 Days)\",\n",
    "    \"preop_med_90days_biphosphonate\": \"Preoperative Biphosphonate Use (90 Days)\",\n",
    "    \"preop_med_90days_loop_diuretic\": \"Preoperative Loop Diuretic Use (90 Days)\",\n",
    "    \"preop_med_90days_thiazide_diuretic\": \"Preoperative Thiazide Diuretic Use (90 Days)\",\n",
    "    \"preop_med_90days_cinacalcet\": \"Preoperative Cinacalcet Use (90 Days)\",\n",
    "    \"preop_med_90days_insulin\": \"Preoperative Insulin Use (90 Days)\",\n",
    "    \"preop_med_90days_oral_diabetes\": \"Preoperative Oral Diabetes Medication Use (90 Days)\",\n",
    "    \"preop_med_90days_calcium_supplement\": \"Preoperative Calcium Supplement Use (90 Days)\",\n",
    "    \"preop_med_90days_vit_d_supplement\": \"Preoperative Vitamin D Supplement Use (90 Days)\",\n",
    "    \"OR_duration_hours\": \"OR Duration (Hours)\",\n",
    "    \"anesthesia_duration_hours\": \"Anesthesia Duration (Hours)\",\n",
    "    \"OR_length_minutes\": \"OR Duration (Minutes)\",\n",
    "    \"cpt_multilevel\": \"Multilevel Procedure\",\n",
    "    \"cpt_instrumentation\": \"Instrumentation\",\n",
    "    \"cohort_query_microdisc\": \"Microdiscectomy\",\n",
    "    \"anesthesia_type_General\": \"Anesthesia Type: General\",\n",
    "    \"procedure_setting_Inpatient\": \"Procedure Setting: Inpatient\",\n",
    "    \"cpt_anterior_approach\": \"Anterior Approach\",\n",
    "    \"cpt_lateral_approach\": \"Lateral Approach\",\n",
    "    \"cpt_posterior_approach\": \"Posterior Approach\",\n",
    "    \"ltc_postlaminectomy_syndrome\": \"Outcome: Post-Laminectomy Syndrome\",\n",
    "    \"1_year_ltc_postlaminectomy_syndrome\": \"Outcome: 1-year Post-Laminectomy Syndrome\",\n",
    "    \"spine_preop_pseudoarthrosis_post_fusion\": \"Preoperative Pseudoarthrosis Post-Fusion\",\n",
    "    \"spine_preop_post_laminectomy_syndrome\": \"Preoperative Post-Laminectomy Syndrome\"\n",
    "\n",
    "}\n",
    "\n",
    "reptouse = 0\n",
    "\n",
    "\n",
    "os.makedirs(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed', exist_ok=True)\n",
    "print(f'Imputing full dataset for {FullDataset_model}, with {procedure_of_interest}')\n",
    "\n",
    "#Set preprocessor\n",
    "preprocessor_RF, skf = scaleAnd_skf(numeric_features, outcome, reptouse, fulldataset=True)\n",
    "print(f\"The number of columns with missing data: {NaNColumn_list}\")\n",
    "\n",
    "trainingdata = preImpute_Full(df_preds, y, reptouse, preprocessor_RF,\n",
    "                                        impute_iterations)\n",
    "x_train_bools, y_train, x_train_features_long, n_features, x_cols, x_train_std = trainingdata\n",
    "\n",
    "x_train = booltoInt(x_train_bools)\n",
    "\n",
    "trainingdata = x_train, y_train, x_train_features_long, n_features, x_cols, x_train_std\n",
    "\n",
    "print(f\"XShape {x_train.shape}\")\n",
    "print(f\"This is the {pickle_folder_name} dataset\")\n",
    "print(f\"Procedure: {procedure_of_interest}\")\n",
    "print(f\"Feature: {feature}\")\n",
    "print(f\"Outcome: {outcome}\")\n",
    "print(f\"Rep seed: {reptouse}\")\n",
    "print(f\"Type of shap collection: {feature_perturbation_version}\")\n",
    "\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/trainingdata.pkl', 'wb') as f:\n",
    "    pickle.dump(trainingdata, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Model (pickled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE ACTUAL MODEL\n",
    "\n",
    "\n",
    "full_RF_start_time = time.time()\n",
    "csv_path_full = f\"{procedure_of_interest}_Full_RF_execution_{date}.csv\"\n",
    "\n",
    "ModelRF_pickle = RF_full_dataset_model(outcome, preprocessor_RF, x_train, y_train,\n",
    "                      x_train_std, reptouse, n_features)\n",
    "\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/modelpickle.pkl', 'wb') as f:\n",
    "    pickle.dump(ModelRF_pickle, f)\n",
    "\n",
    "log_execution(csv_path_full, \"RF_full_model\", full_RF_start_time)\n",
    "\n",
    "#Pickle the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect full model results (tested on training dataset)\n",
    "import pandas as pd\n",
    "RF_Full_results_list = []\n",
    "RF_Full_auc_list = []\n",
    "print(f'Getting from {FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/modelpickle.pkl')\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/modelpickle.pkl', 'rb') as f:\n",
    "    full_model_pickled = pickle.load(f)\n",
    "\n",
    "\n",
    "#unpickle\n",
    "RF_cvmodel, y_pred, y_prob_vec, = full_model_pickled\n",
    "\n",
    "#collect results\n",
    "collect_results(RF_Full_results_list,  RF_Full_auc_list, outcome, procedure_of_interest, \n",
    "                feature, \"RF_Full_dataset\", reptouse, 0, n, label_n, y_train, y_prob_vec,\n",
    "                y_pred)\n",
    "RF_full_results = pd.concat(RF_Full_results_list, ignore_index=True)\n",
    "RF_full_auc_results = pd.concat(RF_Full_auc_list, ignore_index=True)\n",
    "\n",
    "#Save these results as csvs\n",
    "RF_full_auc_results.to_csv(FullDataset_model + \"_\" + procedure_of_interest + \"_FullModel_Imputed/\" + procedure_of_interest+\"_FULL_\" + pickle_folder_name +\"_RF_\" + \"auc_data.csv\")\n",
    "RF_full_results.to_csv(FullDataset_model + \"_\" + procedure_of_interest + \"_FullModel_Imputed/\" +procedure_of_interest+\"_FULL_\" + pickle_folder_name +\"_RF_\"+ \"model_results.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_std.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get shaps (pickled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET THE SHAPS!\n",
    "#THIS IS PICKLED\n",
    "Get_shaps = True\n",
    "csv_path_full = f\"{procedure_of_interest}_Full_RF_execution_{date}.csv\"\n",
    "print(f\"Get shaps using {FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/modelpickle.pkl\")\n",
    "print(f\"Feature perturbation version used is: {feature_perturbation_version}\")\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/modelpickle.pkl', 'rb') as f:\n",
    "    full_model_pickled = pickle.load(f)\n",
    "\n",
    "\n",
    "#unpickle\n",
    "RF_cvmodel, y_pred, y_prob_vec, = full_model_pickled\n",
    "\n",
    "RF_shap_full_starttime = time.time()\n",
    "if Get_shaps:\n",
    "    print(\"GET SHAPS\")\n",
    "    if feature_perturbation_version == \"interventional\":\n",
    "        explainer = shap.TreeExplainer(RF_cvmodel.best_estimator_.named_steps['estimator'], data=x_train_std, feature_perturbation= \"interventional\",\n",
    "                                        model_output = \"probability\")\n",
    "    elif feature_perturbation_version == \"tree_path_dependent\":\n",
    "        explainer = shap.TreeExplainer(RF_cvmodel.best_estimator_.named_steps['estimator'], feature_perturbation= \"tree_path_dependent\",\n",
    "                                        model_output = \"raw\")\n",
    "    print(\"Getting shap values\")\n",
    "    shap_values_3d = explainer.shap_values(x_train_std)\n",
    "    print(shap_values_3d.shape)\n",
    "    shap_values = shap_values_3d[:, :, 1]\n",
    "    print(shap_values.shape)\n",
    "    print(\"done getting shap values\")\n",
    "    #shap_values_explainer = explainer(x_train_std)\n",
    "    with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl', 'wb') as f:\n",
    "        pickle.dump([shap_values, shap_values_3d, explainer], f)\n",
    "\n",
    "    log_execution(csv_path_full, \"RF_shap_full\", RF_shap_full_starttime)\n",
    "    \n",
    "else:\n",
    "    shap_values = None\n",
    "    print(\"NO SHAPS FOR YOU\")\n",
    "Get_shaps = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vizualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bar plot top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column Mapping\n",
    "\n",
    "# Do Shap bar plot\n",
    "print(f'Getting from {FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl')\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl', 'rb') as f:\n",
    "        full_dataset_shaps, full_dataset_shaps_3d, shap_explainer = pickle.load(f)\n",
    "x_train_std_display = x_train_std.copy()\n",
    "x_train_std_display = x_train_std_display.rename(columns=label_vec) # make column names look nice\n",
    "\n",
    "print(full_dataset_shaps.shape)\n",
    "#Using column order of x_train_std\n",
    "#reorder columns of x_train\n",
    "x_train_display = x_train.copy()\n",
    "x_train_display = x_train_display[x_train_std.columns] #make sure x_train display has columns in same order as std, passed into shap\n",
    "x_train_display = x_train_display.rename(columns=label_vec) #make column names look nice\n",
    "\n",
    "# Create figure and plot\n",
    "plt.figure()\n",
    "shap.summary_plot(full_dataset_shaps, x_train_display, plot_type=\"bar\", max_display=10, show=False, show_values_in_legend=True)\n",
    "# Change x-axis label\n",
    "# Adjust subplot parameters\n",
    "plt.subplots_adjust(left=.1, right=.6)\n",
    "plt.gca().set_xlabel('mean(|SHAP value|)')\n",
    "# Save the plot\n",
    "plt.savefig(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_bar_plot_{feature_perturbation_version}.png', \n",
    "            bbox_inches='tight', \n",
    "            dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Beeswarm top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Beeswarm plot\n",
    "print(f'Getting from {FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl')\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl', 'rb') as f:\n",
    "        full_dataset_shaps, full_dataset_shaps_3d, shap_explainer = pickle.load(f)\n",
    "x_train_std_display = x_train_std.copy()\n",
    "x_train_std_display = x_train_std_display.rename(columns=label_vec)\n",
    "\n",
    "#Using column order of x_train_std\n",
    "#reorder columns of x_train\n",
    "x_train_display = x_train.copy()\n",
    "x_train_display = x_train_display[x_train_std.columns]\n",
    "x_train_display = x_train_display.rename(columns=label_vec)\n",
    "\n",
    "\n",
    "# Create figure and plot\n",
    "plt.figure()\n",
    "shap_plot = shap.summary_plot(full_dataset_shaps, x_train_display, max_display=10, show = False)\n",
    "# Change x-axis label\n",
    "ax = plt.gca()\n",
    "\n",
    "for artist in ax.collections:\n",
    "    artist._sizes = [0.5]  # or try an even smaller number like 0.5\n",
    "# Adjust subplot parameters\n",
    "plt.subplots_adjust(left=.1, right=.6)\n",
    "# Save the plot\n",
    "plt.savefig(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_beeswarm_plot_{feature_perturbation_version}.png', \n",
    "            bbox_inches='tight', \n",
    "            dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Barplot all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Do Shap bar plot\n",
    "print(f'Getting from {FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl')\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl', 'rb') as f:\n",
    "        full_dataset_shaps, full_dataset_shaps_3d, shap_explainer = pickle.load(f)\n",
    "x_train_std_display = x_train_std.copy()\n",
    "x_train_std_display = x_train_std_display.rename(columns=label_vec)\n",
    "\n",
    "\n",
    "#Using column order of x_train_std\n",
    "#reorder columns of x_train\n",
    "x_train_display = x_train.copy()\n",
    "x_train_display = x_train_display[x_train_std.columns]\n",
    "x_train_display = x_train_display.rename(columns=label_vec)\n",
    "\n",
    "# Create figure and plot\n",
    "plt.figure()\n",
    "shap.summary_plot(full_dataset_shaps, x_train_display, plot_type=\"bar\", max_display=200, show=False, show_values_in_legend=True)\n",
    "# Change x-axis label\n",
    "# Adjust subplot parameters\n",
    "plt.subplots_adjust(left=.1, right=.6)\n",
    "plt.gca().set_xlabel('mean(|SHAP value|)')\n",
    "# Save the plot\n",
    "plt.savefig(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_bar_plot_all_{feature_perturbation_version}.png', \n",
    "            bbox_inches='tight', \n",
    "            dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Beeswarm all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Beeswarm plot\n",
    "print(f'Getting from {FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl')\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl', 'rb') as f:\n",
    "        full_dataset_shaps, full_dataset_shaps_3d, shap_explainer = pickle.load(f)\n",
    "x_train_std_display = x_train_std.copy()\n",
    "x_train_std_display = x_train_std_display.rename(columns=label_vec)\n",
    "\n",
    "#Using column order of x_train_std\n",
    "#reorder columns of x_train\n",
    "x_train_display = x_train.copy()\n",
    "x_train_display = x_train_display[x_train_std.columns]\n",
    "x_train_display = x_train_display.rename(columns=label_vec)\n",
    "\n",
    "\n",
    "# Create figure and plot\n",
    "plt.figure()\n",
    "shap_plot = shap.summary_plot(full_dataset_shaps, x_train_display, max_display=200, show = False)\n",
    "# Change x-axis label\n",
    "ax = plt.gca()\n",
    "\n",
    "for artist in ax.collections:\n",
    "    artist._sizes = [0.5]  # or try an even smaller number like 0.5\n",
    "# Adjust subplot parameters\n",
    "plt.subplots_adjust(left=.1, right=.6)\n",
    "# Save the plot\n",
    "plt.savefig(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_beeswarm_plot_all_{feature_perturbation_version}.png', \n",
    "            bbox_inches='tight', \n",
    "            dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shap interaction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Getting from {FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl')\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl', 'rb') as f:\n",
    "        full_dataset_shaps, full_dataset_shaps_3d, shap_explainer = pickle.load(f)\n",
    "\n",
    "#get shap interaction values (TAKES TIME)\n",
    "\n",
    "shap_interactions = shap_explainer.shap_interaction_values(x_train_std)\n",
    "\n",
    "#pickle them\n",
    "print(\"Pickling shap interaction values\")\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_interaction_values_{feature_perturbation_version}.pkl', 'wb') as f:\n",
    "        pickle.dump(shap_interactions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependence charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup for all charts\n",
    "\n",
    "print(f'Getting from {FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl')\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl', 'rb') as f:\n",
    "        full_dataset_shaps, full_dataset_shaps_3d, shap_explainer = pickle.load(f)\n",
    "x_train_std_display = x_train_std.copy()\n",
    "x_train_std_display = x_train_std_display.rename(columns=label_vec)\n",
    "\n",
    "feature_importance = np.abs(full_dataset_shaps).mean(0)\n",
    "feature_names = x_train_std_display.columns  # or X_train.columns depending on what you're using\n",
    "top_10_idx = np.argsort(feature_importance)[-10:]  # Get indices of top 10 features\n",
    "top_10_features = feature_names[top_10_idx]\n",
    "top_10_columnNames = x_train_std.columns[top_10_idx]\n",
    "print(top_10_features)\n",
    "#print(top_10_columnNames)\n",
    "\n",
    "#Using column order of x_train_std\n",
    "#reorder columns of x_train\n",
    "x_train_display = x_train.copy()\n",
    "x_train_display = x_train_display[x_train_std.columns]\n",
    "x_train_display_with_features = x_train_display.rename(columns=label_vec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/top10dependence', exist_ok=True)\n",
    "\n",
    "for i in range(len(top_10_features)):\n",
    "        column_label = top_10_columnNames[i]\n",
    "        column_to_plot = top_10_features[i]\n",
    "        if len(x_train_display_with_features[column_to_plot].unique()) < 5:\n",
    "                jitter = 0.2\n",
    "                dotsize = 4\n",
    "                print(f\"Jittering for {column_to_plot}\")\n",
    "        else: \n",
    "                jitter = 0\n",
    "                dotsize = 8\n",
    "        print(column_to_plot)\n",
    "        print(x_train_display_with_features[column_to_plot].dtype)\n",
    "        plt.figure()\n",
    "        shap.dependence_plot(column_to_plot, full_dataset_shaps, x_train_display_with_features, alpha = 0.5, dot_size=dotsize, show=False, x_jitter=jitter)\n",
    "        plt.axhline(y=0, color='black', linestyle=':', linewidth=1)        \n",
    "        plt.savefig(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/top10dependence/shap_dependence_{column_label}_{feature_perturbation_version}.png', \n",
    "                                bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 nocolor\n",
    "os.makedirs(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/top10dependence_noColor', exist_ok=True)\n",
    "\n",
    "for i in range(len(top_10_features)):\n",
    "        column_label = top_10_columnNames[i]\n",
    "        column_to_plot = top_10_features[i]\n",
    "        if len(x_train_display_with_features[column_to_plot].unique()) < 5:\n",
    "                jitter = 0.2\n",
    "                dotsize = 4\n",
    "                print(f\"Jittering for {column_to_plot}\")\n",
    "        else: \n",
    "                jitter = 0\n",
    "                dotsize = 8\n",
    "        print(column_to_plot)\n",
    "        print(x_train_display_with_features[column_to_plot].dtype)\n",
    "        plt.figure()\n",
    "        shap.dependence_plot(column_to_plot, full_dataset_shaps, x_train_display_with_features, alpha = 0.5, dot_size=dotsize, show=False, x_jitter=jitter, interaction_index=None)\n",
    "        plt.axhline(y=0, color='black', linestyle=':', linewidth=1)        \n",
    "        plt.savefig(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/top10dependence_noColor/shap_dependence_{column_label}_{feature_perturbation_version}.png', \n",
    "                                bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Numerical Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "columns_to_plot = [\"Age at Procedure\", \"Body Mass Index (BMI)\", \"OR Duration (Minutes)\"]\n",
    "column_labels = [\"age\", \"bmi\", \"ORdur\"]\n",
    "\n",
    "for i in range(len(columns_to_plot)):\n",
    "    column_label = column_labels[i]\n",
    "    column_to_plot = columns_to_plot[i]\n",
    "    plt.figure()\n",
    "    shap.dependence_plot(column_to_plot, full_dataset_shaps, x_train_display_with_features, alpha = 0.5, dot_size=8, show=False)\n",
    "    plt.axhline(y=0, color='black', linestyle=':', linewidth=1)\n",
    "    plt.savefig(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_dependence_{column_label}_{feature_perturbation_version}.png', \n",
    "                bbox_inches='tight', \n",
    "                dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Additional Specific Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion Beta Blocker, color cardiac\n",
    "if procedure_of_interest == \"Fusion\":\n",
    "\n",
    "    #make directory for these\n",
    "    os.makedirs(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/cardiacs_colored_beta', exist_ok=True)\n",
    "    cardiac_comorbidities = {\"Elix: Cardiac Arrhythmia\": \"arrythmia\", \n",
    "                            \"Elix: Congestive Heart Failure\": \"CHF\", \n",
    "                            \"Elix: Valvular Disease\": \"Valvular_Disease\",\n",
    "                            \"Elix: Complicated Hypertension\": \"HTN_Compl\", \n",
    "                            \"Elix: Uncomplicated Hypertension\": \"HTN_Uncompl\"\n",
    "    }\n",
    "    jitter = 0.2\n",
    "    dotsize = 4\n",
    "\n",
    "    for (key, value) in cardiac_comorbidities.items():\n",
    "        plt.figure()\n",
    "        shap.dependence_plot(key, full_dataset_shaps, x_train_display_with_features, alpha = 0.5, dot_size=dotsize, show=False,\n",
    "                            interaction_index = \"Preoperative Beta Blocker Use (90 Days)\", x_jitter = jitter)\n",
    "        # Add horizontal dotted line at y=0\n",
    "        plt.axhline(y=0, color='black', linestyle=':', linewidth=1)\n",
    "        plt.savefig(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/cardiacs_colored_beta/shap_dependence_{value}_{feature_perturbation_version}.png', \n",
    "                    bbox_inches='tight', \n",
    "                    dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardiac_comorbidities = [\"elix_cardiac_arrhythmia\", \"elix_congestive_heart_failure\", \"elix_valvular_disease\", \"elix_hypertension_complicated\", \"elix_hypertension_uncomplicated\"]\n",
    "x_train_cardiac = x_train.copy()\n",
    "x_train_cardiac['cardiac_comorbidities'] = x_train_cardiac[cardiac_comorbidities].any(axis=1).astype(\"Int64\")\n",
    "\n",
    "# Create the contingency table with descriptive labels\n",
    "beta_blocker_cardiac_contingency = pd.crosstab(\n",
    "    x_train_cardiac['cardiac_comorbidities'], \n",
    "    x_train_cardiac[\"preop_med_90days_beta_blocker\"],\n",
    "    margins=True,  # This adds row and column totals\n",
    "    margins_name='Total'\n",
    ")\n",
    "\n",
    "# Rename the index and columns for clarity\n",
    "beta_blocker_cardiac_contingency.index = ['No Cardiac Disease', 'Has Cardiac Disease', 'Total']\n",
    "beta_blocker_cardiac_contingency.columns = ['No Beta Blocker', 'On Beta Blocker', 'Total']\n",
    "\n",
    "# Optional: Add a title\n",
    "print(\"Contingency Table: Cardiac Disease vs Beta Blocker Use\")\n",
    "print(beta_blocker_cardiac_contingency)\n",
    "\n",
    "beta_blocker_cardiac_contingency.to_csv(f\"{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/cardiacs_colored_beta/beta_blocker_cardiac_contingency.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "table_no_margins = beta_blocker_cardiac_contingency.iloc[:-1,:-1]\n",
    "print(table_no_margins)\n",
    "chi2, p_value, dof, expected = chi2_contingency(table_no_margins)\n",
    "print(f\"Chi-square statistic: {chi2}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "print(f\"Expected frequencies: {expected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explainer Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainerdashboard import ClassifierExplainer, ExplainerDashboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/modelpickle.pkl', 'rb') as f:\n",
    "    full_model_pickled = pickle.load(f)\n",
    "\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/trainingdata.pkl', 'rb') as g:\n",
    "    training_data = pickle.load(g)\n",
    "\n",
    "print(f'Getting from {FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl')\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl', 'rb') as f:\n",
    "        full_dataset_shaps, full_dataset_shaps_3d, shap_explainer = pickle.load(f)\n",
    "\n",
    "#unpickle\n",
    "print(f\"Unpickling from {FullDataset_model}, {procedure_of_interest}\")\n",
    "RF_cvmodel, y_pred, y_prob_vec, = full_model_pickled\n",
    "x_train, y_train, x_train_features_long, n_features, x_cols, x_train_std = training_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make and set shaps for explainer\n",
    "\n",
    "dashboardExplainer = ClassifierExplainer(model=RF_cvmodel.best_estimator_, X=x_train, y=y_train, shap='tree', model_output='raw',\n",
    "                                         target='1_year_ltc_postlaminectomy_syndrome', index_name=\"PtIndex\")\n",
    "dashboardExplainer.set_shap_values([-0.5, 0.5], [-full_dataset_shaps, full_dataset_shaps])\n",
    "\n",
    "explainerLocation = f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/explainer.joblib'\n",
    "dashboardExplainer.dump(explainerLocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numeric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dashboard Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainerLocation = f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/explainer.joblib'\n",
    "\n",
    "explainer =  ClassifierExplainer.from_file(explainerLocation)\n",
    "dashboard = ExplainerDashboard(\n",
    "    explainer,\n",
    "    tabs=['whatif'],  # Show only the What-If tab\n",
    "    title=\"What-If Analysis Dashboard\"\n",
    ")\n",
    "# Save the dashboard to a pickle file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainLocation = f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/'\n",
    "dashboard.to_yaml(mainLocation+\"dashboard.yaml\", explainerfile=\"explainer.joblib\" , dump_explainer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = ExplainerDashboard.from_config(mainLocation+\"explainer.joblib\", mainLocation+\"dashboard.yaml\")\n",
    "app = db.flask_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ngrok\n",
    "# Expose local port using ngrok\n",
    "public_url = ngrok.connect(805)  # Expose port 8050\n",
    "print(f\"Dashboard is live at: {public_url}\")\n",
    "\n",
    "# Run the dashboard\n",
    "dashboard.run(port=805)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do all repetitions\n",
    "\n",
    "for rep in repetitions:\n",
    "    preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(dum_df, y)):\n",
    "        # Create all the different train_test splits\n",
    "        x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "        x_test_features_long, n_features, x_cols, x_train_std, x_test_std = set_train_test(dum_df= dum_df, y=y, train_index=train_index, test_index=test_index, rep=rep, preprocessor=preprocessor)\n",
    "\n",
    "        for model in model_set:\n",
    "            \n",
    "            '''\n",
    "            print(procedure)\n",
    "            print(feature)\n",
    "            print(outcome)\n",
    "            print(rep)\n",
    "            print(i)\n",
    "            \n",
    "            print(model)\n",
    "            print(time.strftime('%X %x %Z'))\n",
    "            '''\n",
    "            if model == \"ASA\":\n",
    "                asa_model_fitted, y_pred, y_prob_vec = ASA_model(x_train, x_test, y_train, rep)\n",
    "\n",
    "            elif model == \"ASA_categorical\":\n",
    "                y_pred, y_prob_vec_two = ASA_categorical_model(x_test=x_test)\n",
    "                print(y_prob_vec_two)\n",
    "                        \n",
    "            elif model == \"ENet\":\n",
    "                ENet_model_fitted, y_pred, y_prob_vec, shap_values = ENet_model(outcome, preprocessor, x_train, y_train,\n",
    "                                                                                x_test, x_train_std, x_test_std, rep)    \n",
    "            elif model == \"XGBoost\":\n",
    "                XGBoost_model_fitted, y_pred, y_prob_vec, shap_values = XGBoost_model(outcome, preprocessor, x_train,\n",
    "                                                                              y_train, x_test, x_train_std, x_test_std,\n",
    "                                                                              rep)\n",
    "            \n",
    "            elif model == \"RF\": \n",
    "                \n",
    "                   \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_results_output = pd.concat(feature_results, ignore_index = True)\n",
    "feature_results_output.to_csv(\"thumb_arthro_features_3_11_23_partial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(np.repeat(row, len(x_cols)))\n",
    "print(len(shap_values_row))\n",
    "print(len(temp_feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_features_shap.to_csv(\"tester_shap.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    output_file_results.to_csv(file_name_results)\n",
    "    \n",
    "    \n",
    "    feature_file_results = pd.concat(feature_results)\n",
    "    feature_file_results = feature_file_results[feature_file_results['Procedure'] == procedure]\n",
    "    feature_file_results.to_csv(file_name_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_plot_results.to_csv(\"auc_results_health_util_11_7_22.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(output_file_results)\n",
    "np.median(output_file_results['MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shap_features_row)\n",
    "\n",
    "#shap_features_row.to_csv(\"NN_feature_test.csv\")\n",
    "\n",
    "summarized_features_shap = shap_features_row.groupby(['Feature_Name']).agg(\n",
    "    Feature_Mean_Abs = ('Feature_Value_Abs','mean'),   \n",
    "    Feature_Mean_Real = ('Feature_Value_Real','mean') \n",
    ").reset_index()\n",
    "\n",
    "print(summarized_features_shap)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install joblib==1.1.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(feature_results)\n",
    "#print(all_results)\n",
    "#feature_results.to_csv(\"feature_test_1_30_21.csv\")\n",
    "partial_output_results = pd.concat(all_results)\n",
    "partial_output_features = pd.concat(feature_results)\n",
    "partial_output_results.to_csv(\"partial_acdf_results_5_31_22.csv\")\n",
    "partial_output_features.to_csv(\"partial_acdf_features_5_31_22.csv\")\n",
    "#hyperparam_results.to_csv(\"all_results_acdf_cbc_bmp_hyperparam_lasso_brf_xgb_2_6_22_updated.csv\")\n",
    "\n",
    "print(feature_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_output_file_results = pd.concat(all_results)\n",
    "partial_output_file_results = partial_output_file_results[partial_output_file_results['Procedure'] == \"PLF\"]\n",
    "partial_output_file_results.to_csv(\"partial_plf_results_5_31_22.csv\")\n",
    "    \n",
    "    \n",
    "partial_feature_file_results = pd.concat(feature_results)\n",
    "partial_feature_file_results = partial_feature_file_results[partial_feature_file_results['Procedure'] == \"PLF\"]\n",
    "partial_feature_file_results.to_csv(\"partial_plf_features_5_31_22.csv\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outcome)\n",
    "print(procedure)\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_results = all_results.groupby(['Outcome', 'Features', 'Model']).agg(\n",
    "    WF1_Mean = ('W_F1','mean'),\n",
    "    WF1_SD = ('W_F1', 'std'),\n",
    "    AUC_Mean = ('AUC', 'mean'),\n",
    "    AUC_SD = ('AUC', 'std'),\n",
    "    Acc_Mean = ('Accuracy', 'mean'),\n",
    "    Acc_SD = ('Accuracy', 'std'),\n",
    "    BAcc_Mean = ('Balanced_Accuracy', 'mean'),\n",
    "    BAcc_SD = ('Balanced_Accuracy', 'std'),\n",
    "    Log_Loss_Mean = ('Log-Loss', 'mean'),\n",
    "    Log_Loss_SD = ('Log-Loss', 'std'),\n",
    "    Precision_Neg_Mean = ('Precision_Neg', 'mean'),\n",
    "    Precision_Neg_SD = ('Precision_Neg', 'std'),\n",
    "    Recall_Neg_Mean = ('Recall_Neg', 'mean'),\n",
    "    Recall_Neg_SD = ('Recall_Neg', 'std'),\n",
    "    Precision_Pos_Mean = ('Precision_Pos', 'mean'),\n",
    "    Precision_Pos_SD = ('Precision_Pos', 'std'),\n",
    "    Recall_Pos_Mean = ('Recall_Pos', 'mean'),\n",
    "    Recall_Pos_SD = ('Recall_Pos', 'std'),\n",
    "    n_Mean = ('n', 'mean'),\n",
    "    n_SD = ('n', 'std'),\n",
    "    label_n_Mean = ('label_n', 'mean'),\n",
    "    label_n_SD = ('label_n', 'std')\n",
    "    \n",
    "    \n",
    ").reset_index()\n",
    "\n",
    "summarized_results.to_csv(\"wnd_dehis_summarized_lasso_brf_xgb_2_6_22_updated.csv\")\n",
    "\n",
    "print(summarized_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_coef)\n",
    "print(feature_coef_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_dat = pd.read_csv(r\"Results/LASSO/pre_op_features_2_1_22.csv\", sep=',')\n",
    "feature_dat = pd.read_csv(r\"wnd_dehis_features_lasso_brf_xgb_2_3_22_updated.csv\", sep=',')\n",
    "\n",
    "\n",
    "feature_dat['Feature_Value_Real'] = feature_dat['Feature_Value_Real'].str.strip('[]').astype(float) # uncomment and run this with lasso\n",
    "\n",
    "summarized_features = feature_dat.groupby(['Outcome', 'Model', 'Feature_Name']).agg(\n",
    "    Feature_Value_Mean = ('Feature_Value_Real', 'mean'),\n",
    "    Feature_Value_SD = ('Feature_Value_Real', 'std'),\n",
    "    \n",
    ").reset_index()\n",
    "\n",
    "summarized_features.to_csv(\"wnd_dehiscence_xgb_features_summarized_2_3_22_updated.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myConda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
