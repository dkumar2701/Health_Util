{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the key packages\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import sklearn\n",
    "import hyperopt\n",
    "from hyperopt import hp\n",
    "import imblearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.calibration as cal\n",
    "import xgboost as xgb\n",
    "import sklearn.utils.class_weight as wt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from pathlib import Path\n",
    "from sklearn import datasets, metrics, model_selection, svm\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import skopt\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "import multiprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, utils, backend as K, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "#tensorflow.compat.v1.disable_v2_behavior() \n",
    "import random\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from numpy.ma import MaskedArray\n",
    "import sklearn.utils.fixes\n",
    "\n",
    "import miceforest as mf\n",
    "\n",
    "sklearn.utils.fixes.MaskedArray = MaskedArray\n",
    "\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configure the logging module\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rays and tune imports\n",
    "from tune_sklearn import TuneSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USING PYTHON 3.11.0\n",
    "print(sklearn.__version__)\n",
    "print(shap.__version__)\n",
    "print(tf.__version__)\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(xgb.__version__)\n",
    "print(tf.executing_eagerly())\n",
    "\n",
    "'''\n",
    "Should be: \n",
    "1.5.2\n",
    "0.46.0\n",
    "2.16.2\n",
    "2.2.2\n",
    "1.26.4\n",
    "True\n",
    "'''\n",
    "\n",
    "'''\n",
    "SHOUD BE THE FOLLOWING WITH 3.11.0\n",
    "1.5.2\n",
    "0.46.0\n",
    "2.16.2\n",
    "2.2.3\n",
    "1.23.5\n",
    "2.1.1\n",
    "True\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Initializing dataframes to store the results\n",
    "\n",
    "\n",
    "all_results = []\n",
    "\n",
    "\n",
    "# hyperparam_results = pd.DataFrame(\n",
    "#     {\n",
    "#         \"Procedure\": [],\n",
    "#         \"Outcome\": [],\n",
    "#         \"Features\": [],\n",
    "#         \"Model\": [],\n",
    "#         \"Rep\": [],\n",
    "#         \"Hyp_Name\": [],\n",
    "#         \"Hyp_Value\": []\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "feature_results = []\n",
    "\n",
    "auc_plot_results = []\n",
    "\n",
    "\n",
    "# Areas which below pipeline will iterate through -- CHANGE THIS BASED ON NEED\n",
    "\n",
    "\n",
    "#binary_outcomes = np.array([\"readmission_binary\", \"major_med_comp\", \"extended_los\", \"returnor\", \"wnd_related_comp\"])\n",
    "#binary_outcomes = np.array([\"readmission_binary\"])\n",
    "#binary_outcomes = np.array([\"returnor\", \"any_med_comp_no_wnd\", \"any_med_comp_wnd\", \"any_comp_overall\"])\n",
    "binary_outcomes = [\"High_Health_Utilizer\"]\n",
    "\n",
    "#continuous_outcomes = np.array([\"outpatient_resource_sum\", \"los_days\"])\n",
    "#continuous_outcomes = np.array(['los_days'])\n",
    "\n",
    "continuous_outcomes = []\n",
    "\n",
    "\n",
    "outcomes = binary_outcomes + continuous_outcomes\n",
    "\n",
    "#procedures = [\"Microdisc\", \"Foraminotomy\", \"Laminectomy\", \"AXDLIF\", \"PLF\", \"PTLIF\"]\n",
    "procedures = [\"Fusion\", \"Decompression\"]\n",
    "\n",
    "\n",
    "#features = [\"Spine_Institution\", \"Spine_NSQIP\", \"Peripheral_NSQIP\"]\n",
    "#features = [\"Spine_Institution\"]\n",
    "#features = [\"Peripheral_NSQIP\"]\n",
    "#features = [\"PLS_features\"]\n",
    "features = [\"Health_Util_Features\"]\n",
    "feature = features[0]\n",
    "\n",
    "model_set = [\"RF\", \"ENet\", \"XGBoost\", \"NN\", \"ASA\", \"Dummy\"]\n",
    "#model_set = [\"RF\"]\n",
    "\n",
    "#model_set = [\"XGBoost\"]\n",
    "#model_set = [\"Dummy\"]\n",
    "\n",
    "\n",
    "\n",
    "repetitions = list(range(10)) #TODO: Change to range(10)\n",
    "date = \"01_14_25\"\n",
    "impute_iterations = 2 #TODO CHANGE TO 2\n",
    "tunesearch_iterations = 10 #TODO: Switch to 10\n",
    "Get_shaps = False #TODO: DO I WANT SHAPS?\n",
    "procedure_of_interest = \"Fusion\" #TODO: Change procedure-of-interest\n",
    "pickle_folder_name = \"NoLabs\" # Change when doing a different pickling #NoLabs\n",
    "FullDataset_model = \"RF\"\n",
    "feature_perturbation_version = \"tree_path_dependent\" #TODO: For full dataset model RF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_random_seed(rep):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    os.environ['PYTHONHASHSEED']=str(rep)\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "    tf.random.set_seed(rep)\n",
    "    np.random.seed(rep)\n",
    "    random.seed(rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(procedure):\n",
    "    readdata = pd.read_csv(r\"122124_Spine_Reports.csv\", sep=',')\n",
    "    \n",
    "    if procedure == \"Fusion\":\n",
    "        readdata = readdata[\n",
    "            (readdata['cpt_thoracolumbar_sacro_arthrodesis'] == True) &\n",
    "            (readdata['cohort_query_lumbar'] == True)\n",
    "            ]\n",
    "    elif procedure == \"Decompression\":\n",
    "        readdata = readdata[\n",
    "            (readdata['cpt_thoracolumbar_sacro_arthrodesis'] == False) & \n",
    "            (readdata['cohort_query_spinal_decompression'] == True) & \n",
    "            (readdata['cohort_query_lumbar'] == True)\n",
    "        ]\n",
    "\n",
    "\n",
    "    readdata = readdata.reset_index(drop=True)\n",
    "    return readdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preop_to_binary(input_df):\n",
    "    df = input_df.copy()\n",
    "    # Get all columns that start with \"preop_med_\"\n",
    "    preop_med_cols = [col for col in df.columns if col.startswith('preop_med_')]\n",
    "    print(f\"There are {len(preop_med_cols)} preop columns\")\n",
    "\n",
    "    # Check for missing values first\n",
    "    missing_values = {col: df[col].isna().sum() \n",
    "                    for col in preop_med_cols \n",
    "                    if df[col].isna().any()}\n",
    "\n",
    "    if missing_values:\n",
    "        raise ValueError(f\"Missing values found in the following columns: {missing_values}\")\n",
    "\n",
    "    # Convert to boolean if no missing values found\n",
    "    for col in preop_med_cols:\n",
    "        # Store original values for verification\n",
    "        original_values = df[col].value_counts()\n",
    "        \n",
    "        # Convert: 0 -> False, >=1 -> True\n",
    "        df[col] = df[col] > 0\n",
    "        \n",
    "        # Print verification of the conversion\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        print(\"Original value counts:\")\n",
    "        print(original_values)\n",
    "        print(\"New value counts:\")\n",
    "        print(df[col].value_counts())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_columns_remove_rows(input_df):\n",
    "\n",
    "    df = input_df.copy()\n",
    "    # Recode categorical columns\n",
    "        # anesthesia_type\n",
    "    df['anesthesia_type_General'] = df['anesthesia_type'].apply(\n",
    "        lambda x: 1 if pd.notna(x) and str(x).upper() == 'GENERAL'\n",
    "                  else (0 if pd.notna(x)  # if it's not NaN and not 'GENERAL', return 0\n",
    "                        else np.nan)  # if it's NaN, return np.nan\n",
    "    )\n",
    "    df['anesthesia_type_General'] = df['anesthesia_type_General'].astype('Int64')\n",
    "    \n",
    "    #procedure_setting\n",
    "    df['procedure_setting_Inpatient'] = df['procedure_setting'].apply(lambda x: 1 if str(x).upper() == 'INPATIENT' \n",
    "                                            else (0 if str(x).upper() == 'OUTPATIENT' \n",
    "                                            else np.nan))\n",
    "    df['procedure_setting_Inpatient'] = df['procedure_setting_Inpatient'].astype('Int64')\n",
    "    # Recode gender into new binary column\n",
    "    df['gender_female'] = df['gender'].apply(lambda x: 1 if str(x).upper() == 'F' \n",
    "                                           else (0 if str(x).upper() == 'M' \n",
    "                                           else np.nan))\n",
    "    df['gender_female'] = df['gender_female'].astype('Int64')\n",
    "\n",
    "    # add allograft and autograft columns\n",
    "    df['cpt_allograft'] = df['procedure_codes'].str.contains('20930|20931').astype(bool)\n",
    "    df['cpt_autograft'] = df['procedure_codes'].str.contains('20936|20937|20938').astype(bool)\n",
    "\n",
    "    # Anterior approach codes\n",
    "    df['cpt_anterior_approach'] = df['procedure_codes'].str.contains(\n",
    "        '22556|22558|22586|22808|22810|22812'\n",
    "    ).astype(bool)\n",
    "\n",
    "    # Lateral approach codes\n",
    "    df['cpt_lateral_approach'] = df['procedure_codes'].str.contains(\n",
    "        '22533|22534'\n",
    "    ).astype(bool)\n",
    "\n",
    "    # Posterior approach codes\n",
    "    df['cpt_posterior_approach'] = df['procedure_codes'].str.contains(\n",
    "        '22610|22612|22800|22802|22804|22630|22632|22633|22634|27279|27280'\n",
    "    ).astype(bool)\n",
    "\n",
    "    # Convert surgery_start_datetime to datetime type if it isn't already\n",
    "    df['surgery_start_datetime_date'] = pd.to_datetime(df['surgery_start_datetime'])\n",
    "    df['surgery_end_datetime_date'] = pd.to_datetime(df['surgery_end_datetime'])\n",
    "    df['patient_in_or_datetime_date'] = pd.to_datetime(df['patient_in_or_datetime'])\n",
    "    df['patient_out_or_datetime_date'] = pd.to_datetime(df['patient_out_or_datetime'])\n",
    "    df['anesthesia_start_datetime_date'] = pd.to_datetime(df['anesthesia_start_datetime'])\n",
    "    df['anesthesia_stop_datetime_date'] = pd.to_datetime(df['anesthesia_stop_datetime'])\n",
    "    \n",
    "    # Create date filters\n",
    "    start_date = pd.to_datetime('2003-01-01')\n",
    "    end_date = pd.to_datetime('2022-10-01')\n",
    "    \n",
    "    df = df[\n",
    "        # Date conditions\n",
    "        (df['surgery_start_datetime_date'] >= start_date) & \n",
    "        (df['surgery_start_datetime_date'] < end_date) &\n",
    "        # Age filter - exclude patients under 18\n",
    "        (df['age_at_procedure'] >= 18) &\n",
    "        # Previous conditions (negated)\n",
    "        ~(df['spine_preop_tumor'] | \n",
    "          df['spine_preop_trauma'] | \n",
    "          df['spine_preop_infection'] |\n",
    "          df['cpt_tumor'] |\n",
    "          df['cpt_trauma'] | \n",
    "          df['spine_preop_curvature'] |\n",
    "          df['cpt_deformity']|\n",
    "          df['cpt_infection'])\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "    # Remove neg los patient 1338489,\"2012-05-02 09:43:00\"\n",
    "    df = df[~((df['ir_id'] == 1338489) & \n",
    "                   (df['surgery_start_datetime'] == \"2012-05-02 09:43:00\"))]\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    ### Clean BMI: Make NA for >100 and =0\n",
    "    df.loc[(df['BMI'] > 100) | (df['BMI'] == 0), 'BMI'] = np.nan\n",
    "\n",
    "    ### Clean Anesthesia: Make NA for >=20\n",
    "    df.loc[df['anesthesia_duration_hours'] >= 20, 'anesthesia_duration_hours'] = np.nan\n",
    "\n",
    "\n",
    "    # Make columns in hours and minutes for surgery length\n",
    "    # Calculate lengths\n",
    "    df['OR_length_hours'] = ((df['patient_out_or_datetime_date'] - \n",
    "                                df['patient_in_or_datetime_date']).dt.total_seconds() / 3600).round()\n",
    "    df['OR_length_minutes'] = ((df['patient_out_or_datetime_date'] - \n",
    "                                    df['patient_in_or_datetime_date']).dt.total_seconds() / 60).round()\n",
    "\n",
    "    df['anesthesia_length_hours'] = ((df['anesthesia_stop_datetime_date'] - \n",
    "                                    df['anesthesia_start_datetime_date']).dt.total_seconds() / 3600).round()\n",
    "    df['anesthesia_length_minutes'] = ((df['anesthesia_stop_datetime_date'] - \n",
    "                                        df['anesthesia_start_datetime_date']).dt.total_seconds() / 60).round()\n",
    "    \n",
    "    df['surgery_length_hours'] = ((df['surgery_end_datetime_date'] -\n",
    "                                    df['surgery_start_datetime_date']).dt.total_seconds() / 3600).round()\n",
    "    df['surgery_length_minutes'] = ((df['surgery_end_datetime_date'] -\n",
    "                                    df['surgery_start_datetime_date']).dt.total_seconds() / 60).round()\n",
    "\n",
    "    # Handle missing values\n",
    "    OR_missing = df['patient_in_or_datetime_date'].isna() | df['patient_out_or_datetime_date'].isna()\n",
    "    anesthesia_missing = df['anesthesia_start_datetime_date'].isna() | df['anesthesia_stop_datetime_date'].isna()\n",
    "    surgery_missing = df['surgery_start_datetime_date'].isna() | df['surgery_end_datetime_date'].isna()\n",
    "\n",
    "    df.loc[OR_missing, ['OR_length_hours', 'OR_length_minutes']] = np.nan\n",
    "    df.loc[anesthesia_missing, ['anesthesia_length_hours', 'anesthesia_length_minutes']] = np.nan\n",
    "    df.loc[surgery_missing, ['surgery_length_hours', 'surgery_length_minutes']] = np.nan\n",
    "\n",
    "    # Convert to integer type (while preserving NaN values)\n",
    "    length_columns = ['OR_length_hours', 'OR_length_minutes',\n",
    "                    'anesthesia_length_hours', 'anesthesia_length_minutes',\n",
    "                    'surgery_length_hours', 'surgery_length_minutes']\n",
    "    df[length_columns] = df[length_columns].astype('Int64')  # Int64 allows for NaN values\n",
    "\n",
    "     ### Clean Anesthesia: Make NA for >=20\n",
    "    df.loc[df['anesthesia_length_hours'] >= 20, 'anesthesia_length_hours'] = np.nan\n",
    "    df.loc[df['anesthesia_length_minutes'] >= 20*60, 'anesthesia_length_minutes'] = np.nan\n",
    "\n",
    "    ### clean surgery: make NA for > 1000 hours or eqivalent minutes\n",
    "    df.loc[df['surgery_length_hours'] >= 20, 'surgery_length_hours'] = np.nan\n",
    "    df.loc[df['surgery_length_minutes'] >= 20*60, 'surgery_length_minutes'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_labs_90(df):\n",
    "\n",
    "    input_df = df.copy()\n",
    "\n",
    "    # Create columns lists for days_before\n",
    "    CBC_cols = [\"CBC_MONOCYTES\", \"CBC_NEUTROPHILS\", \"CBC_BASOPHILS\", \"CBC_PLATELET_COUNT\",\n",
    "                    \"CBC_WBC_COUNT\", \"CBC_HEMOGLOBIN\", \"CBC_RBC_COUNT\",\n",
    "                    \"CBC_RDW\", \"CBC_HEMATOCRIT\", \"CBC_MCH\", \"CBC_MCHC\",\n",
    "                    \"CBC_ABSOLUTE_LYMPHOCYTES\", \"CBC_ABSOLUTE_NEUTROPHILS\",\n",
    "                    \"CBC_LYMPHOCYTE\", \"CBC_EOSINOPHILS\", \"CBC_ABSOLUTE_EOSINOPHILS\",\n",
    "                    \"CBC_ABSOLUTE_BASOPHILS\", \"CBC_ABSOLUTE_MONOCYTES\"]\n",
    "    \n",
    "    CBC_date_cols = [col + \"_days_before_surgery\" for col in CBC_cols]\n",
    "        \n",
    "    BMP_cols = [\"BMP_POTASSIUM\", \"BMP_CREATININE\", \"BMP_BUN\", \"BMP_CALCIUM\", \"BMP_CHLORIDE\", \n",
    "                    \"BMP_SODIUM\", \"BMP_CO2\", \"BMP_GLUCOSE\"]\n",
    "    BMP_date_cols = [col + \"_days_before_surgery\" for col in BMP_cols]\n",
    "\n",
    "    lab_cols = CBC_cols + BMP_cols\n",
    "    lab_days_before = CBC_date_cols + BMP_date_cols\n",
    "    lab_pairs = [(lab_cols[i], lab_days_before[i]) for i in range(len(lab_cols))]\n",
    "    print(lab_pairs)\n",
    "\n",
    "    def extract_days(x):\n",
    "        if pd.isna(x):\n",
    "            return np.nan\n",
    "        # Extract just the number before \"days\"\n",
    "        try:\n",
    "            return float(str(x).split()[0])\n",
    "        except:\n",
    "            return np.nan\n",
    "    # Process each pair of columns\n",
    "    for lab_col, days_col in lab_pairs:\n",
    "        # Convert the days strings to numbers\n",
    "        days = input_df[days_col].apply(extract_days)\n",
    "\n",
    "        # Create a mask for values > 90 days\n",
    "        mask = days > 90\n",
    "        \n",
    "        # Set the lab values to NaN where mask is True\n",
    "        input_df[lab_col] = input_df[lab_col].mask(mask)\n",
    "\n",
    "\n",
    "    return input_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_columns(data, outcome, pofI):\n",
    "    individual_features_shap_full = []\n",
    "    # Basic demographics = age, sex, race (not present), BMI\n",
    "    basic_demographics = [\"ir_id\", \"surgery_start_datetime\", \"age_at_procedure\", \"gender_female\", \"BMI\"]\n",
    "\n",
    "    #Med hx: include all of the comorbidities with the elix_ prefix. \n",
    "    # Those are based on the Elixhauser comorbidity guidelines and \n",
    "    # are the most comprehensive. We broke out several other frailty\n",
    "    #  tools (CCI, MFI, etc) but these are ultimately duplicative \n",
    "    # and not as comprehensive (i.e. don’t worry about including). \n",
    "    # I do not believe elixhauser has anything on tobacco. \n",
    "    # If ther isn’t, then use validation_fmr_tobacco and \n",
    "    # validation_cur_tobacco.\n",
    "\n",
    "    Medhx = [\"elix_aids_hiv\", \"elix_lymphoma\", \"elix_paralysis\",\n",
    "            \"elix_psychoses\", \"elix_depression\", \"elix_drug_abuse\", \"elix_weight_loss\",\n",
    "            \"elix_coagulopathy\", \"elix_alcohol_abuse\", \"elix_liver_disease\", \"elix_renal_failure\",\n",
    "            \"elix_hypothyroidism\", \"elix_valvular_disease\", \"elix_blood_loss_anemia\",\n",
    "            \"elix_deficiency_anemia\", \"elix_metastatic_cancer\", \"elix_cardiac_arrhythmia\",\n",
    "            \"elix_rheumatoid_arhritis\", \"elix_diabetes_complicated\", \"elix_diabetes_uncomplicated\", \n",
    "            \"elix_congestive_heart_failure\", \"elix_hypertension_complicated\", \"elix_chronic_pulmonary_disease\",\n",
    "            \"elix_solid_tumor_wo_metastasis\", \"elix_hypertension_uncomplicated\", \"elix_other_neurological_disorder\",\n",
    "            \"elix_peripheral vascular_disorder\", \"elix_pulmonary_circulation_disorder\", \"elix_fluid_and_electrolyte_disorders\",\n",
    "            \"elix_peptic_ulcer_disease_excluding_bleeding\", \"validation_cur_tobacco\", \"validation_fmr_tobacco\"]\n",
    "    \n",
    "    #Surg hx: look at the shx_ prefix variables and include those\n",
    "\n",
    "    Surghx = [\"shx_cervical_fusion\", \"shx_cervical_surgery\", \"shx_thoracolumbar_fusion\",\n",
    "                \"shx_thoracolumbar_surgery\", \"shx_unspecified_spine_fusion\", \"shx_unspecified_spine_surgery\"]\n",
    "    \n",
    "    #Spine-specific preop pathology: lumbar stenosis, lumbar spondy, \n",
    "    # lumbar disc disorders, lumbar disc herniation (all binary columns)\n",
    "    SpineSpecific = [\"lumbar_stenosis\", \"lumbar_spondy\", \"lumbar_disc_disorders\",\n",
    "                        \"cervical_disc_diorders\", \"cervical_stenosis\", \"cervical_spondy\",\n",
    "                        \"cervical_disc_herniation\", \"lumbar_disc_herniation\", \"spine_preop_pseudoarthrosis_post_fusion\", \"spine_preop_post_laminectomy_syndrome\"]\n",
    "\n",
    "    #Medication hx: look for preop_med_ suffix. Also just focus on 90\n",
    "    #  days preop for this analysis. Exclude anything with _sorg in the\n",
    "    #  name (that is for a separate validation analysis)\n",
    "\n",
    "    Medicationhx = [\"preop_med_90days_ace_inhibitor\", \"preop_med_90days_arb\", \"preop_med_90days_antidepressant\",\n",
    "                \"preop_med_90days_beta_2_agonist\", \"preop_med_90days_beta_blocker\", \"preop_med_90days_benzodiazepine\",\n",
    "                \"preop_med_90days_immunosuppresant\", \"preop_med_90days_nsaid\", \"preop_med_90days_opioid\", \"preop_med_90days_anti_psychotic\",\n",
    "                \"preop_med_90days_neuromodulator\", \"preop_med_90days_biphosphonate\", \"preop_med_90days_loop_diuretic\",\n",
    "                \"preop_med_90days_thiazide_diuretic\", \"preop_med_90days_cinacalcet\", \"preop_med_90days_insulin\", \n",
    "                \"preop_med_90days_oral_diabetes\", \"preop_med_90days_calcium_supplement\", \"preop_med_90days_vit_d_supplement\"]\n",
    "\n",
    "    #Surgical characteristics: inpatient versus outpatient, type of anesthesia \n",
    "    # (should almost always be general, but a few weird ones here and there), \n",
    "    # OR duration, anesthesia duration, cpt_multilevel, cpt_grafts, \n",
    "    # cpt_instrumentation (tell us more about what was done during the case)\n",
    "\n",
    "    SurgCharsNumeric = [\"asa_class\", \"OR_length_minutes\",\n",
    "                        \"cpt_multilevel\", \"cpt_instrumentation\", \n",
    "                        \"cohort_query_microdisc\", \"anesthesia_type_General\", \"procedure_setting_Inpatient\"]\n",
    "    \n",
    "    Approaches = [\"cpt_anterior_approach\", \"cpt_lateral_approach\", \"cpt_posterior_approach\"]\n",
    "\n",
    "    #Add approach columns if Fusion\n",
    "    if pofI == \"Fusion\":\n",
    "        SurgCharsNumeric = SurgCharsNumeric + Approaches\n",
    "\n",
    "    #SurgCharsCat = [\"anesthesia_type\", \"procedure_setting\"]\n",
    "\n",
    "    # CBC and BMP, all with <50% missing values\n",
    "\n",
    "    CBC_cols = [\"CBC_MONOCYTES\", \"CBC_NEUTROPHILS\", \"CBC_BASOPHILS\", \"CBC_PLATELET_COUNT\",\n",
    "                \"CBC_WBC_COUNT\", \"CBC_HEMOGLOBIN\", \"CBC_RBC_COUNT\",\n",
    "                \"CBC_RDW\", \"CBC_HEMATOCRIT\", \"CBC_MCH\", \"CBC_MCHC\",\n",
    "                \"CBC_ABSOLUTE_LYMPHOCYTES\", \"CBC_ABSOLUTE_NEUTROPHILS\",\n",
    "                \"CBC_LYMPHOCYTE\", \"CBC_EOSINOPHILS\", \"CBC_ABSOLUTE_EOSINOPHILS\",\n",
    "                \"CBC_ABSOLUTE_BASOPHILS\", \"CBC_ABSOLUTE_MONOCYTES\"]\n",
    "    \n",
    "    BMP_cols = [\"BMP_POTASSIUM\", \"BMP_CREATININE\", \"BMP_BUN\", \"BMP_CALCIUM\", \"BMP_CHLORIDE\", \n",
    "                \"BMP_SODIUM\", \"BMP_CO2\", \"BMP_GLUCOSE\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    outcome = [outcome]\n",
    "    ## Set Lab columns\n",
    "    labCols = BMP_cols + CBC_cols\n",
    "    if pickle_folder_name == \"NoLabs\":\n",
    "        all_columns = basic_demographics + Medhx + Surghx + SpineSpecific + Medicationhx + SurgCharsNumeric + outcome\n",
    "    elif pickle_folder_name == \"Labs\":\n",
    "        all_columns = basic_demographics + BMP_cols + CBC_cols + Medhx + Surghx + SpineSpecific + Medicationhx + SurgCharsNumeric + outcome\n",
    "    elif pickle_folder_name == \"Testing\":\n",
    "        all_columns = basic_demographics + Medhx + Surghx + SpineSpecific + Medicationhx + SurgCharsNumeric + outcome\n",
    "    elif pickle_folder_name == \"TestingLabs\":\n",
    "        all_columns = basic_demographics + BMP_cols + CBC_cols + Medhx + Surghx + SpineSpecific + Medicationhx + SurgCharsNumeric + outcome\n",
    "\n",
    "    df = data[all_columns].copy()\n",
    "\n",
    "    ## Fix ASA class\n",
    "    df['asa_class'] = df['asa_class'].replace(0, np.nan)\n",
    "\n",
    "    \n",
    "    #df['asa_above_2'] = np.where(df['asa_class'] >= 3, 1, 0)\n",
    "    \n",
    "\n",
    "    #dum_cols = [\"anesthesia_type\", \"procedure_setting\"]\n",
    "\n",
    "    numeric_features = [\"age_at_procedure\", \"BMI\", \"OR_length_minutes\"]\n",
    "    \n",
    "        # Convert preop columns to boolean\n",
    "    preop_columns = [col for col in df.columns if col.startswith('preop')]\n",
    "    print(f\"{len(preop_columns)} Preop Columns\")\n",
    "\n",
    "    \n",
    "    for col in preop_columns:\n",
    "        trueBefore = sum(df[col] == True)\n",
    "        df[col] = df[col].astype('boolean')\n",
    "        # df[col] = df[col].astype('float')\n",
    "        df[col] = df[col].astype('Int64') # Just convert to Int64\n",
    "        # df[col] = df[col].fillna(0) #fill na as 0 in binary conversion\n",
    "        trueAfter = sum(df[col] == True)\n",
    "        if trueBefore != trueAfter:\n",
    "            raise ValueError(f\"\"\"\n",
    "            Column {col} has different number of True values after conversion!\n",
    "            Before: {trueBefore} True values\n",
    "            After: {trueAfter} True values\n",
    "            Difference: {trueAfter - trueBefore}\n",
    "            \"\"\")\n",
    "        else: \n",
    "            print(\"All preop conversions good!\")\n",
    "    \n",
    "\n",
    "    ## Change these float columns to ints\n",
    "\n",
    "    to_int_cols = [\"age_at_procedure\", 'OR_length_minutes']\n",
    "\n",
    "    for col in to_int_cols:\n",
    "        df[col] = df[col].astype(\"Int64\")\n",
    "\n",
    "    \n",
    "    ## ADD Lab columns to numeric_features\n",
    "    if pickle_folder_name in [\"Labs\", \"TestingLabs\"]:\n",
    "        numeric_features = numeric_features + labCols\n",
    "        print(\"adding lab columns to numeric_features\") \n",
    "        for col in labCols:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            # Ensure the column dtype is float\n",
    "            df[col] = df[col].astype('float')\n",
    "    \n",
    "    #Convert \"object\" columns to categorical (NO CATEGORICAL COLUMNS NOW)\n",
    "    '''\n",
    "    objectcols = SurgCharsCat\n",
    "    for col in objectcols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    '''\n",
    "\n",
    "    # Create ASA df\n",
    "    df_asa = df[['ir_id', 'surgery_start_datetime', 'asa_class', outcome[0]]].copy()\n",
    "    df_asa['asa_class'] = df_asa['asa_class'].astype(\"Int64\")\n",
    "\n",
    "    #remove ASA from df\n",
    "    df = df.drop('asa_class', axis=1)\n",
    "    \n",
    "        \n",
    "    return df, df_asa, numeric_features, individual_features_shap_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new dfs for predictors, preds+dummies, and ys\n",
    "\n",
    "def separate_dfs(df, outcome):\n",
    "    \"\"\"\n",
    "    Separates a dataframe into three separate dataframes: predictors, dummies, and ys.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input dataframe.\n",
    "        dum_cols (list): A list of column names that are dummy variables. NO MORE DUM COLUMNS\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing three dataframes: (df_preds, dum_df, y).\n",
    "    \"\"\"\n",
    "    #df = df.dropna().reset_index(drop=True) # drop missing variables\n",
    "    \n",
    "    y = df[outcome].values\n",
    "\n",
    "    df_preds = df.drop(columns = [outcome])\n",
    "\n",
    "    #dum_df = pd.get_dummies(df_preds, columns= dum_cols)\n",
    "\n",
    "    return df_preds, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for feature + outcome combo NOT USED YET\n",
    "'''\n",
    "def full_feature_outcome_test(feature, outcome):\n",
    "   \n",
    "   Function to do the entire test for a feature + outcome combo\n",
    "   Inputs: feature (string), outcome (string)\n",
    "   \n",
    "   n = len(df)\n",
    "   label_n = sum(y)\n",
    "   return \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to be repeated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Formulating the preprocessor for scaling and stratified folds\n",
    "\n",
    "def scaleAnd_skf(numeric_features, outcome, rep, fulldataset = False):\n",
    "     # Formulating the preprocessor for scaling\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "\n",
    "    if fulldataset:\n",
    "        preprocessor = ColumnTransformer([('robust', scaler, numeric_features)], remainder = 'passthrough', verbose_feature_names_out=False)\n",
    "    else:\n",
    "        preprocessor = ColumnTransformer([('minmax', scaler, numeric_features)], remainder = 'passthrough')\n",
    "\n",
    "    if outcome in binary_outcomes:\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5, shuffle = True, random_state = rep) #TODO: Change back to 5\n",
    "\n",
    "    elif outcome in continuous_outcomes:\n",
    "        \n",
    "        print(\"In Progress\")\n",
    "    \n",
    "    return preprocessor, skf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do within each traintest split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the dtypes for the xtrain_std and x_test_std\n",
    "\n",
    "def save_dtypes(df, original_df, preprocessor):\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "    df = pd.DataFrame(df, columns=feature_names, index=original_df.index)\n",
    "    df.columns = [col.replace('minmax__', '') for col in df.columns]\n",
    "    df.columns = [col.replace('remainder__', '') for col in df.columns]\n",
    "    for col in df.columns:\n",
    "        if col in original_df.columns:\n",
    "            #print(\"Good\")\n",
    "            #print(col)\n",
    "\n",
    "            #df[col] = df[col].astype(original_df[col].dtype)\n",
    "            df[col] = df[col].astype('float64')\n",
    "\n",
    "        else:\n",
    "            print(\"ERROR\")\n",
    "            #print(col)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Any extra missing values filled in using mode/median of same dataset\n",
    "\n",
    "def post_imputation_cleanup(data):\n",
    "    total_replaced = 0\n",
    "    for col in data.columns:\n",
    "        if data[col].isnull().any():\n",
    "            nan_count_before = data[col].isnull().sum()\n",
    "            if data[col].dtype.name == 'category':\n",
    "                # For categorical data, use mode if it exists\n",
    "                if not data[col].mode().empty:\n",
    "                    data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "            elif data[col].dtype.kind in 'biufc':  # boolean, integer, unsigned integer, float, complex\n",
    "                # For numeric data, use median if it exists and is not null\n",
    "                median = data[col].median()\n",
    "                if pd.notnull(median):\n",
    "                    data[col].fillna(median, inplace=True)\n",
    "            else:\n",
    "                # For other types (like object), use mode if it exists\n",
    "                if not data[col].mode().empty:\n",
    "                    data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "            \n",
    "            nan_count_after = data[col].isnull().sum()\n",
    "            replaced = nan_count_before - nan_count_after\n",
    "            total_replaced += replaced\n",
    "\n",
    "            print(f\"Column '{col}': {replaced} NaN values replaced\")\n",
    "\n",
    "            \n",
    "            # Check if there are still NaN values after imputation\n",
    "            if data[col].isnull().any():\n",
    "                print(f\"Warning: Column '{col}' still contains NaN values after imputation.\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeData(x_train, y_train, x_test, y_test, rep, impute_number):\n",
    "    # Combine x_train and y_train for imputation\n",
    "    x_train = x_train.reset_index(drop=True)\n",
    "    x_test = x_test.reset_index(drop=True)\n",
    "\n",
    "    train_data = x_train.copy()\n",
    "    train_data['target'] = y_train\n",
    "\n",
    "    # Create and fit the imputation kernel\n",
    "    \n",
    "    kernel = mf.ImputationKernel(\n",
    "        train_data,\n",
    "        random_state=rep,\n",
    "        variable_schema = NaNColumn_list\n",
    "    )\n",
    "    \n",
    "    # Use sklearn pipeline method (as in examples)\n",
    "    pipe = Pipeline([('impute', kernel)])\n",
    "    \n",
    "    # Perform imputation\n",
    "    #kernel.mice(impute_number, verbose=True)  # Run 5 iterations, adjust as needed\n",
    "    \n",
    "    # Get the imputed training data\n",
    "    #imputed_train = kernel.complete_data()\n",
    "\n",
    "    imputed_train = pipe.fit_transform(train_data, impute__iterations = impute_number,\n",
    "                                       impute__verbose=True)\n",
    "    \n",
    "    #imputed_train = post_imputation_cleanup(imputed_train)\n",
    "\n",
    "    assert not np.any(np.isnan(imputed_train))\n",
    "\n",
    "    # Separate features and target\n",
    "    x_train_imputed = imputed_train.drop('target', axis=1)\n",
    "    y_train_imputed = imputed_train['target']\n",
    "\n",
    "    # Combine Test data\n",
    "    test_data = x_test.copy()\n",
    "    #test_data['target'] = y_test\n",
    "    test_data['target'] = np.nan \n",
    "    test_data['target'] = test_data['target'].astype('bool')# add dummy target column\n",
    "    # Impute test data\n",
    "    test_imputed = pipe.transform(test_data)\n",
    "    #test_imputed = kernel.transform(test_data)\n",
    "    #test_imputed = post_imputation_cleanup(test_imputed)\n",
    "    x_test_imputed = test_imputed.drop('target', axis=1)\n",
    "\n",
    "    assert not np.any(np.isnan(x_test_imputed))\n",
    "\n",
    "    y_test_imputed = y_test\n",
    "\n",
    "    \n",
    "    return x_train_imputed, y_train_imputed, x_test_imputed, y_test_imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create training, test, validation sets and additional sets\n",
    "def set_train_test(input_df, y, train_index, test_index, rep, preprocessor, impute_number,\n",
    "                   want_val = False):\n",
    "    # Split into train and test\n",
    "\n",
    "    # NEED TO HAVE DUMMYS HERE AFTER IMPUTATION! do in impute_data\n",
    "\n",
    "    # dum_df cut out asa_class column\n",
    "    # x_train_asa = asa_class.iloc[train_index].copy()\n",
    "    # x_test_asa = asa_class.iloc[test_index].copy()\n",
    "    # add these two to the output of set_train_test\n",
    "        \n",
    "    x_train_split = input_df.iloc[train_index].copy()\n",
    "    x_test_split = input_df.iloc[test_index].copy()\n",
    "    y_train_split = y[train_index].copy()\n",
    "    y_test_split = y[test_index].copy()\n",
    "    \n",
    "    \n",
    "    # Peel off validation set\n",
    "\n",
    "    x_train_actual_split, x_val_split, y_train_actual_split, y_val_split = train_test_split(x_train_split,\n",
    "                                                                                            y_train_split, stratify = y_train_split,\n",
    "                                                                                            test_size = 0.1, random_state = rep) # random process\n",
    "\n",
    "\n",
    "    # Remove mrn and surgery start datetime and include that as the actual train and test\n",
    "        \n",
    "        \n",
    "    #if feature == mainfeature:\n",
    "        \n",
    "    print(\"Test\")\n",
    "\n",
    "    if want_val:\n",
    "\n",
    "        x_train_actual = x_train_actual_split.drop(columns = [\"ir_id\", \"surgery_start_datetime\"])\n",
    "        x_val = x_val_split.drop(columns = [\"ir_id\", \"surgery_start_datetime\"])\n",
    "        y_train_actual = y_train_actual_split.copy()\n",
    "        y_val = y_val_split.copy()\n",
    "\n",
    "        # IMPUTED VALUES\n",
    "        x_train_actual, y_train_actual, x_val, y_val = imputeData(x_train_actual, y_train_actual, x_val, y_val, rep, impute_number)\n",
    "    else:\n",
    "        x_train_actual = None\n",
    "        x_val = None\n",
    "        y_train_actual = None\n",
    "        y_val = None\n",
    "\n",
    "\n",
    "\n",
    "    x_train = x_train_split.drop(columns = [\"ir_id\", \"surgery_start_datetime\"])\n",
    "    x_test = x_test_split.drop(columns = [\"ir_id\", \"surgery_start_datetime\"])\n",
    "    x_test_id_cols = x_test_split[[\"ir_id\", \"surgery_start_datetime\"]]\n",
    "    x_test_id_cols = x_test_id_cols.reset_index(drop=True)\n",
    "    y_train = y_train_split.copy()\n",
    "    y_test = y_test_split.copy()\n",
    "\n",
    "    #IMPUTED VALUES\n",
    "    x_train, y_train, x_test, y_test = imputeData(x_train, y_train, x_test, y_test, rep, impute_number)\n",
    "    \n",
    "    \n",
    "    x_train_std = preprocessor.fit_transform(x_train)\n",
    "    x_train_std = save_dtypes(x_train_std, x_train, preprocessor)\n",
    "    x_test_std = preprocessor.transform(x_test)\n",
    "    x_test_std = save_dtypes(x_test_std, x_test, preprocessor)\n",
    "\n",
    "\n",
    "\n",
    "    # Keep a version that has those values as index columns \n",
    "\n",
    "    x_test_features = x_test.copy() #use imputed data\n",
    "    # Add back the identifier columns\n",
    "    x_test_features = pd.concat([x_test_id_cols, x_test_features], axis=1)\n",
    "\n",
    "    x_test_features[\"Patient_ID\"]=  np.arange(len(x_test_features))\n",
    "\n",
    "    x_test_features_long = pd.melt(x_test_features, id_vars = [\"ir_id\", \"Patient_ID\", \"surgery_start_datetime\"], var_name = \"Feature_Name\", value_name = \"Feature_Actual_Value\" )\n",
    "    \n",
    "    x_test_features_long['Feature_Actual_Value'] = pd.to_numeric(x_test_features_long['Feature_Actual_Value'])\n",
    "\n",
    "    x_cols = x_test.columns\n",
    "\n",
    "    n_features = len(x_cols)\n",
    "    \n",
    "    return x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, x_test_features_long, n_features, x_cols, x_train_std, x_test_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ASA model - only works for binary outcomes\n",
    "\n",
    "def ASA_model(x_train, x_test, y_train, rep):\n",
    "\n",
    "    '''\n",
    "    Input: x_train: training data from train-test set\n",
    "           x_test: test data from train-test set\n",
    "           y_train: training labels from train-test set\n",
    "           rep: random state for reproducibility\n",
    "\n",
    "    Output: cv_model: trained logistic regression model\n",
    "            y_pred: predicted labels for test set\n",
    "            y_prob_vec: predicted probabilities for test set\n",
    "    '''\n",
    "\n",
    "    # Extract ASA class feature\n",
    "    trim_train = x_train[[\"asa_class\"]].copy()\n",
    "    trim_test = x_test[[\"asa_class\"]].copy()\n",
    "\n",
    "    # Fit logistic regression model\n",
    "    cv_model = linear_model.LogisticRegression(penalty=None, random_state=rep)\n",
    "    cv_model.fit(trim_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = cv_model.predict(trim_test)\n",
    "    y_prob = cv_model.predict_proba(trim_test)\n",
    "    y_prob_vec = y_prob[:, 1]\n",
    "\n",
    "    return cv_model, y_pred, y_prob_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ASA Categorical model -> <=2 and >2\n",
    "def ASA_categorical_model(x_test):\n",
    "    \n",
    "    x_test['asa_above_2'] = np.where(x_test['asa_class'] >= 3, 1, 0)\n",
    "\n",
    "    trim_test_categorical = x_test[\"asa_above_2\"]\n",
    "\n",
    "\n",
    "    y_pred = trim_test_categorical.values.reshape(-1,1)\n",
    "    y_prob = trim_test_categorical.values.reshape(-1,1)\n",
    "    y_prob_vec = trim_test_categorical.values.reshape(-1,1)\n",
    "    #print(y_prob_vec)\n",
    "    return y_pred, y_prob_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ENet_model(outcome, preprocessor, x_train, y_train, x_test, x_train_std, x_test_std, rep):\n",
    "    '''\n",
    "    Inputs: outcome (str): column_name of outcome variable\n",
    "            preprocessor (obj): standardizing preprocessing object\n",
    "            x_train (df): training data from train-test set\n",
    "            y_train (df): training outcome variable from train-test set\n",
    "            x_test (df): test data from train-test set\n",
    "            x_train_std (df): standardized training data\n",
    "            x_test_std (df): standardized test data\n",
    "\n",
    "    Outputs: cv_model (obj): best model from bayesian optimization\n",
    "             y_pred (arr): predicted values for test set\n",
    "             y_prob_vec (arr): predicted probability values for test set\n",
    "             shap_values (arr): shap values for test set\n",
    "    '''\n",
    "    if outcome in binary_outcomes:\n",
    "        '''\n",
    "        y_train_df = pd.DataFrame(y_train, columns = [\"y_train\"])\n",
    "        All_train = pd.concat([x_train, y_train_df], axis = 1)\n",
    "\n",
    "        kernel = mf.ImputationKernel(\n",
    "            All_train,\n",
    "            random_state=rep,\n",
    "            variable_schema = NaNColumn_list\n",
    "        )\n",
    "        '''\n",
    "        pipe = Pipeline([   #('impute', kernel),\n",
    "                            ('processing', preprocessor), \n",
    "                            ('estimator', linear_model.LogisticRegression(penalty = 'elasticnet', \n",
    "                                                                        solver='saga', \n",
    "                                                                        class_weight = 'balanced',\n",
    "                                                                        random_state = rep, \n",
    "                                                                        max_iter = 1000\n",
    "                                                                        ))])\n",
    "\n",
    "        fit_params = {'impute__iterations': impute_iterations,\n",
    "                      'impute__verbose': True}\n",
    "        model_params = {'estimator__C': Real(1e-2, 1e2, prior = 'log-uniform'),\n",
    "                        'estimator__l1_ratio': Real(0, 1)\n",
    "                        }\n",
    "        hyperopt_model_params = {\n",
    "            'estimator__C': hp.loguniform('estimator__C', np.log(1e-2), np.log(1e2)),\n",
    "            'estimator__l1_ratio': hp.uniform('estimator__l1_ratio', 0, 1)\n",
    "                                 }\n",
    "\n",
    "        cv_model = TuneSearchCV(pipe, \n",
    "                                param_distributions = hyperopt_model_params, \n",
    "                                search_optimization=\"hyperopt\",\n",
    "                                verbose = 2,\n",
    "                                scoring='roc_auc', # auc is most important metric\n",
    "                                refit=True,\n",
    "                                cv=5,\n",
    "                                n_jobs = 7,\n",
    "                                n_trials = tunesearch_iterations, \n",
    "                                random_state = rep\n",
    "                                )\n",
    "\n",
    "        cv_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "        y_pred = cv_model.predict(x_test)\n",
    "        y_prob = cv_model.predict_proba(x_test)\n",
    "        y_prob_vec = y_prob[:,1]\n",
    "\n",
    "\n",
    "    elif outcome in continuous_outcomes:\n",
    "\n",
    "        print(\"In Progress\")\n",
    "\n",
    "\n",
    "    if Get_shaps:\n",
    "        explainer = shap.LinearExplainer(cv_model.best_estimator_.named_steps['estimator'], x_train_std)\n",
    "        shap_values = explainer.shap_values(x_test_std)\n",
    "        print(\"SHAPS DONE\")\n",
    "    else:\n",
    "        shap_values = None\n",
    "        print(\"NO SHAPS FOOR YOU\")\n",
    "\n",
    "    return cv_model, y_pred, y_prob_vec, shap_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost_model(outcome, preprocessor, x_train, y_train, x_test, x_train_std, x_test_std, rep):\n",
    "    '''\n",
    "    Inputs: outcome (str): name of the outcome variable\n",
    "            preprocessor (sklearn.preprocessing): standardizing preprocessor object\n",
    "            x_train (pd.DataFrame): training data from train-test set\n",
    "            y_train (pd.Series): training outcome variable from train-test set\n",
    "            x_test (pd.DataFrame): test data\n",
    "            rep (int): random state for reproducibility\n",
    "\n",
    "    Outputs: y_pred : predicted class for test data\n",
    "             y_prob_vec : predicted probability for test data\n",
    "             cv_model : trained model object\n",
    "             shap_values: SHAP values for the model\n",
    "    '''\n",
    "\n",
    "    if outcome in binary_outcomes:\n",
    "\n",
    "        weight_vec = wt.compute_sample_weight(class_weight = \"balanced\", y = y_train) # compute weights using sklearn\n",
    "#        eval_weight = wt.compute_sample_weight(class_weight = \"balanced\", y = y_val)\n",
    "\n",
    "        pipe = Pipeline([('processing', preprocessor), \n",
    "                            ('estimator', xgb.XGBClassifier(#n_estimators = 500,\n",
    "                                                            #eval_metric = \"auc\",\n",
    "                                                            use_label_encoder=False,\n",
    "                                                            verbosity = 1, random_state = rep\n",
    "                                                        ))]) \n",
    "\n",
    "\n",
    "        es = xgb.callback.EarlyStopping(\n",
    "            rounds = 10,\n",
    "            save_best=True,\n",
    "        )\n",
    "        print(f\"XShape: {x_train.shape}\")\n",
    "\n",
    "        model_params = {\n",
    "            'estimator__n_estimators': hp.uniformint('estimator__n_estimators', 50, 250),\n",
    "            'estimator__max_depth': hp.uniformint('estimator__max_depth', 2, 10),\n",
    "            'estimator__subsample': hp.uniform('estimator__subsample', 0.5, 1.0),\n",
    "            'estimator__learning_rate': hp.uniform('estimator__learning_rate', 0.1, 0.5),\n",
    "            'estimator__colsample_bytree': hp.uniform('estimator__colsample_bytree', 0.5, 1.0),\n",
    "            'estimator__colsample_bylevel': hp.uniform('estimator__colsample_bylevel', 0.5, 1.0),\n",
    "            'estimator__min_child_weight': hp.uniformint('estimator__min_child_weight', 1, 10),\n",
    "            'estimator__gamma': hp.uniform('estimator__gamma', 0, 1.0),\n",
    "            'estimator__reg_lambda': hp.loguniform('estimator__reg_lambda', np.log(1e-2), np.log(1e2)),\n",
    "            'estimator__reg_alpha': hp.loguniform('estimator__reg_alpha', np.log(1e-2), np.log(1e2)),\n",
    "        }\n",
    "\n",
    "        fit_params = {#'estimator__sample_weight_eval_set': [eval_weight],\n",
    "#                                          'estimator__eval_set': [(x_val_std, y_val)],\n",
    "#                                          'estimator__callbacks': [es],\n",
    "                        'estimator__sample_weight': weight_vec,\n",
    "#                                          'estimator__early_stopping_rounds': 10\n",
    "\n",
    "        }\n",
    "\n",
    "        cv_model = TuneSearchCV(pipe, \n",
    "                                param_distributions = model_params, n_trials = tunesearch_iterations,\n",
    "                                scoring='roc_auc', \n",
    "                                refit=True, cv= 5, \n",
    "                                n_jobs = 7, random_state = rep, \n",
    "                                search_optimization = \"hyperopt\",\n",
    "                                verbose = 2)\n",
    "\n",
    "        cv_model.fit(x_train, y_train, **fit_params)\n",
    "\n",
    "\n",
    "\n",
    "        y_pred = cv_model.predict(x_test)\n",
    "        y_prob = cv_model.predict_proba(x_test) # generate prediction probability ([0,1])\n",
    "        y_prob_vec = y_prob[:,1]\n",
    "\n",
    "    elif outcome in continuous_outcomes:\n",
    "\n",
    "        print(\"In Progress\")\n",
    "\n",
    "\n",
    "\n",
    "    if Get_shaps:\n",
    "        explainer = shap.TreeExplainer(cv_model.best_estimator_.named_steps['estimator'], data=x_train_std, model_output = \"probability\")\n",
    "        shap_values = explainer.shap_values(x_test_std)\n",
    "        print(shap_values.shape)\n",
    "        test = shap_values[0] # TODO: Check if 0 is correct here if needed\n",
    "        print(test.shape)\n",
    "        print(\"SHAPS DONE\")\n",
    "    else:\n",
    "        shap_values = None\n",
    "        print(\"NO SHAPS FOR YOU\")\n",
    "\n",
    "    return cv_model, y_pred, y_prob_vec, shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_model(outcome, preprocessor, x_train, y_train, x_test, x_train_std, x_test_std, rep, n_features_in, Interventional):\n",
    "    '''\n",
    "    Inputs: outcome (str): name of the outcome variable\n",
    "            preprocessor (sklearn.preprocessing): standardizing preprocessor object\n",
    "            x_train (pd.DataFrame): training data from train-test set\n",
    "            y_train (pd.Series): training outcome variable from train-test set\n",
    "            x_test (pd.DataFrame): test data\n",
    "            rep (int): random state for reproducibility\n",
    "\n",
    "    Outputs: y_pred : predicted class for test data\n",
    "             y_prob_vec : predicted probability for test data\n",
    "             cv_model : trained model object\n",
    "             shap_values: SHAP values for the model\n",
    "    '''\n",
    "\n",
    "    if outcome in binary_outcomes:\n",
    "\n",
    "        pipe = Pipeline([('processing', preprocessor), \n",
    "                            ('estimator', BalancedRandomForestClassifier(random_state = rep,\n",
    "                                                                         sampling_strategy='all',\n",
    "                                                                         replacement=True,\n",
    "                                                                         bootstrap=False\n",
    "                                                                         ))]) \n",
    "\n",
    "        model_params = {\n",
    "            'estimator__n_estimators': hp.uniformint('estimator__n_estimators', 50, 250),\n",
    "            'estimator__max_features': hp.uniformint('estimator__max_features', 2, n_features_in),\n",
    "            'estimator__max_depth': hp.uniformint('estimator__max_depth', 1, 25),\n",
    "            'estimator__min_samples_split': hp.uniformint('estimator__min_samples_split', 2, 10),\n",
    "            'estimator__min_samples_leaf': hp.uniformint('estimator__min_samples_leaf', 1, 5),\n",
    "        }\n",
    "\n",
    "        cv_model = TuneSearchCV(pipe,\n",
    "                                param_distributions = model_params, n_trials = tunesearch_iterations,\n",
    "                                scoring='roc_auc', # AUC is most important metric\n",
    "                                refit=True, cv=5, n_jobs = 7,\n",
    "                                random_state = rep,\n",
    "                                search_optimization = \"hyperopt\",\n",
    "                                verbose = 2)\n",
    "\n",
    "        cv_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "        y_pred = cv_model.predict(x_test) # generate prediction (0 or 1)\n",
    "        y_prob = cv_model.predict_proba(x_test) # generate prediction probability ([0,1])\n",
    "        y_prob_vec = y_prob[:,1]\n",
    "\n",
    "    elif outcome in continuous_outcomes:\n",
    "\n",
    "        print(\"In Progress\")\n",
    "\n",
    "    if Get_shaps:\n",
    "        if Interventional:\n",
    "            print(\"DOING INTERVENTIONAL\")\n",
    "            explainer = shap.TreeExplainer(cv_model.best_estimator_.named_steps['estimator'], data=x_train_std, feature_perturbation= \"interventional\",\n",
    "                                       model_output = \"probability\")\n",
    "        else:\n",
    "            print(\"DOING PATH DEPENDENT\")\n",
    "            explainer = shap.TreeExplainer(cv_model.best_estimator_.named_steps['estimator'], feature_perturbation= \"tree_path_dependent\")\n",
    "        shap_values = explainer.shap_values(x_test_std)\n",
    "        print(shap_values.shape)\n",
    "        shap_values = shap_values[:, :, 1]\n",
    "        print(shap_values.shape)\n",
    "        print(\"GET SHAPS\")\n",
    "    else:\n",
    "        shap_values = None\n",
    "        print(\"NO SHAPS FOR YOU\")\n",
    "\n",
    "    return cv_model, y_pred, y_prob_vec, shap_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dummy_model(outcome, x_train, y_train, x_test):\n",
    "    '''\n",
    "    Inputs: outcome (str): name of the outcome variable\n",
    "            preprocessor (sklearn.preprocessing): standardizing preprocessor object\n",
    "            x_train (pd.DataFrame): training data from train-test set\n",
    "            y_train (pd.Series): training outcome variable from train-test set\n",
    "            x_test (pd.DataFrame): test data\n",
    "            rep (int): random state for reproducibility\n",
    "\n",
    "    Outputs: y_pred : predicted class for test data\n",
    "             y_prob_vec : predicted probability for test data\n",
    "             cv_model : trained model object\n",
    "             shap_values: SHAP values for the model\n",
    "    '''\n",
    "    if outcome in binary_outcomes:\n",
    "\n",
    "        dummy_clf = DummyClassifier(strategy=\"prior\")\n",
    "        dummy_clf.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = dummy_clf.predict(x_test)\n",
    "        y_prob = dummy_clf.predict_proba(x_test)\n",
    "        y_prob_vec = y_prob[:,1]\n",
    "\n",
    "    elif outcome in continuous_outcomes:\n",
    "\n",
    "        dummy_clf = DummyRegressor(strategy=\"median\")\n",
    "        dummy_clf.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = np.round(dummy_clf.predict(x_test))\n",
    "\n",
    "    return dummy_clf, y_pred, y_prob_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model(outcome, preprocessor, x_train_actual, y_train_actual, x_val, y_val, x_test, n_features, rep):\n",
    "    '''\n",
    "    Inputs: outcome (str): name of the outcome variable\n",
    "            preprocessor (sklearn.preprocessing): standardizing preprocessor object\n",
    "            x_train (pd.DataFrame): training data from train-test set\n",
    "            y_train (pd.Series): training outcome variable from train-test set\n",
    "            x_test (pd.DataFrame): test data\n",
    "            rep (int): random state for reproducibility\n",
    "\n",
    "    Outputs: y_pred : predicted class for test data\n",
    "             y_prob_vec : predicted probability for test data\n",
    "             cv_model : trained model object\n",
    "             shap_values: SHAP values for the model\n",
    "    '''\n",
    "\n",
    "    #tf.config.run_functions_eagerly(True)\n",
    "\n",
    "    if outcome in binary_outcomes:\n",
    "\n",
    "        x_train_actual_std = preprocessor.fit_transform(x_train_actual)\n",
    "        x_train_actual_std = save_dtypes(x_train_actual_std, x_train_actual, preprocessor)\n",
    "        x_val_std = preprocessor.transform(x_val)\n",
    "        x_val_std = save_dtypes(x_val_std, x_val, preprocessor)\n",
    "\n",
    "#       x_train_std = preprocessor.fit_transform(x_train)\n",
    "        x_test_std = preprocessor.transform(x_test)\n",
    "        x_test_std = save_dtypes(x_test_std, x_test, preprocessor)\n",
    "\n",
    "        reset_random_seed(rep)\n",
    "\n",
    "\n",
    "        metric_set=[tf.keras.metrics.AUC(name=\"auc\")]\n",
    "\n",
    "\n",
    "\n",
    "        weight_vec = wt.compute_sample_weight(class_weight = \"balanced\", y = y_train_actual) # compute weights using sklearn\n",
    "        eval_weight = wt.compute_sample_weight(class_weight = \"balanced\", y = y_val)\n",
    "\n",
    "\n",
    "        # Convert data to TensorFlow datasets\n",
    "        #train_dataset = tf.data.Dataset.from_tensor_slices((x_train_actual_std, y_train_actual, weight_vec))\n",
    "        #train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32)\n",
    "\n",
    "        #val_dataset = tf.data.Dataset.from_tensor_slices((x_val_std, y_val, eval_weight))\n",
    "        #val_dataset = val_dataset.batch(32)\n",
    "\n",
    "\n",
    "        nn_model = tf.keras.Sequential(name=\"DeepNN_CLF\", layers=[\n",
    "\n",
    "            # Input layer is implicitly defined here\n",
    "\n",
    "            ### hidden layer 1\n",
    "            tf.keras.layers.Dense(name=\"h1\", input_dim=n_features,\n",
    "                            units=int(round((n_features+1)/2)), \n",
    "                            activation='relu'),\n",
    "\n",
    "            ### dropout layer 1\n",
    "            tf.keras.layers.Dropout(name=\"drop1\", rate=0.2, seed = rep),\n",
    "\n",
    "            ### hidden layer 2\n",
    "            tf.keras.layers.Dense(name=\"h2\", units=int(round((n_features+1)/4)), \n",
    "                            activation='relu'),\n",
    "\n",
    "            ### dropout layer 2\n",
    "            tf.keras.layers.Dropout(name=\"drop2\", rate=0.2, seed = rep),\n",
    "\n",
    "            ### layer output\n",
    "            tf.keras.layers.Dense(name=\"output\", units=1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        nn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics = metric_set)\n",
    "\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_auc', \n",
    "            verbose=1,\n",
    "            patience=10,\n",
    "            mode='max',\n",
    "            restore_best_weights=True)\n",
    "\n",
    "        history = nn_model.fit(\n",
    "            x_train_actual_std,\n",
    "            y_train_actual,\n",
    "            epochs= 100, #TODO: Change back to 100\n",
    "            sample_weight=weight_vec,\n",
    "            batch_size=32, #added\n",
    "            callbacks=[early_stopping],\n",
    "            validation_data=(x_val_std, y_val, eval_weight),\n",
    "        )\n",
    "\n",
    "        y_prob = nn_model.predict(x_test_std) \n",
    "        y_pred = (y_prob > 0.5).astype(\"int32\")                 \n",
    "        y_prob_vec = y_prob.flatten()\n",
    "\n",
    "        nn_model.summary()\n",
    "\n",
    "        # Plot training history\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['auc'], label='Training AUC')\n",
    "        plt.plot(history.history['val_auc'], label='Validation AUC')\n",
    "        plt.title('Model AUC')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('AUC')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    elif outcome in continuous_outcomes:\n",
    "\n",
    "        print(\"In Progress\")\n",
    "\n",
    "\n",
    "    # SHAP values calculation\n",
    "    '''\n",
    "    tf.config.run_functions_eagerly(False)\n",
    "    print(tf.executing_eagerly())\n",
    "    background = shap.sample(x_train_actual_std, 100)  # Use a subset of training data as background\n",
    "    explainer = shap.DeepExplainer(nn_model, background)\n",
    "    shap_values = explainer.shap_values(x_test_std.values)\n",
    "    shap_values = shap_values[:, :, 0]\n",
    "    print(shap_values.shape)\n",
    "    tf.config.run_functions_eagerly(True)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    #explainer = shap.DeepExplainer(nn_model, data=x_train_actual_std)\n",
    "    #print(type(x_test_std))\n",
    "    #shap_values = explainer.shap_values(x_test_std)\n",
    "    #print(shap_values.shape)\n",
    "\n",
    "    return nn_model, y_pred, y_prob_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Linear_SVC_model(outcome, preprocessor, x_train, y_train, x_test, x_train_std, x_test_std, rep):\n",
    "    '''\n",
    "    Inputs: outcome (str): name of the outcome variable\n",
    "            preprocessor (sklearn.preprocessing): standardizing preprocessor object\n",
    "            x_train (pd.DataFrame): training data from train-test set\n",
    "            y_train (pd.Series): training outcome variable from train-test set\n",
    "            x_test (pd.DataFrame): test data\n",
    "            x_train_std (pd.DataFrame): standardized training data\n",
    "            x_test_std (pd.DataFrame): standardized test data\n",
    "            rep (int): random state for reproducibility\n",
    "\n",
    "    Outputs: y_pred : predicted class for test data\n",
    "             y_prob_vec : predicted probability for test data\n",
    "             cv_model : trained model object\n",
    "             shap_values: SHAP values for the model\n",
    "    '''\n",
    "\n",
    "    if outcome in binary_outcomes:\n",
    "\n",
    "\n",
    "        pipe = Pipeline([('processing', preprocessor),\n",
    "                         ('estimator', sklearn.svm.LinearSVC(random_state=rep,\n",
    "                                                             dual=False,\n",
    "                                                             max_iter=1000,\n",
    "                                                             class_weight='balanced' ))])\n",
    "\n",
    "        model_params = {\n",
    "            'estimator__C': hp.loguniform('estimator__C', np.log(1e-2), np.log(1e2)),\n",
    "        }\n",
    "\n",
    "        cv_model = TuneSearchCV(pipe, \n",
    "                                param_distributions = model_params, \n",
    "                                scoring='roc_auc', # auc is most important metric\n",
    "                                refit=True, \n",
    "                                cv=5, n_jobs = 7,\n",
    "                                n_trials = tunesearch_iterations, \n",
    "                                random_state = rep,\n",
    "                                search_optimization = \"hyperopt\",\n",
    "                                verbose = 2\n",
    "                                )        \n",
    "        \n",
    "        cv_model.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = cv_model.predict(x_test)\n",
    "        y_prob = cv_model.decision_function(x_test)\n",
    "        y_prob_vec = 1 / (1 + np.exp(-y_prob))\n",
    "\n",
    "    elif outcome in continuous_outcomes:\n",
    "        print(\"In Progress\")\n",
    "\n",
    "    if Get_shaps:\n",
    "        print(\"GET SHAPS\")\n",
    "        explainer = shap.LinearExplainer(cv_model.best_estimator_.named_steps['estimator'], x_train_std)\n",
    "        shap_values = explainer.shap_values(x_test_std)\n",
    "    else:\n",
    "        shap_values = None\n",
    "        print(\"NO SHAPS FOR YOU\")\n",
    "\n",
    "    return cv_model, y_pred, y_prob_vec, shap_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "\n",
    "def SVC_model_with_kernels(outcome, preprocessor, x_train, y_train, x_test, x_train_std, x_test_std, rep):\n",
    "    '''\n",
    "    Inputs: outcome (str): name of the outcome variable\n",
    "            preprocessor (sklearn.preprocessing): standardizing preprocessor object\n",
    "            x_train (pd.DataFrame): training data from train-test set\n",
    "            y_train (pd.Series): training outcome variable from train-test set\n",
    "            x_test (pd.DataFrame): test data\n",
    "            x_train_std (pd.DataFrame): standardized training data\n",
    "            x_test_std (pd.DataFrame): standardized test data\n",
    "            rep (int): random state for reproducibility\n",
    "\n",
    "    Outputs: y_pred : predicted class for test data\n",
    "             y_prob_vec : predicted probability for test data\n",
    "             cv_model : trained model object\n",
    "             shap_values: SHAP values for the model\n",
    "    '''\n",
    "\n",
    "    if outcome in binary_outcomes:\n",
    "        pipe = Pipeline([\n",
    "            ('processing', preprocessor),\n",
    "            ('nystroem', Nystroem(random_state=rep)),\n",
    "            ('estimator', LinearSVC(random_state=rep, dual=False, max_iter=1000, class_weight='balanced'))\n",
    "        ])\n",
    "\n",
    "        model_params = {\n",
    "            'nystroem__kernel': hp.choice('nystroem__kernel', ['rbf', 'poly', 'sigmoid']),\n",
    "            'nystroem__n_components': hp.uniformint('nystroem__n_components', 50, 200),\n",
    "            'nystroem__gamma': hp.loguniform('nystroem__gamma', np.log(1e-3), np.log(1e1)),\n",
    "            'nystroem__degree': hp.uniformint('nystroem__degree', 2, 6),  # Integer values from 2 to 5\n",
    "            'nystroem__coef0': hp.uniform('nystroem__coef0', 0, 1),  # Uniform distribution between 0 and 1\n",
    "            'estimator__C': hp.loguniform('estimator__C', np.log(1e-2), np.log(1e2)),\n",
    "        }\n",
    "        '''\n",
    "        # Define separate search spaces for each kernel\n",
    "        linear_params = {}  # No additional parameters for linear kernel\n",
    "        rbf_params = {\n",
    "            'nystroem__gamma': Real(1e-3, 1e1, prior='log-uniform'),\n",
    "        }\n",
    "        poly_params = {\n",
    "            'nystroem__degree': Integer(2, 5),\n",
    "            'nystroem__gamma': Real(1e-3, 1e1, prior='log-uniform'),\n",
    "            'nystroem__coef0': Real(0, 1),\n",
    "        }\n",
    "        sigmoid_params = {\n",
    "            'nystroem__gamma': Real(1e-3, 1e1, prior='log-uniform'),\n",
    "            'nystroem__coef0': Real(0, 1),\n",
    "        }\n",
    "\n",
    "        # Combine the search spaces based on the kernel\n",
    "        search_spaces = model_params.copy()\n",
    "        search_spaces.update(linear_params if 'linear' in search_spaces['nystroem__kernel'] else {})\n",
    "        search_spaces.update(rbf_params if 'rbf' in search_spaces['nystroem__kernel'] else {})\n",
    "        search_spaces.update(poly_params if 'poly' in search_spaces['nystroem__kernel'] else {})\n",
    "        search_spaces.update(sigmoid_params if 'sigmoid' in search_spaces['nystroem__kernel'] else {})\n",
    "        '''\n",
    "        \n",
    "        cv_model = TuneSearchCV(\n",
    "            pipe, \n",
    "            param_distributions=model_params, \n",
    "            scoring='roc_auc',\n",
    "            refit=True, \n",
    "            cv=5,\n",
    "            n_jobs=7,\n",
    "            n_trials=tunesearch_iterations,  # Increased due to larger search space\n",
    "            random_state=rep,\n",
    "            search_optimization = \"hyperopt\",\n",
    "            verbose = 2\n",
    "        )        \n",
    "        \n",
    "        cv_model.fit(x_train, y_train)\n",
    "        best_params = cv_model.best_params_\n",
    "        best_kernel = best_params['nystroem__kernel']\n",
    "        #best_gamma = best_params['nystroem__gamma']\n",
    "        print(f\"Best kernel: {best_kernel}\")\n",
    "        #print(f\"Best gamma: {best_gamma}\")\n",
    "\n",
    "        y_pred = cv_model.predict(x_test)\n",
    "        y_prob = cv_model.decision_function(x_test)\n",
    "        y_prob_vec = 1 / (1 + np.exp(-y_prob))\n",
    "\n",
    "    elif outcome in continuous_outcomes:\n",
    "        print(\"In Progress\")\n",
    "        return\n",
    "\n",
    "    # Transform the data using the fitted Nystroem approximation\n",
    "    nystroem = cv_model.best_estimator_.named_steps['nystroem']\n",
    "    x_train_nystroem = nystroem.transform(x_train_std)\n",
    "    x_test_nystroem = nystroem.transform(x_test_std)\n",
    "    print(type(nystroem.components_))\n",
    "    print(nystroem.components_.shape)\n",
    "\n",
    "    if Get_shaps:\n",
    "        print(\"GET SHAPS\")\n",
    "        #For SHAP values, we'll use KernelExplainer as LinearExplainer won't work with the kernel approximation\n",
    "        explainer = shap.LinearExplainer(cv_model.best_estimator_.named_steps['estimator'], x_train_nystroem)\n",
    "        shap_values = explainer.shap_values(x_test_nystroem)\n",
    "        print(shap_values.shape)\n",
    "    else:\n",
    "        print(\"NO SHAPS FOR YOU\")\n",
    "        shap_values = None\n",
    "\n",
    "    return cv_model, y_pred, y_prob_vec, shap_values, best_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shap.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "def log_execution(csv_path, name_of_model, start_time):\n",
    "    end_time = time.time()\n",
    "    total_seconds = end_time - start_time\n",
    "    \n",
    "    # Calculate minutes and seconds\n",
    "    minutes = math.floor(total_seconds / 60)  # Get complete minutes\n",
    "    seconds = round(total_seconds % 60)  # Get remaining seconds, rounded\n",
    "    \n",
    "    # Create new row\n",
    "    new_row = {\n",
    "        'model_name': name_of_model,\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'execution_time_minutes': minutes,\n",
    "        'execution_time_seconds': seconds\n",
    "    }\n",
    "    \n",
    "    # Read existing CSV, append new row, and save\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    except FileNotFoundError:\n",
    "        # If file doesn't exist, create new DataFrame\n",
    "        df = pd.DataFrame([new_row])\n",
    "    \n",
    "    df.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_results(results_list, auc_plot_list, outcome, procedure, feature, model_name, rep, i, n, label_n, y_test, y_prob_vec, y_pred):\n",
    "    \"\"\"\n",
    "    Collects and computes performance metrics for binary classification models.\n",
    "\n",
    "    This function calculates various performance metrics for binary classification models and stores them in a results dataframe.\n",
    "    It also generates ROC curve data for plotting.\n",
    "\n",
    "    Parameters:\n",
    "        results_list (list): List to store performance metric results\n",
    "        auc_plot_list (list): List to store ROC curve plotting data\n",
    "        outcome (str): Name of the outcome being predicted\n",
    "        procedure (str): Name of the procedure being analyzed\n",
    "        feature (str): Name/description of features used\n",
    "        model_name (str): Name of the model used\n",
    "        rep (int): Repetition number\n",
    "        i (int): Fold number for cross-validation\n",
    "        n (int): Total number of samples\n",
    "        label_n (int): Number of labeled samples\n",
    "        y_test (array-like): True labels\n",
    "        y_prob_vec (array-like): Predicted probabilities\n",
    "        y_pred (array-like): Predicted labels\n",
    "\n",
    "    Returns:\n",
    "        None - Updates results_list and auc_plot_list in place\n",
    "\n",
    "    Metrics calculated:\n",
    "    - AUC (Area Under ROC Curve)\n",
    "    - Sensitivity/Recall\n",
    "    - Specificity\n",
    "    - PPV (Positive Predictive Value)\n",
    "    - NPV (Negative Predictive Value) \n",
    "    - Log Loss\n",
    "    - Brier Score\n",
    "    - Weighted F1 Score\n",
    "    - Accuracy\n",
    "    - Balanced Accuracy\n",
    "    - Confusion Matrix\n",
    "\n",
    "    The function only processes binary classification outcomes (checks if outcome is in binary_outcomes).\n",
    "    Results are stored in a pandas DataFrame and appended to the input lists.\n",
    "    \"\"\"\n",
    "\n",
    "    if outcome in binary_outcomes:\n",
    "        # Computing AUC\n",
    "        fpr, tpr, threshold = metrics.roc_curve(y_test, y_prob_vec, pos_label = 1)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        AUC = metrics.auc(fpr, tpr)\n",
    "\n",
    "        print(f\"AUC: {AUC}\")\n",
    "        logging.info(f\"AUC, Logging: {AUC}\")\n",
    "        # Sensitivity, Specificity\n",
    "\n",
    "        recall_score_0 = metrics.recall_score(y_test,y_pred, pos_label=0)\n",
    "        recall_score_1 = metrics.recall_score(y_test,y_pred, pos_label=1)\n",
    "\n",
    "        # PPV, NPV\n",
    "        precision_score_0 = metrics.precision_score(y_test,y_pred, pos_label=0)\n",
    "        precision_score_1 = metrics.precision_score(y_test,y_pred, pos_label=1)\n",
    "\n",
    "        # Computing Log Loss\n",
    "        log_loss = metrics.log_loss(y_test, y_prob_vec, labels = [0,1])\n",
    "\n",
    "        # Computing Brier score\n",
    "        brier_loss = metrics.brier_score_loss(y_test, y_prob_vec, pos_label = 1)\n",
    "\n",
    "        # Computing WF1\n",
    "        W_F1= metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        # Computing Accuracy\n",
    "        accuracy_score = metrics.accuracy_score(y_test,y_pred)\n",
    "        B_accuracy_score = metrics.balanced_accuracy_score(y_test,y_pred)\n",
    "\n",
    "\n",
    "        # Confusion Matrix\n",
    "        c_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        new_results = pd.DataFrame(\n",
    "            {\n",
    "                \"Procedure\": [procedure],\n",
    "                \"Outcome\": [outcome],\n",
    "                \"Features\": [feature],\n",
    "                \"Model\": [model_name],\n",
    "                \"Rep\": [rep],\n",
    "                \"Fold\": [i],\n",
    "                \"W_F1\": [W_F1],\n",
    "                \"AUC\": [AUC],\n",
    "                \"MAE\": [\"NA\"],\n",
    "                \"R2\": [\"NA\"],\n",
    "                \"RMSE\": [\"NA\"],\n",
    "                \"Log-Loss\": [log_loss],\n",
    "                \"Brier-Loss\": [brier_loss],\n",
    "                \"Accuracy\": [accuracy_score],\n",
    "                \"Balanced_Accuracy\": [B_accuracy_score],\n",
    "                \"Sensitivity\": [recall_score_1],\n",
    "                \"Specificity\": [recall_score_0],\n",
    "                \"NPV\": [precision_score_0],\n",
    "                \"PPV\": [precision_score_1],\n",
    "                \"c_matrix\": [c_mat],\n",
    "                \"n\":[n],\n",
    "                \"label_n\": [label_n]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        auc_plot_results_new = pd.DataFrame(\n",
    "            {\n",
    "                \"Procedure\": np.repeat(procedure, len(fpr)),\n",
    "                \"Outcome\": np.repeat(outcome, len(fpr)),\n",
    "                \"Features\": np.repeat(feature, len(fpr)),\n",
    "                \"Model\": np.repeat(model_name, len(fpr)),\n",
    "                \"Rep\": np.repeat(rep, len(fpr)),\n",
    "                \"Fold\": np.repeat(i, len(fpr)),\n",
    "                \"FPR\": fpr,\n",
    "                \"TPR\": tpr,\n",
    "                \"Thresholds\": threshold\n",
    "            }\n",
    "        )\n",
    "        #print(len(fpr))\n",
    "        auc_plot_list.append(auc_plot_results_new)\n",
    "\n",
    "        results_list.append(new_results)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_shap_results(individual_features_shap_full_list, feature_results_list, shap_values, y_test, x_cols, x_test_features_long, outcome, procedure,\n",
    "                         feature, model_name, rep, i, svcKernel = False):\n",
    "    \n",
    "    '''\n",
    "    Inputs: individual_features_shap_full: empty shap list\n",
    "\n",
    "    Outputs: shap_file_results: dataframe of shap values for each patient and feature\n",
    "    '''\n",
    "    mod_shap = shap_values.copy()\n",
    "    #mod_shap = shap_values[0]\n",
    "\n",
    "    test_length = len(y_test)\n",
    "\n",
    "    row_vec = list(range(0, test_length))\n",
    "    shap_features_row = []\n",
    "    if svcKernel:\n",
    "        print(x_cols)\n",
    "    for row in row_vec:\n",
    "\n",
    "        shap_values_row = mod_shap[row]\n",
    "\n",
    "        temp_feature_names = list(x_cols) #CHECK here\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        new_shap_features_row = pd.DataFrame(\n",
    "            {\n",
    "                \"Patient_ID\": np.repeat(row, len(x_cols)),\n",
    "                \"Feature_Name\": temp_feature_names,\n",
    "                \"Feature_Value\": shap_values_row,\n",
    "                \"Feature_Abs_Value\": np.abs(shap_values_row),\n",
    "\n",
    "            }\n",
    "        )\n",
    "\n",
    "        shap_features_row.append(new_shap_features_row)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    shap_features_tabular = pd.concat(shap_features_row)\n",
    "\n",
    "\n",
    "\n",
    "    individual_features_shap = x_test_features_long.merge(shap_features_tabular, how = \"left\", on = [\"Patient_ID\", \"Feature_Name\"])\n",
    "\n",
    "    individual_features_shap[\"Procedure\"]=  procedure\n",
    "    individual_features_shap[\"Outcome\"]=  outcome\n",
    "    individual_features_shap[\"Model\"]=  model_name\n",
    "    individual_features_shap[\"Rep\"]=  rep\n",
    "    individual_features_shap[\"Fold\"]=  i\n",
    "\n",
    "\n",
    "    individual_features_shap_full_list.append(individual_features_shap)\n",
    "\n",
    "    summarized_features_shap = shap_features_tabular.groupby(['Feature_Name']).agg(   \n",
    "        Feature_Mean_Abs = ('Feature_Abs_Value','mean'),\n",
    "    ).reset_index()\n",
    "\n",
    "\n",
    "    feature_coef = summarized_features_shap['Feature_Mean_Abs'].values\n",
    "    feature_names = summarized_features_shap['Feature_Name'].values\n",
    "\n",
    "\n",
    "    new_features = pd.DataFrame(\n",
    "        {\n",
    "            \"Procedure\": np.repeat(procedure, len(feature_names)),\n",
    "            \"Outcome\": np.repeat(outcome, len(feature_names)),\n",
    "            \"Features\": np.repeat(feature, len(feature_names)),\n",
    "            \"Model\": np.repeat(model_name, len(feature_names)),\n",
    "            \"Rep\": np.repeat(rep, len(feature_names)),\n",
    "            \"Fold\": np.repeat(i, len(feature_names)),\n",
    "            \"Feature_Name\": feature_names,\n",
    "            \"Feature_Mean_Abs_Value\": feature_coef,\n",
    "\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "#                    feature_results = feature_results.append(new_features, ignore_index=True)\n",
    "    feature_results_list.append(new_features)\n",
    "\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install shap==0.41.0 --user\n",
    "print(shap.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "## TEST WITH FUSION FIRST\n",
    "\n",
    "print(procedure_of_interest)\n",
    "data_non_binary = load_data(procedure_of_interest)\n",
    "#data = pd.read_csv(r\"081524_Spine_reports_vf.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert to binary preop_meds\n",
    "data = preop_to_binary(data_non_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMP missing columns\n",
    "\n",
    "cbc_columns = [col for col in data.columns if col.startswith('BMP')]\n",
    "# Calculate the percentage of missing values for each of these columns\n",
    "missing_percentages = data[cbc_columns].isnull().mean() * 100\n",
    "\n",
    "# Convert the result to a DataFrame for better readability\n",
    "BMP_missing_df = pd.DataFrame({'Column': missing_percentages.index, 'Percent Missing': missing_percentages.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBC missing columns\n",
    "\n",
    "cbc_columns = [col for col in data.columns if col.startswith('CBC')]\n",
    "# Calculate the percentage of missing values for each of these columns\n",
    "missing_percentages = data[cbc_columns].isnull().mean() * 100\n",
    "\n",
    "# Convert the result to a DataFrame for better readability\n",
    "CBC_missing_df = pd.DataFrame({'Column': missing_percentages.index, 'Percent Missing': missing_percentages.values})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name_base = procedure_of_interest+\"_\"+date+\"_\"\n",
    "file_name_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_feature_outcome_test(feature=\"PLS_features\", outcome=\"Post_lam_syndrome\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data['gender'] == 'U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up what columns to use \n",
    "## Testing with fusion first\n",
    "# Set feature, outcome\n",
    "mainfeature = \"Health_Util_Features\"\n",
    "outcome = outcomes[0]\n",
    "print(outcome)\n",
    "data_new = add_columns_remove_rows(data)\n",
    "data_null_labs = remove_labs_90(data_new)\n",
    "print(data_null_labs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create outcome variable\n",
    "data_w_outcome = data_null_labs.copy()\n",
    "\n",
    "data_w_outcome['specialist_visits'] = data_w_outcome['Number_of_neurosurgery_visits'] + data_w_outcome['Number_of_orthopaedic_visits']\n",
    "data_w_outcome['emergency_visits'] = data_w_outcome['Number_of_ED'] + data_w_outcome['Number_of_urgent_care_visits']\n",
    "data_w_outcome['Number_pain_meds'] = data_w_outcome['Number_of_opioids_prescriptions'] + data_w_outcome['Number_of_benzodiazepine_prescriptions'] + data_w_outcome['Number_of_neuromodulator_prescriptions']\n",
    "data_w_outcome['Number_referrals'] = data_w_outcome['Number_of_PT_referrals'] + data_w_outcome['Number_of_other_referrals'] \n",
    "\n",
    "count_columns = ['specialist_visits', 'emergency_visits', 'Number_of_imaging_orders', 'Number_pain_meds', 'Number_referrals']\n",
    "\n",
    "\n",
    "for column in count_columns:\n",
    "    p75 = data_w_outcome[column].quantile(0.75)\n",
    "    print(f\"{column}: {p75}\")\n",
    "\n",
    "percentiles = data_w_outcome[count_columns].quantile(0.75)\n",
    "data_w_outcome['High_physician_time'] = ((data_w_outcome['specialist_visits'] > percentiles['specialist_visits']) | \n",
    "                                            (data_w_outcome['Number_referrals'] > percentiles['Number_referrals'])).astype('Int64')\n",
    "data_w_outcome['High_medication_time'] = ((data_w_outcome['emergency_visits'] >= 1) | \n",
    "                                               (data_w_outcome['Number_pain_meds'] > percentiles['Number_pain_meds']) |\n",
    "                                               (data_w_outcome['Number_of_imaging_orders'] > percentiles['Number_of_imaging_orders'])).astype('Int64')\n",
    "\n",
    "\n",
    "# Convert to DataFrame (makes it easier to save to CSV)\n",
    "count_stats = []\n",
    "for col in count_columns:\n",
    "    col_type = data_w_outcome[col].dtype\n",
    "    missing = data_w_outcome[col].isna().sum()\n",
    "    total = len(data_w_outcome[col])\n",
    "    \n",
    "    # Create stats dictionary for each column\n",
    "    col_stats = {\n",
    "        'column': col,\n",
    "        'dtype': str(col_type),\n",
    "        'missing_count': missing,\n",
    "        'missing_pct': (missing/total * 100).round(2),\n",
    "        'mean': data_w_outcome[col].mean(),\n",
    "        'std': data_w_outcome[col].std(),\n",
    "        'min': data_w_outcome[col].min(),\n",
    "        '25%': data_w_outcome[col].quantile(0.25),\n",
    "        'median': data_w_outcome[col].median(),\n",
    "        '75%': data_w_outcome[col].quantile(0.75),\n",
    "        'max': data_w_outcome[col].max()\n",
    "    }\n",
    "    count_stats.append(col_stats)\n",
    "\n",
    "extra_cols = ['High_physician_time', 'High_medication_time']\n",
    "\n",
    "for col in extra_cols:\n",
    "    col_type = data_w_outcome[col].dtype\n",
    "    missing = data_w_outcome[col].isna().sum()\n",
    "    total = len(data_w_outcome[col])\n",
    "\n",
    "    # Handle both boolean and binary integer columns\n",
    "    non_null = total - missing\n",
    "    true_count = data_w_outcome[col].sum()\n",
    "    false_count = non_null - true_count\n",
    "    \n",
    "    col_stats = {\n",
    "        'column': col,\n",
    "        'dtype': str(col_type),\n",
    "        'missing_count': missing,\n",
    "        'missing_pct': (missing/total * 100).round(2),\n",
    "        'true_count': true_count,\n",
    "        'true_pct': (true_count/non_null * 100).round(2) if non_null > 0 else 0,\n",
    "        'false_count': false_count,\n",
    "        'false_pct': (false_count/non_null * 100).round(2) if non_null > 0 else 0\n",
    "    }\n",
    "    count_stats.append(col_stats)\n",
    "\n",
    "# Convert to DataFrame\n",
    "count_summary_df = pd.DataFrame(count_stats)\n",
    "\n",
    "# Save to CSV\n",
    "count_summary_df.to_csv(f'{procedure_of_interest}_{pickle_folder_name}_percentile_75_thresholds.csv', index=False)\n",
    "\n",
    "''' OR\n",
    "# Create the classification\n",
    "# If threshold or more counts are above their 75th percentile -> high utilizer (1)\n",
    "# Otherwise -> low/normal utilizer (0)\n",
    "def classify_utilizer(row, threshold=2):  # Added threshold parameter\n",
    "    count_above_75 = 0  # Counter for columns exceeding 75th percentile\n",
    "    for column in count_columns:\n",
    "        if row[column] > percentiles[column]:\n",
    "            count_above_75 += 1\n",
    "    return 1 if count_above_75 >= threshold else 0  # Return 1 if meets or exceeds threshold\n",
    "'''\n",
    "# Create the classification\n",
    "# If ALL counts are above their 75th percentiles -> high utilizer (1)\n",
    "# If ANY count is below its 75th percentile -> low/normal utilizer (0)\n",
    "''' AND\n",
    "def classify_utilizer(row):\n",
    "    for column in count_columns:\n",
    "        if row[column] <= percentiles[column]:  # Changed > to <= and flipped the logic\n",
    "            return 0  # Low/normal utilizer\n",
    "    return 1  # High utilizer - only reached if ALL counts are above 75th percentile\n",
    "'''\n",
    "\n",
    "# Apply the classification with threshold of 2\n",
    "threshold = 1  # You can adjust this number as needed\n",
    "#data_w_outcome['High_Health_Utilizer'] = data_w_outcome.apply(lambda x: classify_utilizer(x, threshold=threshold), axis=1)\n",
    "#data_w_outcome['High_Health_Utilizer'] = data_w_outcome.apply(classify_utilizer, axis=1)\n",
    "data_w_outcome['High_Health_Utilizer'] = ((data_w_outcome['High_physician_time'] == 1) &\n",
    "                                          (data_w_outcome['High_medication_time'] == 1))\n",
    "data_w_outcome['High_Health_Utilizer'] = data_w_outcome['High_Health_Utilizer'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate percentage of emergency visits >= 1\n",
    "emergency_visits_pct = (len(data_w_outcome[data_w_outcome['emergency_visits'] >= 1]) / len(data_w_outcome)) * 100\n",
    "print(f\"Percentage of patients with emergency visits: {emergency_visits_pct:.2f}%\")\n",
    "\n",
    "# Calculate 75th percentile of emergency visits\n",
    "emergency_visits_75th = data_w_outcome['emergency_visits'].quantile(0.75)\n",
    "print(f\"75th percentile of emergency visits: {emergency_visits_75th:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_asa, numeric_features, individual_features_shap_full = set_columns(data=data_w_outcome, outcome=outcome,\n",
    "                                                                          pofI= procedure_of_interest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_info = pd.DataFrame({\n",
    "    'Column Name': df.columns,\n",
    "    'Data Type': df.dtypes    \n",
    "})\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numeric_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Separate df into three new dfs using separate_dfs\n",
    "# original dum_df shape (with dropnan): 11709, 102\n",
    "\n",
    "df_preds, y = separate_dfs(df, outcome=outcome)\n",
    "n = len(df_preds)\n",
    "label_n = sum(y)\n",
    "df_preds.shape\n",
    "\n",
    "#Fusion shape (3581, 81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get a list of all columns with nan values\n",
    "nan_df = df_preds.isna()\n",
    "NaNColumn_list = nan_df.any().loc[nan_df.any() == True].index.tolist()\n",
    "print(len(NaNColumn_list))\n",
    "print(NaNColumn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary stats\n",
    "df_for_summary = df.copy()\n",
    "df_for_summary['surgery_start_datetime'] = pd.to_datetime(df_for_summary['surgery_start_datetime'])\n",
    "(df_for_summary.dtypes).unique()\n",
    "\n",
    "def get_summary_stats(df):\n",
    "    # Initialize lists to store results\n",
    "    stats = []\n",
    "    nrow, ncol = df.shape\n",
    "    shape_stats = {\n",
    "        'column': 'DataFrame Shape',\n",
    "        'dtype': 'info',\n",
    "        'missing_count': nrow,\n",
    "        'missing_pct': ncol\n",
    "    }\n",
    "    stats.append(shape_stats)\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        missing = df[col].isna().sum()\n",
    "        total = len(df[col])\n",
    "        \n",
    "        # Create base stats dictionary\n",
    "        col_stats = {\n",
    "            'column': col,\n",
    "            'dtype': str(col_type),\n",
    "            'missing_count': missing,\n",
    "            'missing_pct': (missing/total * 100).round(2)\n",
    "        }\n",
    "        # Check if Int64/int64 column is binary (0,1,NA only)\n",
    "        is_binary = False\n",
    "        if col_type in ['Int64']:\n",
    "            unique_vals = df[col].dropna().unique()\n",
    "            is_binary = set(unique_vals).issubset({0, 1})\n",
    "\n",
    "        # Add type-specific statistics\n",
    "        if (col_type in ['int64', 'Int64', 'float64']) and not is_binary:\n",
    "            col_stats.update({\n",
    "                'mean': df[col].mean(),\n",
    "                'std': df[col].std(),\n",
    "                'min': df[col].min(),\n",
    "                '25%': df[col].quantile(0.25),\n",
    "                'median': df[col].median(),\n",
    "                '75%': df[col].quantile(0.75),\n",
    "                'max': df[col].max()\n",
    "            })\n",
    "        elif col_type == 'datetime64[ns]':\n",
    "             # For datetime, calculate days from the minimum date\n",
    "            min_date = df[col].min()\n",
    "            days_from_min = (df[col] - min_date).dt.total_seconds() / (24*60*60)\n",
    "            \n",
    "            col_stats.update({\n",
    "                'min': df[col].min(),\n",
    "                'max': df[col].max(),\n",
    "                'mean': df[col].mean(),\n",
    "                'std': days_from_min.std(),  # Standard deviation in days\n",
    "                '25%': df[col].quantile(0.25),\n",
    "                'median': df[col].quantile(0.50),\n",
    "                '75%': df[col].quantile(0.75),\n",
    "                'range_days': (df[col].max() - df[col].min()).days\n",
    "            })\n",
    "        elif col_type == 'bool' or is_binary:\n",
    "            # Handle both boolean and binary integer columns\n",
    "            non_null = total - missing\n",
    "            true_count = df[col].sum()\n",
    "            false_count = non_null - true_count\n",
    "            \n",
    "            col_stats.update({\n",
    "                'true_count': true_count,\n",
    "                'true_pct': (true_count/non_null * 100).round(2) if non_null > 0 else 0,\n",
    "                'false_count': false_count,\n",
    "                'false_pct': (false_count/non_null * 100).round(2) if non_null > 0 else 0\n",
    "            })\n",
    "        stats.append(col_stats)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    summary_df = pd.DataFrame(stats)\n",
    "    return summary_df\n",
    "\n",
    "# Use the function\n",
    "summary_stats = get_summary_stats(df_for_summary)\n",
    "\n",
    "summary_stats.to_csv(f'{procedure_of_interest}_{pickle_folder_name}_summary_stats.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cell\n",
    "csv_path = f'{procedure_of_interest}_{date}_model_execution_log.csv'\n",
    "if not os.path.exists(csv_path):\n",
    "    pd.DataFrame(columns=['model_name', 'timestamp', \n",
    "                        'execution_time_minutes', 'execution_time_seconds']).to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Negative LOS patients\n",
    "df_LOS_neg = df_for_summary[df_for_summary['LOS_days'] < 0]\n",
    "df_LOS_neg.to_csv('df_LOS_neg.csv', index=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Where graft is true\n",
    "df_graft_true = data[data['cpt_graft'] == True]\n",
    "# Split the strings and get unique values\n",
    "unique_numbers = set()\n",
    "\n",
    "# Assuming your column name is 'column_name' - replace with actual column name\n",
    "for string in df_graft_true['procedure_codes'].dropna():  # dropna() to handle any NaN values\n",
    "    numbers = string.split('; ')  # split on '; '\n",
    "    unique_numbers.update(numbers)\n",
    "\n",
    "# Convert to sorted list for better viewing\n",
    "unique_numbers_sorted = sorted(unique_numbers)\n",
    "\n",
    "print(\"Unique numbers found:\")\n",
    "print(unique_numbers_sorted)\n",
    "print(f\"\\nTotal unique numbers: {len(unique_numbers_sorted)}\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot out number of missing by surgery year\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "want_missingcharts = False\n",
    "if want_missingcharts:\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    output_dir = f'preop_missing_{procedure_of_interest}'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Extract year from datetime column\n",
    "    df_for_summary['surgery_year'] = df_for_summary['surgery_start_datetime'].dt.year\n",
    "\n",
    "    # Get all preop columns\n",
    "    preop_columns = [col for col in df_for_summary.columns if col.startswith('preop')]\n",
    "\n",
    "    # Create a plot for each preop column\n",
    "    for col in preop_columns:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Calculate missing values by year\n",
    "        missing_by_year = df_for_summary.groupby('surgery_year')[col].apply(lambda x: x.isna().sum()).reset_index()\n",
    "        missing_by_year.columns = ['Year', 'Missing Count']\n",
    "        \n",
    "        # Create bar plot\n",
    "        sns.barplot(data=missing_by_year, x='Year', y='Missing Count')\n",
    "        \n",
    "        # Customize plot\n",
    "        plt.title(f'Missing Values by Year: {col}')\n",
    "        plt.xlabel('Surgery Year')\n",
    "        plt.ylabel('Number of Missing Values')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for i, v in enumerate(missing_by_year['Missing Count']):\n",
    "            plt.text(i, v, str(v), ha='center', va='bottom')\n",
    "        \n",
    "        # Adjust layout and save\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/{col}_missing.png')\n",
    "        plt.close()\n",
    "\n",
    "    # Optional: Create a summary plot with all preop columns\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Melt the data for all preop columns\n",
    "    melted_df_for_summary = df_for_summary.melt(id_vars=['surgery_year'], \n",
    "                        value_vars=preop_columns, \n",
    "                        var_name='Preop Variable', \n",
    "                        value_name='Value')\n",
    "\n",
    "    # Calculate missing values\n",
    "    missing_summary = (melted_df_for_summary.groupby(['surgery_year', 'Preop Variable'])\n",
    "                    .apply(lambda x: x['Value'].isna().sum())\n",
    "                    .reset_index(name='Missing Count'))\n",
    "\n",
    "    # Create summary plot\n",
    "    sns.barplot(data=missing_summary, \n",
    "                x='surgery_year', \n",
    "                y='Missing Count', \n",
    "                hue='Preop Variable')\n",
    "\n",
    "    plt.title('Missing Values by Year: All Preop Variables')\n",
    "    plt.xlabel('Surgery Year')\n",
    "    plt.ylabel('Number of Missing Values')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/all_preop_missing.png')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting and Results DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_set)\n",
    "print(n)\n",
    "print(label_n)\n",
    "print(df_preds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later, when you need to use the data for a specific model:\n",
    "def load_split_data(rep, fold):\n",
    "    print(f'Loading split data for {pickle_folder_name}, {procedure_of_interest}, rep {rep} and fold {fold}')\n",
    "    with open(f'{pickle_folder_name}_{procedure_of_interest}_SavedSplits/split_data_rep{rep}_fold{fold}.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save TrainTests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Create a directory to store the pickled data\n",
    "traintest_start_time = time.time()\n",
    "os.makedirs(f'{pickle_folder_name}_{procedure_of_interest}_SavedSplits', exist_ok=True)\n",
    "for rep in repetitions:\n",
    "    preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "        \n",
    "        # Create all the different train_test splits\n",
    "        print(f'Creating train_test split for {pickle_folder_name}, procedure {procedure_of_interest}, rep {rep} fold {i}')\n",
    "        split_data = set_train_test(input_df= df_preds, y=y, train_index=train_index, test_index=test_index, rep=rep, preprocessor=preprocessor,\n",
    "                                    impute_number=impute_iterations, want_val=True)\n",
    "        with open(f'{pickle_folder_name}_{procedure_of_interest}_SavedSplits/split_data_rep{rep}_fold{i}.pkl', 'wb') as f:\n",
    "            pickle.dump(split_data, f)\n",
    "\n",
    "log_execution(csv_path, 'TrainTestSplit', traintest_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ASA\n",
    "'''\n",
    "def ASA_train_test(procedure):\n",
    "\n",
    "    # Create results lists\n",
    "    ASA_results_list = []\n",
    "    ASA_auc_list = []\n",
    "\n",
    "    for rep in repetitions:\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "            # Create all the different train_test splits\n",
    "            ASA_split_data = load_split_data(rep, i)\n",
    "            x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "            x_test_features_long, n_features, x_cols, x_train_std, x_test_std = ASA_split_data\n",
    "\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "            \n",
    "            \n",
    "         \n",
    "            asa_model_fitted, y_pred, y_prob_vec = ASA_model(x_train, x_test, y_train, rep)\n",
    "            collect_results(ASA_results_list, ASA_auc_list, outcome, procedure, feature, \"ASA\", rep, i, n, label_n,\n",
    "                                                            y_test, y_prob_vec, y_pred)\n",
    "\n",
    "    ASA_results = pd.concat(ASA_results_list, ignore_index=True)\n",
    "    ASA_auc_results = pd.concat(ASA_auc_list, ignore_index=True)\n",
    "\n",
    "    return ASA_results, ASA_auc_results\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW ASA USING LOGISTIC REGRESSION!\n",
    "def ASA_train_test(procedure):\n",
    "\n",
    "    # Create results lists\n",
    "    ASA_results_list = []\n",
    "    ASA_auc_list = []\n",
    "\n",
    "    for rep in repetitions:\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_asa, y)):\n",
    "            # Create all the different train_test splits\n",
    "\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "\n",
    "            X_train_asa = df_asa.iloc[train_index].copy()\n",
    "            X_train_asa = X_train_asa.reset_index(drop=True)\n",
    "            X_test_asa = df_asa.iloc[test_index].copy()\n",
    "            X_test_asa = X_test_asa.reset_index(drop=True)\n",
    "            y_train = y[train_index].copy()\n",
    "            y_test = y[test_index].copy()\n",
    "\n",
    "\n",
    "            # Impute ASA class with mode of training set\n",
    "            train_mode = X_train_asa['asa_class'].mode()[0]\n",
    "            X_train_asa['asa_class'] = X_train_asa['asa_class'].fillna(train_mode)\n",
    "            X_test_asa['asa_class'] = X_test_asa['asa_class'].fillna(train_mode)\n",
    "\n",
    "            # Extract features and reshape for sklearn\n",
    "            X_train = X_train_asa['asa_class'].values.reshape(-1, 1)\n",
    "            X_test = X_test_asa['asa_class'].values.reshape(-1, 1)\n",
    "\n",
    "            # No need to scale since it's a single ordinal variable\n",
    "            # Train logistic regression\n",
    "            lr_model = LogisticRegression(random_state=rep)\n",
    "            lr_model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get predictions\n",
    "            y_pred = lr_model.predict(X_test)\n",
    "            y_prob_vec = lr_model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            \n",
    "            collect_results(ASA_results_list, ASA_auc_list, outcome, procedure, feature, \"ASA\", rep, i, n, label_n,\n",
    "                                                            y_test, y_prob_vec, y_pred)\n",
    "\n",
    "    ASA_results = pd.concat(ASA_results_list, ignore_index=True)\n",
    "    ASA_auc_results = pd.concat(ASA_auc_list, ignore_index=True)\n",
    "\n",
    "    return ASA_results, ASA_auc_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run ASA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASA_start_time = time.time()\n",
    "ASA_results, ASA_auc_results = ASA_train_test(procedure_of_interest)\n",
    "log_execution(csv_path, \"ASA\", ASA_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASA_auc_results.to_csv(procedure_of_interest+ \"_\" + pickle_folder_name + \"_ASA_\" + \"auc_data.csv\")\n",
    "ASA_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name + \"_ASA_\"+ \"model_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASA Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ASA categorical\n",
    "'''\n",
    "def ASA_categorical_train(procedure):\n",
    "    asa_cat_results_list = []\n",
    "    asa_cat_auc_list = []\n",
    "    for rep in repetitions:\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "            # Create all the different train_test splits\n",
    "\n",
    "            ASA_cat_split_data = load_split_data(rep, i)\n",
    "            x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "            x_test_features_long, n_features, x_cols, x_train_std, x_test_std = ASA_cat_split_data\n",
    "\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "\n",
    "            y_pred, y_prob_vec_two = ASA_categorical_model(x_test)\n",
    "            #print(y_prob_vec_two)\n",
    "            collect_results(asa_cat_results_list, asa_cat_auc_list, outcome, procedure, feature,\n",
    "                            \"ASA_Categorical\", rep, i, n, label_n, y_test, y_prob_vec_two, y_pred)\n",
    "\n",
    "    ASA_cat_results = pd.concat(asa_cat_results_list, ignore_index=True)\n",
    "    ASA_cat_auc_results = pd.concat(asa_cat_auc_list, ignore_index=True)\n",
    "\n",
    "    return ASA_cat_results, ASA_cat_auc_results\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run ASA Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ASA_cat_results, ASA_cat_auc_results = ASA_categorical_train(procedure_of_interest)\n",
    "ASA_cat_auc_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_ASACat_\" + \"auc_data.csv\")\n",
    "ASA_cat_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_ASACat_\"+ \"model_results.csv\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENet\n",
    "\n",
    "import numpy as np\n",
    "def ENet_model_train_test(procedure):\n",
    "\n",
    "    ENet_results_list = []\n",
    "    ENet_auc_list = []\n",
    "    ENet_shap_full_list = []\n",
    "    ENet_shap_summary_list = []\n",
    "\n",
    "    for rep in repetitions:\n",
    "        #rep = 4\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "            #if i != 3: \n",
    "            #    continue\n",
    "            # Create all the different train_test splits\n",
    "            Enet_split_data = load_split_data(rep, i)\n",
    "            x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "            x_test_features_long, n_features, x_cols, x_train_std, x_test_std = Enet_split_data\n",
    "\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "            print(f\"SizeData {x_train.shape}\")\n",
    "            #x_train = x_train.reset_index(drop=True)\n",
    "\n",
    "            ENet_model_fitted, y_pred, y_prob_vec, shap_values = ENet_model(outcome, preprocessor, x_train, y_train,\n",
    "                                                                            x_test, x_train_std, x_test_std, rep)\n",
    "            \n",
    "            collect_results(ENet_results_list, ENet_auc_list, outcome, procedure, feature,\n",
    "                            \"ENet\", rep, i, n, label_n, y_test, y_prob_vec, y_pred)\n",
    "            \n",
    "            if Get_shaps:\n",
    "                print(\"Collecting Shaps\")\n",
    "                collect_shap_results(ENet_shap_full_list, ENet_shap_summary_list, shap_values, \n",
    "                                    y_test, x_cols, x_test_features_long, outcome, procedure, feature, \"ENet\",\n",
    "                                    rep, i)\n",
    "            else:\n",
    "                print(\"Not collecting shaps\")\n",
    "            \n",
    "            ENET_temp_results = pd.concat(ENet_results_list, ignore_index=True)\n",
    "            ENET_temp_auc_results = pd.concat(ENet_auc_list, ignore_index=True)\n",
    "            \n",
    "            ENET_temp_auc_results.to_csv(\"TEMP_\" + procedure_of_interest+\"_\" + pickle_folder_name +\"_ENET_\" + \"auc_data.csv\")\n",
    "            ENET_temp_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_ENET_\"+ \"model_results.csv\")\n",
    "\n",
    "            if Get_shaps:\n",
    "                print(\"Saving temp shaps\")\n",
    "                ENET_temp_shap_long_results = pd.concat(ENet_shap_full_list, ignore_index=True)\n",
    "                ENET_temp_shap_summary_results = pd.concat(ENet_shap_summary_list, ignore_index=True)\n",
    "                ENET_temp_shap_long_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_ENET_\"+\"feature_importance_full.csv\")\n",
    "                ENET_temp_shap_summary_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_ENET_\"+\"feature_importance.csv\")\n",
    "            else:\n",
    "                print(\"Not saving temp Shaps\")\n",
    "            \n",
    "            \n",
    "\n",
    "    ENet_results = pd.concat(ENet_results_list, ignore_index=True)\n",
    "    ENet_auc_results = pd.concat(ENet_auc_list, ignore_index=True)\n",
    "    if Get_shaps:\n",
    "        print(\"Saving final shaps\")\n",
    "        ENet_shap_long_results = pd.concat(ENet_shap_full_list, ignore_index=True)\n",
    "        ENet_shap_summary_results = pd.concat(ENet_shap_summary_list, ignore_index=True)\n",
    "    else:\n",
    "        print(\"Not saving final shaps\")\n",
    "        ENet_shap_long_results = None\n",
    "        ENet_shap_summary_results = None\n",
    "\n",
    "    return ENet_results, ENet_auc_results, ENet_shap_long_results, ENet_shap_summary_results, shap_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enet Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results, AUC results, shaps, and shap summaries\n",
    "import time\n",
    "ENet_start_time = time.time()\n",
    "ENet_results, ENet_auc_results, ENet_shap_long_results, ENet_shap_summary_results, shap_values_Enet = ENet_model_train_test(procedure_of_interest)\n",
    "log_execution(csv_path, 'ENet', ENet_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enet Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENet_auc_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_Enet_\" + \"auc_data.csv\")\n",
    "ENet_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_Enet_\"+ \"model_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Get_shaps:\n",
    "    print(\"Saving Shap vals to CSV\")\n",
    "    ENet_shap_summary_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_Enet_\"+\"feature_importance.csv\")\n",
    "    ENet_shap_long_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_Enet_\"+\"feature_importance_full.csv\")\n",
    "else:\n",
    "    print(\"Not saving Shap vals to CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBoost\n",
    "def XGB_model_train_test(procedure):\n",
    "    XGB_results_list = []\n",
    "    XGB_auc_list = []\n",
    "    XGB_shap_full_list = []\n",
    "    XGB_shap_summary_list = []\n",
    "\n",
    "    for rep in repetitions:\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "            # Create all the different train_test splits\n",
    "            split_data = load_split_data(rep, i)\n",
    "            x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "            x_test_features_long, n_features, x_cols, x_train_std, x_test_std = split_data\n",
    "\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "\n",
    "            XGBoost_model_fitted, y_pred, y_prob_vec, shap_values_two = XGBoost_model(outcome, preprocessor, x_train,\n",
    "                                                                                y_train, x_test, x_train_std, x_test_std,\n",
    "                                                                                rep)\n",
    "            collect_results(XGB_results_list, XGB_auc_list, outcome, procedure, feature, \"XGB\", rep, i, n,\n",
    "                            label_n, y_test, y_prob_vec, y_pred)\n",
    "            \n",
    "            if Get_shaps:\n",
    "                print(\"Collecting Shaps\")\n",
    "                collect_shap_results(XGB_shap_full_list, XGB_shap_summary_list, shap_values_two, y_test,\n",
    "                                 x_cols, x_test_features_long, outcome, procedure, feature, \n",
    "                                 \"XGB\", rep, i)\n",
    "            else:\n",
    "                print(\"Not collecting shaps\")\n",
    "            \n",
    "            XGB_temp_results = pd.concat(XGB_results_list, ignore_index=True)\n",
    "            XGB_temp_auc_results = pd.concat(XGB_auc_list, ignore_index=True)\n",
    "            XGB_temp_auc_results.to_csv(\"TEMP_\" + procedure_of_interest+\"_\" + pickle_folder_name +\"_XGB_\" + \"auc_data.csv\")\n",
    "            XGB_temp_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_XGB_\"+ \"model_results.csv\")\n",
    "\n",
    "\n",
    "            if Get_shaps:\n",
    "                print(\"Saving temp shaps\")\n",
    "                XGB_temp_shap_full_results = pd.concat(XGB_shap_full_list, ignore_index=True)\n",
    "                XGB_temp_shap_summary_results = pd.concat(XGB_shap_summary_list, ignore_index=True)\n",
    "                XGB_temp_shap_full_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_XGB_\"+\"feature_importance_full.csv\")\n",
    "                XGB_temp_shap_summary_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_XGB_\"+\"feature_importance.csv\")\n",
    "            else:\n",
    "                print(\"Not saving temp shaps\")\n",
    "\n",
    "\n",
    "    XGB_results = pd.concat(XGB_results_list, ignore_index=True)\n",
    "    XGB_auc_results = pd.concat(XGB_auc_list, ignore_index=True)\n",
    "\n",
    "    if Get_shaps:\n",
    "        print(\"Saving final shaps\")\n",
    "        XGB_shap_full_results = pd.concat(XGB_shap_full_list, ignore_index=True)\n",
    "        XGB_shap_summary_results = pd.concat(XGB_shap_summary_list, ignore_index=True)\n",
    "    else:\n",
    "        print(\"Not Saving Final shaps\")\n",
    "        XGB_shap_full_results = None\n",
    "        XGB_shap_summary_results = None\n",
    "\n",
    "    return XGB_results, XGB_auc_results, XGB_shap_full_results, XGB_shap_summary_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_start_time = time.time()\n",
    "XGB_results, XGB_auc_results, XGB_shap_full_results, XGB_shap_summary_results = XGB_model_train_test(procedure_of_interest)\n",
    "log_execution(csv_path, 'XGB', XGB_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XBG Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_auc_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_XGB_\" + \"auc_data.csv\")\n",
    "XGB_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_XGB_\"+ \"model_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Get_shaps:\n",
    "    print(\"Saving shap csv\")\n",
    "    XGB_shap_summary_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_XGB_\"+\"feature_importance.csv\")\n",
    "    XGB_shap_full_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_XGB_\"+\"feature_importance_full.csv\")\n",
    "else:\n",
    "    print(\"Not saving shap csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XGB_shap_summary_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RF\n",
    "Get_shaps = True\n",
    "InterventionalBool = False\n",
    "def RF_model_train_test(procedure):\n",
    "    RF_results_list = []\n",
    "    RF_auc_list = []\n",
    "    RF_shap_full_list = []\n",
    "    RF_shap_summary_list = []\n",
    "\n",
    "    for rep in repetitions:\n",
    "       # if rep != 1:\n",
    "        #    continue\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "            # Create all the different train_test splits\n",
    "         #   if i != 1:\n",
    "          #      continue\n",
    "            RF_split_data = load_split_data(rep, i)\n",
    "            x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "            x_test_features_long, n_features, x_cols, x_train_std, x_test_std = RF_split_data\n",
    "\n",
    "            print(f\"XShape {x_train.shape}\")\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "\n",
    "            RF_model_fitted, y_pred, y_prob_vec, shap_values = RF_model(outcome, preprocessor, x_train,\n",
    "                                                                        y_train, x_test, x_train_std, x_test_std,\n",
    "                                                                        rep, n_features, InterventionalBool)\n",
    "            \n",
    "            collect_results(RF_results_list, RF_auc_list, outcome, procedure, feature, \"RF\", rep, i,\n",
    "                            n, label_n, y_test, y_prob_vec, y_pred)\n",
    "            \n",
    "            if Get_shaps:\n",
    "                print(\"Collect Shaps\")\n",
    "                collect_shap_results(RF_shap_full_list, RF_shap_summary_list, shap_values, y_test, \n",
    "                                    x_cols, x_test_features_long, outcome, procedure, feature, \"RF\", rep,\n",
    "                                    i)\n",
    "            else:\n",
    "                print(\"Not collecting Shaps\")\n",
    "            \n",
    "            RF_temp_results = pd.concat(RF_results_list, ignore_index=True)\n",
    "            RF_temp_auc_results = pd.concat(RF_auc_list, ignore_index=True)\n",
    "            RF_temp_auc_results.to_csv(\"TEMP_\" + procedure_of_interest+\"_\" + pickle_folder_name +\"_RF_\" + \"auc_data.csv\")\n",
    "            RF_temp_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_RF_\"+ \"model_results.csv\")\n",
    "\n",
    "            if Get_shaps:\n",
    "                print(\"Saving temp shaps\")\n",
    "                RF_temp_shap_full_results = pd.concat(RF_shap_full_list, ignore_index=True)\n",
    "                RF_temp_shap_summary_results = pd.concat(RF_shap_summary_list, ignore_index=True)\n",
    "                RF_temp_shap_full_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_RF_\"+ \"feature_importance_full.csv\")\n",
    "                RF_temp_shap_summary_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_RF_\"+\"feature_importance.csv\")\n",
    "            else:\n",
    "                print(\"Not Saving Temp Shaps\")\n",
    "\n",
    "    RF_results = pd.concat(RF_results_list, ignore_index=True)\n",
    "    RF_auc_results = pd.concat(RF_auc_list, ignore_index=True)\n",
    "\n",
    "    if Get_shaps:\n",
    "        print(\"Save full shaps\")\n",
    "        RF_shap_full_results = pd.concat(RF_shap_full_list, ignore_index=True)\n",
    "        RF_shap_summary_results = pd.concat(RF_shap_summary_list, ignore_index=True)\n",
    "    else:\n",
    "        print(\"Not saving full shaps\")\n",
    "        RF_shap_full_results = None\n",
    "        RF_shap_summary_results = None\n",
    "\n",
    "    return RF_results, RF_auc_results, RF_shap_full_results, RF_shap_summary_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_start_time = time.time()\n",
    "RF_results, RF_auc_results, RF_shap_full_results, RF_shap_summary_results = RF_model_train_test(procedure_of_interest)\n",
    "log_execution(csv_path, 'RF', RF_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_auc_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_RF_\" + \"auc_data.csv\")\n",
    "RF_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_RF_\"+ \"model_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Get_shaps:\n",
    "    print(\"Save shaps to csv\")\n",
    "    RF_shap_summary_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_RF_\"+\"feature_importance.csv\")\n",
    "    RF_shap_full_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_RF_\"+\"feature_importance_full.csv\")\n",
    "else:\n",
    "    print(\"Not saving shaps to csv\")\n",
    "\n",
    "Get_shaps = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dummy\n",
    "\n",
    "def Dummy_model_train_test(procedure):\n",
    "    Dummy_results_list = []\n",
    "    Dummy_auc_list = []\n",
    "    for rep in repetitions:\n",
    "        #rep = 1\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "            #if i != 2:\n",
    "            #    continue\n",
    "            # Create all the different train_test splits\n",
    "\n",
    "            Dummy_split_data = load_split_data(rep, i)\n",
    "            x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "            x_test_features_long, n_features, x_cols, x_train_std, x_test_std = Dummy_split_data\n",
    "\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "\n",
    "            Dummy_model_fitted, y_pred, y_prob_vec = Dummy_model(outcome, x_train, y_train, x_test)\n",
    "            collect_results(Dummy_results_list, Dummy_auc_list, outcome, procedure, feature, \"Dummy\", rep, i, n, \n",
    "                            label_n, y_test, y_prob_vec, y_pred)\n",
    "    \n",
    "    Dummy_results = pd.concat(Dummy_results_list, ignore_index=True)\n",
    "    Dummy_auc_results = pd.concat(Dummy_auc_list, ignore_index=True) \n",
    "\n",
    "    return Dummy_results, Dummy_auc_results\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dummy_start_time = time.time()\n",
    "Dummy_results, Dummy_auc_results = Dummy_model_train_test(procedure_of_interest)\n",
    "log_execution(csv_path, 'Dummy', Dummy_start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dummy_auc_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_Dummy_\" + \"auc_data.csv\")\n",
    "Dummy_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_Dummy_\"+ \"model_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN, no shap values right now to save runtime\n",
    "def NN_model_train_test(procedure):\n",
    "    NN_results_list = []\n",
    "    NN_auc_results_list = []\n",
    "    NN_shap_results_list = []\n",
    "    NN_shap_summary_list = []\n",
    "    for rep in repetitions:\n",
    "        #rep = 4\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "            # Create all the different train_test splits\n",
    "            #if i != 3:\n",
    "            #    continue\n",
    "            NN_split_data = load_split_data(rep, i)\n",
    "\n",
    "            x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "            x_test_features_long, n_features, x_cols, x_train_std, x_test_std = NN_split_data\n",
    "\n",
    "            nn_n_features = x_train_actual.shape[1]\n",
    "            \n",
    "            y_train_actual = y_train_actual.values if isinstance(y_train_actual, pd.Series) else y_train_actual\n",
    "            y_val = y_val.values if isinstance(y_val, pd.Series) else y_val\n",
    "\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "            \n",
    "            \n",
    "            nn_model_fitted, y_pred, y_prob_vec = NN_model(outcome, preprocessor, x_train_actual, \n",
    "                                                        y_train_actual, x_val, y_val, x_test, nn_n_features,\n",
    "                                                        rep)\n",
    "            collect_results(NN_results_list, NN_auc_results_list, outcome, procedure, feature, \"NN\", rep, i,\n",
    "                            n, label_n, y_test, y_prob_vec, y_pred)\n",
    "            \n",
    "            NN_temp_results = pd.concat(NN_results_list, ignore_index=True)\n",
    "            NN_temp_auc_results = pd.concat(NN_auc_results_list, ignore_index=True)\n",
    "            #RF_shap_full_results = pd.concat(RF_shap_full_list, ignore_index=True)\n",
    "            #NN_temp_shap_summary_results = pd.concat(RF_shap_summary_list, ignore_index=True)\n",
    "            \n",
    "            NN_temp_auc_results.to_csv(\"TEMP_\" + procedure_of_interest+\"_\" + pickle_folder_name +\"_NN_\" + \"auc_data.csv\")\n",
    "            NN_temp_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_NN_\"+ \"model_results.csv\")\n",
    "            #RF_temp_shap_summary_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_RF_\"+\"feature_importance.csv\")\n",
    "            #collect_shap_results(NN_shap_results_list, NN_shap_summary_list, shap_values, y_test, x_cols, x_test_features_long,\n",
    "             #                    outcome, procedure, feature, \"NN\", rep, i)\n",
    "            \n",
    "    NN_results = pd.concat(NN_results_list, ignore_index=True)\n",
    "    NN_auc_results = pd.concat(NN_auc_results_list, ignore_index=True)\n",
    "    #NN_shap_full_results = pd.concat(NN_shap_results_list, ignore_index=True)\n",
    "    #NN_shap_summary_results = pd.concat(NN_shap_summary_list, ignore_index=True)\n",
    "    \n",
    "    return NN_results, NN_auc_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_start_time = time.time()\n",
    "NN_results, NN_auc_results = NN_model_train_test(procedure_of_interest)\n",
    "log_execution(csv_path, 'NN', NN_start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_auc_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_NN_\" + \"auc_data.csv\")\n",
    "NN_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_NN_\"+ \"model_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVC\n",
    "def linear_svc_train_test(procedure):\n",
    "    \n",
    "    SVC_results_list = []\n",
    "    SVC_auc_list = []\n",
    "    SVC_shap_full_list = []\n",
    "    SVC_shap_summary_list = []\n",
    "\n",
    "    for rep in repetitions:\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "            # Create all the different train_test splits\n",
    "\n",
    "            LinSVC_split_data = load_split_data(rep, i)\n",
    "            x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "            x_test_features_long, n_features, x_cols, x_train_std, x_test_std = LinSVC_split_data\n",
    "\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "\n",
    "            SVC_model_fitted, y_pred, y_prob_vec, shap_values = Linear_SVC_model(outcome, preprocessor, x_train, y_train,\n",
    "                                                                            x_test, x_train_std, x_test_std, rep)\n",
    "            \n",
    "            collect_results(SVC_results_list, SVC_auc_list, outcome, procedure, feature,\n",
    "                            \"LinearSVC\", rep, i, n, label_n, y_test, y_prob_vec, y_pred)\n",
    "            \n",
    "            if Get_shaps:\n",
    "                print(\"Collecting Shaps\")\n",
    "                collect_shap_results(SVC_shap_full_list, SVC_shap_summary_list, shap_values, \n",
    "                                    y_test, x_cols, x_test_features_long, outcome, procedure, feature, \"LinearSVC\",\n",
    "                                    rep, i)\n",
    "            else:\n",
    "                print(\"Not Collecting Shaps\")\n",
    "            \n",
    "            LinSVC_temp_results = pd.concat(SVC_results_list, ignore_index=True)\n",
    "            LinSVC_temp_auc_results = pd.concat(SVC_auc_list, ignore_index=True)\n",
    "            LinSVC_temp_auc_results.to_csv(\"TEMP_\" + procedure_of_interest+\"_\" + pickle_folder_name +\"_SVC_\" + \"auc_data.csv\")\n",
    "            LinSVC_temp_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_SVC_\"+ \"model_results.csv\")\n",
    "\n",
    "            if Get_shaps:\n",
    "                print(\"Saving temp shaps\")\n",
    "                LinSVC_temp_shap_long_results = pd.concat(SVC_shap_full_list, ignore_index=True)\n",
    "                LinSVC_temp_shap_summary_results = pd.concat(SVC_shap_summary_list, ignore_index=True)\n",
    "                LinSVC_temp_shap_long_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_SVC_\"+\"feature_importance_full.csv\")\n",
    "                LinSVC_temp_shap_summary_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_SVC_\"+\"feature_importance.csv\")\n",
    "            else:\n",
    "                print(\"Not saving temp shaps\")\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    SVC_results = pd.concat(SVC_results_list, ignore_index=True)\n",
    "    SVC_auc_results = pd.concat(SVC_auc_list, ignore_index=True)\n",
    "    if Get_shaps:\n",
    "        print(\"Saving final shaps\")\n",
    "        SVC_shap_long_results = pd.concat(SVC_shap_full_list, ignore_index=True)\n",
    "        SVC_shap_summary_results = pd.concat(SVC_shap_summary_list, ignore_index=True)\n",
    "    else:\n",
    "        print(\"NOT saving final shaps\")\n",
    "        SVC_shap_long_results = None\n",
    "        SVC_shap_summary_results = None\n",
    "\n",
    "    return SVC_results, SVC_auc_results, SVC_shap_long_results, SVC_shap_summary_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinSVC run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinSVC_start_time = time.time()\n",
    "LinSVC_results, LinSVC_auc_results, LinSVC_shap_long_results, LinSVC_shap_summary_results = linear_svc_train_test(procedure_of_interest)\n",
    "log_execution(csv_path, 'LinSVC', LinSVC_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinSVC Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinSVC_auc_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_LinSVC_\" + \"auc_data.csv\")\n",
    "LinSVC_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_LinSVC_\"+ \"model_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Get_shaps:\n",
    "    print(\"Saving shap to csv\")\n",
    "    LinSVC_shap_summary_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_LinSVC_\"+\"feature_importance.csv\")\n",
    "    LinSVC_shap_long_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_LinSVC_\"+\"feature_importance_full.csv\")\n",
    "else:\n",
    "    print(\"NOT saving shap to csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC with Kernels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lin SVC w Kernels\n",
    "#TODO: Fix Shap results collection with Nystroem\n",
    "def LinSVC_Kernel_model_train_test(procedure):\n",
    "    SVCKern_results_list = []\n",
    "    SVCKern_auc_list = []\n",
    "    SVCKern_shap_full_list = []\n",
    "    SVCKern_shap_summary_list = []\n",
    "    SVCKern_kernel_list = []\n",
    "\n",
    "    for rep in repetitions:\n",
    "        preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(df_preds, y)):\n",
    "            # Create all the different train_test splits\n",
    "\n",
    "            LinSVCKernel_split_data = load_split_data(rep, i)\n",
    "            x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "            x_test_features_long, n_features, x_cols, x_train_std, x_test_std = LinSVCKernel_split_data\n",
    "\n",
    "            print(f\"Procedure: {procedure}\")\n",
    "            print(f\"Feature: {feature}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print(f\"Rep: {rep}\")\n",
    "            print(f\"TrainTest I: {i}\")\n",
    "\n",
    "            SVC_model_fitted, y_pred, y_prob_vec, shap_values, best_kernel = SVC_model_with_kernels(outcome, preprocessor, x_train, y_train,\n",
    "                                                                            x_test, x_train_std, x_test_std, rep)\n",
    "            \n",
    "            collect_results(SVCKern_results_list, SVCKern_auc_list, outcome, procedure_of_interest, feature,\n",
    "                            \"LinSVC_Kernel\", rep, i, n, label_n, y_test, y_prob_vec, y_pred)\n",
    "            \n",
    "            kernel_row = pd.DataFrame(\n",
    "                {\n",
    "                    \"Procedure\": [procedure],\n",
    "                    \"Outcome\": [outcome],\n",
    "                    \"Features\": [feature],\n",
    "                    \"Model\": [\"LinSVC_Kernel\"],\n",
    "                    \"Rep\": [rep],\n",
    "                    \"Fold\": [i],\n",
    "                    \"Best_Kernel\": [best_kernel]\n",
    "                }\n",
    "            )\n",
    "\n",
    "            SVCKern_kernel_list.append(kernel_row)\n",
    "\n",
    "\n",
    "            \n",
    "            LinSVCKern_temp_results = pd.concat(SVCKern_results_list, ignore_index=True)\n",
    "            LinSVCKern_temp_auc_results = pd.concat(SVCKern_auc_list, ignore_index=True)\n",
    "            #RF_shap_full_results = pd.concat(RF_shap_full_list, ignore_index=True)\n",
    "            #RF_temp_shap_summary_results = pd.concat(RF_shap_summary_list, ignore_index=True)\n",
    "            \n",
    "            LinSVCKern_temp_auc_results.to_csv(\"TEMP_\" + procedure_of_interest+\"_\" + pickle_folder_name +\"_LinSVCKern_\" + \"auc_data.csv\")\n",
    "            LinSVCKern_temp_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_\" + pickle_folder_name +\"_LinSVCKern_\"+ \"model_results.csv\")\n",
    "            #RF_temp_shap_summary_results.to_csv(\"TEMP_\" +procedure_of_interest+\"_RF_\"+\"feature_importance.csv\")\n",
    "            \n",
    "            \n",
    "            '''\n",
    "            collect_shap_results(SVCKern_shap_full_list, SVCKern_shap_summary_list, shap_values, \n",
    "                                    y_test, x_cols, x_test_features_long, outcome, procedure_of_interest, feature, \"LinSVC_Kernel\",\n",
    "                                    rep, i)\n",
    "            '''\n",
    "            \n",
    "            \n",
    "\n",
    "    LinSVC_Kernel_results = pd.concat(SVCKern_results_list, ignore_index=True)\n",
    "    LinSVC_Kernel_auc = pd.concat(SVCKern_auc_list, ignore_index=True)\n",
    "    LinSVC_Kernel_kernels = pd.concat(SVCKern_kernel_list, ignore_index=True)\n",
    "    #LinSVC_Kernel_shap_full = pd.concat(SVCKern_shap_full_list, ignore_index=True)\n",
    "    #LinSVC_Kernel_shap_summary = pd.concat(SVCKern_shap_summary_list, ignore_index=True)\n",
    "\n",
    "    return LinSVC_Kernel_results, LinSVC_Kernel_auc, LinSVC_Kernel_kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinSVC Kernel Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinSVC w/ Kernel no shap implementation right now TODO\n",
    "import time\n",
    "LinSVC_Kernel_start_time = time.time()\n",
    "LinSVC_Kernel_results, LinSVC_Kernel_auc, LinSVC_Kernel_kernels = LinSVC_Kernel_model_train_test(procedure_of_interest)\n",
    "log_execution(csv_path, \"LinSVC_Kernel\", LinSVC_Kernel_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinSVC Kernel Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinSVC_Kernel_auc.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_LinSVCKernel_\" + \"auc_data.csv\")\n",
    "LinSVC_Kernel_results.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_LinSVCKernel_\"+ \"model_results.csv\")\n",
    "LinSVC_Kernel_kernels.to_csv(procedure_of_interest+\"_\" + pickle_folder_name +\"_LinSVCKernel_\"+ \"kernelstested.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shap Stuff for full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeData_FullDataset(x_train, y_train, rep, impute_number):\n",
    "    # Combine x_train and y_train for imputation\n",
    "    x_train = x_train.reset_index(drop=True)\n",
    "\n",
    "    train_data = x_train.copy()\n",
    "    train_data['target'] = y_train\n",
    "\n",
    "    # Create and fit the imputation kernel\n",
    "    \n",
    "    kernel = mf.ImputationKernel(\n",
    "        train_data,\n",
    "        random_state=rep,\n",
    "        variable_schema = NaNColumn_list\n",
    "    )\n",
    "    \n",
    "    # Use sklearn pipeline method (as in examples)\n",
    "    pipe = Pipeline([('impute', kernel)])\n",
    "    \n",
    "    # Perform imputation\n",
    "    #kernel.mice(impute_number, verbose=True)  # Run 5 iterations, adjust as needed\n",
    "    \n",
    "    # Get the imputed training data\n",
    "    #imputed_train = kernel.complete_data()\n",
    "\n",
    "    imputed_train = pipe.fit_transform(train_data, impute__iterations = impute_number,\n",
    "                                       impute__verbose=True)\n",
    "    \n",
    "    #imputed_train = post_imputation_cleanup(imputed_train)\n",
    "\n",
    "    assert not np.any(np.isnan(imputed_train))\n",
    "\n",
    "    # Separate features and target\n",
    "    x_train_imputed = imputed_train.drop('target', axis=1)\n",
    "    y_train_imputed = imputed_train['target']\n",
    "    \n",
    "    return x_train_imputed, y_train_imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataFrameConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, numeric_features, original_dtypes=None):\n",
    "        self.numeric_features = numeric_features\n",
    "        self.original_dtypes = original_dtypes #actually all Int64\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # We don't want to get dtypes from X here since it's already transformed\n",
    "        # Instead, we'll pass in the original dtypes when creating the transformer\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame(X, columns=self.original_dtypes.index)\n",
    "        \n",
    "        # Restore original dtypes for non-numeric columns\n",
    "        non_numeric_cols = [col for col in df.columns if col not in self.numeric_features]\n",
    "        for col in non_numeric_cols:\n",
    "            # Force the conversion using round() for integers\n",
    "            df[col] = df[col].round()\n",
    "            df[col] = df[col].astype('Int64')\n",
    "            \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get code ready for imputation\n",
    "# Create standardized datasets\n",
    "def preImpute_Full(input_X, input_y, rep, preprocessor, impute_number):\n",
    "    '''\n",
    "    input_X: X_data (df_preds)\n",
    "    input_y: y_data (outcomes, no need to impute)\n",
    "\n",
    "    Outputs:\n",
    "    x_train: imputed X_data (df_preds)\n",
    "    y_train: y_data (outcomes, no need to impute)\n",
    "    x_train_features_long: long form of imputed X_data (each feature each patient)\n",
    "    n_features: number of features\n",
    "    x_cols: list of features\n",
    "    x_train_std: standardized imputed X_data (df_preds)\n",
    "    \n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    X_train = input_X.copy()\n",
    "    y_train = input_y.copy()    \n",
    "    \n",
    "\n",
    "\n",
    "    # remove the identifier columns and save them separately\n",
    "    x_train = X_train.drop(columns = [\"ir_id\", \"surgery_start_datetime\"])\n",
    "    x_train_id_cols = X_train[[\"ir_id\", \"surgery_start_datetime\"]]\n",
    "    x_train_id_cols = x_train_id_cols.reset_index(drop=True)\n",
    "    y_train = y_train.copy()\n",
    "    \n",
    "    print(f\"Shape of X_train: {x_train.shape}\")\n",
    "    #IMPUTED VALUES\n",
    "    x_train, y_train = imputeData_FullDataset(x_train, y_train, rep, impute_number)\n",
    "    \n",
    "    print(f'Shape of imputed x_train: {x_train.shape}')\n",
    "    x_train_std = preprocessor.fit_transform(x_train)\n",
    "    '''\n",
    "    testingConverter = DataFrameConverter(\n",
    "                            numeric_features=numeric_features, \n",
    "                            original_dtypes=x_train.dtypes\n",
    "                        )\n",
    "    x_train_std = testingConverter.fit_transform(x_train_std)\n",
    "    '''\n",
    "    x_train_std = save_dtypes(x_train_std, x_train, preprocessor)\n",
    "    # Keep a version that has those values as index columns \n",
    "\n",
    "    x_train_features = x_train.copy() #use imputed data \n",
    "    # Add back the identifier columns\n",
    "    x_train_features = pd.concat([x_train_id_cols, x_train_features], axis=1)\n",
    "\n",
    "    x_train_features[\"Patient_ID\"]=  np.arange(len(x_train_features))\n",
    "\n",
    "    x_train_features_long = pd.melt(x_train_features, id_vars = [\"ir_id\", \"Patient_ID\", \"surgery_start_datetime\"], var_name = \"Feature_Name\", value_name = \"Feature_Actual_Value\" )\n",
    "    \n",
    "    x_train_features_long['Feature_Actual_Value'] = pd.to_numeric(x_train_features_long['Feature_Actual_Value'])\n",
    "\n",
    "    x_cols = x_train.columns\n",
    "\n",
    "    n_features = len(x_cols)\n",
    "    print(f'Number of Features: {n_features}')\n",
    "\n",
    "    \n",
    "    return x_train, y_train, x_train_features_long, n_features, x_cols, x_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_full_dataset_model(outcome, preprocessor, x_train, y_train, x_train_std, rep, n_features_in):\n",
    "    '''\n",
    "    Actual RF model\n",
    "    Inputs: outcome (str): name of the outcome variable\n",
    "            preprocessor (sklearn.preprocessing): standardizing preprocessor object\n",
    "            x_train (pd.DataFrame): full X data\n",
    "            y_train (pd.Series): full y data\n",
    "            x_train_std (np.array): standardized X data\n",
    "            rep (int): random state for reproducibility\n",
    "\n",
    "    Outputs: \n",
    "             cv_model : fitted model object\n",
    "             y_pred : predicted class for test data\n",
    "             y_prob_vec : predicted probability for test data\n",
    "    '''\n",
    "    print(f\"Size of X is: {x_train.shape}\")\n",
    "    print(f\"Size of y is: {y_train.shape}\")\n",
    "\n",
    "    if outcome in binary_outcomes:\n",
    "        original_dtypes = x_train.dtypes\n",
    "        pipe = Pipeline([('processing', preprocessor), \n",
    "                         #('dtype_converter', DataFrameConverter(numeric_features=numeric_features, original_dtypes=original_dtypes)),\n",
    "                            ('estimator', BalancedRandomForestClassifier(random_state = rep,\n",
    "                                                                         sampling_strategy='all',\n",
    "                                                                         replacement=True,\n",
    "                                                                         bootstrap=False\n",
    "                                                                         ))]) \n",
    "\n",
    "        model_params = {\n",
    "            'estimator__n_estimators': hp.uniformint('estimator__n_estimators', 50, 250),\n",
    "            'estimator__max_features': hp.uniformint('estimator__max_features', 2, n_features_in),\n",
    "            'estimator__max_depth': hp.uniformint('estimator__max_depth', 1, 25),\n",
    "            'estimator__min_samples_split': hp.uniformint('estimator__min_samples_split', 2, 10),\n",
    "            'estimator__min_samples_leaf': hp.uniformint('estimator__min_samples_leaf', 1, 5),\n",
    "        }\n",
    "\n",
    "        cv_model = TuneSearchCV(pipe,\n",
    "                                param_distributions = model_params, n_trials = tunesearch_iterations,\n",
    "                                scoring='roc_auc', # AUC is most important metric\n",
    "                                refit=True, cv=5, n_jobs = 7,\n",
    "                                random_state = rep,\n",
    "                                search_optimization = \"hyperopt\",\n",
    "                                verbose = 2)\n",
    "\n",
    "        cv_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "        y_pred = cv_model.predict(x_train) # generate prediction (0 or 1) on input dataset\n",
    "        y_prob = cv_model.predict_proba(x_train) # generate prediction probability ([0,1])\n",
    "        y_prob_vec = y_prob[:,1]\n",
    "    \n",
    "    elif outcome in continuous_outcomes:\n",
    "\n",
    "        print(\"In Progress\")\n",
    "\n",
    "    \n",
    "\n",
    "    return cv_model, y_pred, y_prob_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def booltoInt(df):\n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Get all boolean columns\n",
    "    bool_columns = df.select_dtypes(include=['bool']).columns\n",
    "    if len(bool_columns) > 0:\n",
    "        print(\"Converting the following columns from boolean to int64:\")\n",
    "        for col in bool_columns:\n",
    "            print(f\"- {col}\")\n",
    "            df[col] = df[col].astype('Int64')\n",
    "    else:\n",
    "        print(\"No boolean columns found to convert\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTUAL CODE\n",
    "# Get all columns with NA values\n",
    "# Get X and y and impute (copy code from train test)\n",
    "import pickle\n",
    "label_vec = {\n",
    "    \"ir_id\": \"Patient ID\",\n",
    "    \"surgery_start_datetime\": \"Surgery Start Time\",\n",
    "    \"age_at_procedure\": \"Age at Procedure\",\n",
    "    \"gender_female\": \"Gender: Female\",\n",
    "    \"BMI\": \"Body Mass Index (BMI)\",\n",
    "    \"elix_aids_hiv\": \"Elix: AIDS/HIV\",\n",
    "    \"elix_lymphoma\": \"Elix: Lymphoma\",\n",
    "    \"elix_paralysis\": \"Elix: Paralysis\",\n",
    "    \"elix_psychoses\": \"Elix: Psychoses\",\n",
    "    \"elix_depression\": \"Elix: Depression\",\n",
    "    \"elix_drug_abuse\": \"Elix: Drug Abuse\",\n",
    "    \"elix_weight_loss\": \"Elix: Weight Loss\",\n",
    "    \"elix_coagulopathy\": \"Elix: Coagulopathy\",\n",
    "    \"elix_alcohol_abuse\": \"Elix: Alcohol Abuse\",\n",
    "    \"elix_liver_disease\": \"Elix: Liver Disease\",\n",
    "    \"elix_renal_failure\": \"Elix: Renal Failure\",\n",
    "    \"elix_hypothyroidism\": \"Elix: Hypothyroidism\",\n",
    "    \"elix_valvular_disease\": \"Elix: Valvular Disease\",\n",
    "    \"elix_blood_loss_anemia\": \"Elix: Blood Loss Anemia\",\n",
    "    \"elix_deficiency_anemia\": \"Elix: Deficiency Anemia\",\n",
    "    \"elix_metastatic_cancer\": \"Elix: Metastatic Cancer\",\n",
    "    \"elix_cardiac_arrhythmia\": \"Elix: Cardiac Arrhythmia\",\n",
    "    \"elix_rheumatoid_arhritis\": \"Elix: Rheumatoid Arthritis\",\n",
    "    \"elix_diabetes_complicated\": \"Elix: Complicated Diabetes\",\n",
    "    \"elix_diabetes_uncomplicated\": \"Elix: Uncomplicated Diabetes\",\n",
    "    \"elix_congestive_heart_failure\": \"Elix: Congestive Heart Failure\",\n",
    "    \"elix_hypertension_complicated\": \"Elix: Complicated Hypertension\",\n",
    "    \"elix_chronic_pulmonary_disease\": \"Elix: Chronic Pulmonary Disease\",\n",
    "    \"elix_solid_tumor_wo_metastasis\": \"Elix: Solid Tumor (Without Metastasis)\",\n",
    "    \"elix_hypertension_uncomplicated\": \"Elix: Uncomplicated Hypertension\",\n",
    "    \"elix_other_neurological_disorder\": \"Elix: Other Neurological Disorder\",\n",
    "    \"elix_peripheral vascular_disorder\": \"Elix: Peripheral Vascular Disorder\",\n",
    "    \"elix_pulmonary_circulation_disorder\": \"Elix: Pulmonary Circulation Disorder\",\n",
    "    \"elix_fluid_and_electrolyte_disorders\": \"Elix: Fluid and Electrolyte Disorders\",\n",
    "    \"elix_peptic_ulcer_disease_excluding_bleeding\": \"Elix: Peptic Ulcer Disease (Excluding Bleeding)\",\n",
    "    \"validation_cur_tobacco\": \"Current Tobacco Use Validation\",\n",
    "    \"validation_fmr_tobacco\": \"Former Tobacco Use Validation\",\n",
    "    \"shx_cervical_fusion\": \"History of Cervical Fusion\",\n",
    "    \"shx_cervical_surgery\": \"History of Cervical Surgery\",\n",
    "    \"shx_thoracolumbar_fusion\": \"History of Thoracolumbar Fusion\",\n",
    "    \"shx_thoracolumbar_surgery\": \"History of Thoracolumbar Surgery\",\n",
    "    \"shx_unspecified_spine_fusion\": \"History of Unspecified Spine Fusion\",\n",
    "    \"shx_unspecified_spine_surgery\": \"History of Unspecified Spine Surgery\",\n",
    "    \"lumbar_stenosis\": \"Lumbar Stenosis\",\n",
    "    \"lumbar_spondy\": \"Lumbar Spondylolisthesis\",\n",
    "    \"lumbar_disc_disorders\": \"Lumbar Disc Disorders\",\n",
    "    \"cervical_disc_diorders\": \"Cervical Disc Disorders\",\n",
    "    \"cervical_stenosis\": \"Cervical Stenosis\",\n",
    "    \"cervical_spondy\": \"Cervical Spondylolisthesis\",\n",
    "    \"cervical_disc_herniation\": \"Cervical Disc Herniation\",\n",
    "    \"lumbar_disc_herniation\": \"Lumbar Disc Herniation\",\n",
    "    \"preop_med_90days_ace_inhibitor\": \"Preoperative ACE Inhibitor Use (90 Days)\",\n",
    "    \"preop_med_90days_arb\": \"Preoperative ARB Use (90 Days)\",\n",
    "    \"preop_med_90days_antidepressant\": \"Preoperative Antidepressant Use (90 Days)\",\n",
    "    \"preop_med_90days_beta_2_agonist\": \"Preoperative Beta-2 Agonist Use (90 Days)\",\n",
    "    \"preop_med_90days_beta_blocker\": \"Preoperative Beta Blocker Use (90 Days)\",\n",
    "    \"preop_med_90days_benzodiazepine\": \"Preoperative Benzodiazepine Use (90 Days)\",\n",
    "    \"preop_med_90days_immunosuppresant\": \"Preoperative Immunosuppressant Use (90 Days)\",\n",
    "    \"preop_med_90days_nsaid\": \"Preoperative NSAID Use (90 Days)\",\n",
    "    \"preop_med_90days_opioid\": \"Preoperative Opioid Use (90 Days)\",\n",
    "    \"preop_med_90days_anti_psychotic\": \"Preoperative Antipsychotic Use (90 Days)\",\n",
    "    \"preop_med_90days_neuromodulator\": \"Preoperative Neuromodulator Use (90 Days)\",\n",
    "    \"preop_med_90days_biphosphonate\": \"Preoperative Biphosphonate Use (90 Days)\",\n",
    "    \"preop_med_90days_loop_diuretic\": \"Preoperative Loop Diuretic Use (90 Days)\",\n",
    "    \"preop_med_90days_thiazide_diuretic\": \"Preoperative Thiazide Diuretic Use (90 Days)\",\n",
    "    \"preop_med_90days_cinacalcet\": \"Preoperative Cinacalcet Use (90 Days)\",\n",
    "    \"preop_med_90days_insulin\": \"Preoperative Insulin Use (90 Days)\",\n",
    "    \"preop_med_90days_oral_diabetes\": \"Preoperative Oral Diabetes Medication Use (90 Days)\",\n",
    "    \"preop_med_90days_calcium_supplement\": \"Preoperative Calcium Supplement Use (90 Days)\",\n",
    "    \"preop_med_90days_vit_d_supplement\": \"Preoperative Vitamin D Supplement Use (90 Days)\",\n",
    "    \"OR_duration_hours\": \"OR Duration (Hours)\",\n",
    "    \"anesthesia_duration_hours\": \"Anesthesia Duration (Hours)\",\n",
    "    \"OR_length_minutes\": \"OR Duration (Minutes)\",\n",
    "    \"cpt_multilevel\": \"Multilevel Procedure\",\n",
    "    \"cpt_instrumentation\": \"Instrumentation\",\n",
    "    \"cohort_query_microdisc\": \"Microdiscectomy\",\n",
    "    \"anesthesia_type_General\": \"Anesthesia Type: General\",\n",
    "    \"procedure_setting_Inpatient\": \"Procedure Setting: Inpatient\",\n",
    "    \"cpt_anterior_approach\": \"Anterior Approach\",\n",
    "    \"cpt_lateral_approach\": \"Lateral Approach\",\n",
    "    \"cpt_posterior_approach\": \"Posterior Approach\",\n",
    "    \"ltc_postlaminectomy_syndrome\": \"Outcome: Post-Laminectomy Syndrome\",\n",
    "    \"1_year_ltc_postlaminectomy_syndrome\": \"Outcome: 1-year Post-Laminectomy Syndrome\",\n",
    "    \"spine_preop_pseudoarthrosis_post_fusion\": \"Preoperative Pseudoarthrosis Post-Fusion\",\n",
    "    \"spine_preop_post_laminectomy_syndrome\": \"Preoperative Post-Laminectomy Syndrome\"\n",
    "\n",
    "}\n",
    "\n",
    "reptouse = 0\n",
    "\n",
    "\n",
    "os.makedirs(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed', exist_ok=True)\n",
    "print(f'Imputing full dataset for {FullDataset_model}, with {procedure_of_interest}')\n",
    "\n",
    "#Set preprocessor\n",
    "preprocessor_RF, skf = scaleAnd_skf(numeric_features, outcome, reptouse, fulldataset=True)\n",
    "print(f\"The number of columns with missing data: {NaNColumn_list}\")\n",
    "\n",
    "trainingdata = preImpute_Full(df_preds, y, reptouse, preprocessor_RF,\n",
    "                                        impute_iterations)\n",
    "x_train_bools, y_train, x_train_features_long, n_features, x_cols, x_train_std = trainingdata\n",
    "\n",
    "x_train = booltoInt(x_train_bools)\n",
    "\n",
    "trainingdata = x_train, y_train, x_train_features_long, n_features, x_cols, x_train_std\n",
    "\n",
    "print(f\"XShape {x_train.shape}\")\n",
    "print(f\"This is the {pickle_folder_name} dataset\")\n",
    "print(f\"Procedure: {procedure_of_interest}\")\n",
    "print(f\"Feature: {feature}\")\n",
    "print(f\"Outcome: {outcome}\")\n",
    "print(f\"Rep seed: {reptouse}\")\n",
    "print(f\"Type of shap collection: {feature_perturbation_version}\")\n",
    "\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/trainingdata.pkl', 'wb') as f:\n",
    "    pickle.dump(trainingdata, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Model (pickled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE ACTUAL MODEL\n",
    "\n",
    "\n",
    "full_RF_start_time = time.time()\n",
    "csv_path_full = f\"{procedure_of_interest}_Full_RF_execution_{date}.csv\"\n",
    "\n",
    "ModelRF_pickle = RF_full_dataset_model(outcome, preprocessor_RF, x_train, y_train,\n",
    "                      x_train_std, reptouse, n_features)\n",
    "\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/modelpickle.pkl', 'wb') as f:\n",
    "    pickle.dump(ModelRF_pickle, f)\n",
    "\n",
    "log_execution(csv_path_full, \"RF_full_model\", full_RF_start_time)\n",
    "\n",
    "#Pickle the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect full model results (tested on training dataset)\n",
    "import pandas as pd\n",
    "RF_Full_results_list = []\n",
    "RF_Full_auc_list = []\n",
    "print(f'Getting from {FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/modelpickle.pkl')\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/modelpickle.pkl', 'rb') as f:\n",
    "    full_model_pickled = pickle.load(f)\n",
    "\n",
    "\n",
    "#unpickle\n",
    "RF_cvmodel, y_pred, y_prob_vec, = full_model_pickled\n",
    "\n",
    "#collect results\n",
    "collect_results(RF_Full_results_list,  RF_Full_auc_list, outcome, procedure_of_interest, \n",
    "                feature, \"RF_Full_dataset\", reptouse, 0, n, label_n, y_train, y_prob_vec,\n",
    "                y_pred)\n",
    "RF_full_results = pd.concat(RF_Full_results_list, ignore_index=True)\n",
    "RF_full_auc_results = pd.concat(RF_Full_auc_list, ignore_index=True)\n",
    "\n",
    "#Save these results as csvs\n",
    "RF_full_auc_results.to_csv(FullDataset_model + \"_\" + procedure_of_interest + \"_FullModel_Imputed/\" + procedure_of_interest+\"_FULL_\" + pickle_folder_name +\"_RF_\" + \"auc_data.csv\")\n",
    "RF_full_results.to_csv(FullDataset_model + \"_\" + procedure_of_interest + \"_FullModel_Imputed/\" +procedure_of_interest+\"_FULL_\" + pickle_folder_name +\"_RF_\"+ \"model_results.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_std.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get shaps (pickled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET THE SHAPS!\n",
    "#THIS IS PICKLED\n",
    "Get_shaps = True\n",
    "csv_path_full = f\"{procedure_of_interest}_Full_RF_execution_{date}.csv\"\n",
    "print(f\"Get shaps using {FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/modelpickle.pkl\")\n",
    "print(f\"Feature perturbation version used is: {feature_perturbation_version}\")\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/modelpickle.pkl', 'rb') as f:\n",
    "    full_model_pickled = pickle.load(f)\n",
    "\n",
    "\n",
    "#unpickle\n",
    "RF_cvmodel, y_pred, y_prob_vec, = full_model_pickled\n",
    "\n",
    "RF_shap_full_starttime = time.time()\n",
    "if Get_shaps:\n",
    "    print(\"GET SHAPS\")\n",
    "    if feature_perturbation_version == \"interventional\":\n",
    "        explainer = shap.TreeExplainer(RF_cvmodel.best_estimator_.named_steps['estimator'], data=x_train_std, feature_perturbation= \"interventional\",\n",
    "                                        model_output = \"probability\")\n",
    "    elif feature_perturbation_version == \"tree_path_dependent\":\n",
    "        explainer = shap.TreeExplainer(RF_cvmodel.best_estimator_.named_steps['estimator'], feature_perturbation= \"tree_path_dependent\",\n",
    "                                        model_output = \"raw\")\n",
    "    print(\"Getting shap values\")\n",
    "    shap_values_3d = explainer.shap_values(x_train_std)\n",
    "    print(shap_values_3d.shape)\n",
    "    shap_values = shap_values_3d[:, :, 1]\n",
    "    print(shap_values.shape)\n",
    "    print(\"done getting shap values\")\n",
    "    #shap_values_explainer = explainer(x_train_std)\n",
    "    with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl', 'wb') as f:\n",
    "        pickle.dump([shap_values, shap_values_3d, explainer], f)\n",
    "\n",
    "    log_execution(csv_path_full, \"RF_shap_full\", RF_shap_full_starttime)\n",
    "    \n",
    "else:\n",
    "    shap_values = None\n",
    "    print(\"NO SHAPS FOR YOU\")\n",
    "Get_shaps = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vizualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bar plot top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column Mapping\n",
    "\n",
    "# Do Shap bar plot\n",
    "print(f'Getting from {FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl')\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl', 'rb') as f:\n",
    "        full_dataset_shaps, full_dataset_shaps_3d, shap_explainer = pickle.load(f)\n",
    "x_train_std_display = x_train_std.copy()\n",
    "x_train_std_display = x_train_std_display.rename(columns=label_vec) # make column names look nice\n",
    "\n",
    "print(full_dataset_shaps.shape)\n",
    "#Using column order of x_train_std\n",
    "#reorder columns of x_train\n",
    "x_train_display = x_train.copy()\n",
    "x_train_display = x_train_display[x_train_std.columns] #make sure x_train display has columns in same order as std, passed into shap\n",
    "x_train_display = x_train_display.rename(columns=label_vec) #make column names look nice\n",
    "\n",
    "# Create figure and plot\n",
    "plt.figure()\n",
    "shap.summary_plot(full_dataset_shaps, x_train_display, plot_type=\"bar\", max_display=10, show=False, show_values_in_legend=True)\n",
    "# Change x-axis label\n",
    "# Adjust subplot parameters\n",
    "plt.subplots_adjust(left=.1, right=.6)\n",
    "plt.gca().set_xlabel('mean(|SHAP value|)')\n",
    "# Save the plot\n",
    "plt.savefig(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_bar_plot_{feature_perturbation_version}.png', \n",
    "            bbox_inches='tight', \n",
    "            dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Beeswarm top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Beeswarm plot\n",
    "print(f'Getting from {FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl')\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl', 'rb') as f:\n",
    "        full_dataset_shaps, full_dataset_shaps_3d, shap_explainer = pickle.load(f)\n",
    "x_train_std_display = x_train_std.copy()\n",
    "x_train_std_display = x_train_std_display.rename(columns=label_vec)\n",
    "\n",
    "#Using column order of x_train_std\n",
    "#reorder columns of x_train\n",
    "x_train_display = x_train.copy()\n",
    "x_train_display = x_train_display[x_train_std.columns]\n",
    "x_train_display = x_train_display.rename(columns=label_vec)\n",
    "\n",
    "\n",
    "# Create figure and plot\n",
    "plt.figure()\n",
    "shap_plot = shap.summary_plot(full_dataset_shaps, x_train_display, max_display=10, show = False)\n",
    "# Change x-axis label\n",
    "ax = plt.gca()\n",
    "\n",
    "for artist in ax.collections:\n",
    "    artist._sizes = [0.5]  # or try an even smaller number like 0.5\n",
    "# Adjust subplot parameters\n",
    "plt.subplots_adjust(left=.1, right=.6)\n",
    "# Save the plot\n",
    "plt.savefig(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_beeswarm_plot_{feature_perturbation_version}.png', \n",
    "            bbox_inches='tight', \n",
    "            dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Barplot all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Do Shap bar plot\n",
    "print(f'Getting from {FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl')\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl', 'rb') as f:\n",
    "        full_dataset_shaps, full_dataset_shaps_3d, shap_explainer = pickle.load(f)\n",
    "x_train_std_display = x_train_std.copy()\n",
    "x_train_std_display = x_train_std_display.rename(columns=label_vec)\n",
    "\n",
    "\n",
    "#Using column order of x_train_std\n",
    "#reorder columns of x_train\n",
    "x_train_display = x_train.copy()\n",
    "x_train_display = x_train_display[x_train_std.columns]\n",
    "x_train_display = x_train_display.rename(columns=label_vec)\n",
    "\n",
    "# Create figure and plot\n",
    "plt.figure()\n",
    "shap.summary_plot(full_dataset_shaps, x_train_display, plot_type=\"bar\", max_display=200, show=False, show_values_in_legend=True)\n",
    "# Change x-axis label\n",
    "# Adjust subplot parameters\n",
    "plt.subplots_adjust(left=.1, right=.6)\n",
    "plt.gca().set_xlabel('mean(|SHAP value|)')\n",
    "# Save the plot\n",
    "plt.savefig(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_bar_plot_all_{feature_perturbation_version}.png', \n",
    "            bbox_inches='tight', \n",
    "            dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Beeswarm all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Beeswarm plot\n",
    "print(f'Getting from {FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl')\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl', 'rb') as f:\n",
    "        full_dataset_shaps, full_dataset_shaps_3d, shap_explainer = pickle.load(f)\n",
    "x_train_std_display = x_train_std.copy()\n",
    "x_train_std_display = x_train_std_display.rename(columns=label_vec)\n",
    "\n",
    "#Using column order of x_train_std\n",
    "#reorder columns of x_train\n",
    "x_train_display = x_train.copy()\n",
    "x_train_display = x_train_display[x_train_std.columns]\n",
    "x_train_display = x_train_display.rename(columns=label_vec)\n",
    "\n",
    "\n",
    "# Create figure and plot\n",
    "plt.figure()\n",
    "shap_plot = shap.summary_plot(full_dataset_shaps, x_train_display, max_display=200, show = False)\n",
    "# Change x-axis label\n",
    "ax = plt.gca()\n",
    "\n",
    "for artist in ax.collections:\n",
    "    artist._sizes = [0.5]  # or try an even smaller number like 0.5\n",
    "# Adjust subplot parameters\n",
    "plt.subplots_adjust(left=.1, right=.6)\n",
    "# Save the plot\n",
    "plt.savefig(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_beeswarm_plot_all_{feature_perturbation_version}.png', \n",
    "            bbox_inches='tight', \n",
    "            dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shap interaction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Getting from {FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl')\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl', 'rb') as f:\n",
    "        full_dataset_shaps, full_dataset_shaps_3d, shap_explainer = pickle.load(f)\n",
    "\n",
    "#get shap interaction values (TAKES TIME)\n",
    "\n",
    "shap_interactions = shap_explainer.shap_interaction_values(x_train_std)\n",
    "\n",
    "#pickle them\n",
    "print(\"Pickling shap interaction values\")\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_interaction_values_{feature_perturbation_version}.pkl', 'wb') as f:\n",
    "        pickle.dump(shap_interactions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependence charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup for all charts\n",
    "\n",
    "print(f'Getting from {FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl')\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl', 'rb') as f:\n",
    "        full_dataset_shaps, full_dataset_shaps_3d, shap_explainer = pickle.load(f)\n",
    "x_train_std_display = x_train_std.copy()\n",
    "x_train_std_display = x_train_std_display.rename(columns=label_vec)\n",
    "\n",
    "feature_importance = np.abs(full_dataset_shaps).mean(0)\n",
    "feature_names = x_train_std_display.columns  # or X_train.columns depending on what you're using\n",
    "top_10_idx = np.argsort(feature_importance)[-10:]  # Get indices of top 10 features\n",
    "top_10_features = feature_names[top_10_idx]\n",
    "top_10_columnNames = x_train_std.columns[top_10_idx]\n",
    "print(top_10_features)\n",
    "#print(top_10_columnNames)\n",
    "\n",
    "#Using column order of x_train_std\n",
    "#reorder columns of x_train\n",
    "x_train_display = x_train.copy()\n",
    "x_train_display = x_train_display[x_train_std.columns]\n",
    "x_train_display_with_features = x_train_display.rename(columns=label_vec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/top10dependence', exist_ok=True)\n",
    "\n",
    "for i in range(len(top_10_features)):\n",
    "        column_label = top_10_columnNames[i]\n",
    "        column_to_plot = top_10_features[i]\n",
    "        if len(x_train_display_with_features[column_to_plot].unique()) < 5:\n",
    "                jitter = 0.2\n",
    "                dotsize = 4\n",
    "                print(f\"Jittering for {column_to_plot}\")\n",
    "        else: \n",
    "                jitter = 0\n",
    "                dotsize = 8\n",
    "        print(column_to_plot)\n",
    "        print(x_train_display_with_features[column_to_plot].dtype)\n",
    "        plt.figure()\n",
    "        shap.dependence_plot(column_to_plot, full_dataset_shaps, x_train_display_with_features, alpha = 0.5, dot_size=dotsize, show=False, x_jitter=jitter)\n",
    "        plt.axhline(y=0, color='black', linestyle=':', linewidth=1)        \n",
    "        plt.savefig(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/top10dependence/shap_dependence_{column_label}_{feature_perturbation_version}.png', \n",
    "                                bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 nocolor\n",
    "os.makedirs(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/top10dependence_noColor', exist_ok=True)\n",
    "\n",
    "for i in range(len(top_10_features)):\n",
    "        column_label = top_10_columnNames[i]\n",
    "        column_to_plot = top_10_features[i]\n",
    "        if len(x_train_display_with_features[column_to_plot].unique()) < 5:\n",
    "                jitter = 0.2\n",
    "                dotsize = 4\n",
    "                print(f\"Jittering for {column_to_plot}\")\n",
    "        else: \n",
    "                jitter = 0\n",
    "                dotsize = 8\n",
    "        print(column_to_plot)\n",
    "        print(x_train_display_with_features[column_to_plot].dtype)\n",
    "        plt.figure()\n",
    "        shap.dependence_plot(column_to_plot, full_dataset_shaps, x_train_display_with_features, alpha = 0.5, dot_size=dotsize, show=False, x_jitter=jitter, interaction_index=None)\n",
    "        plt.axhline(y=0, color='black', linestyle=':', linewidth=1)        \n",
    "        plt.savefig(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/top10dependence_noColor/shap_dependence_{column_label}_{feature_perturbation_version}.png', \n",
    "                                bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Numerical Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "columns_to_plot = [\"Age at Procedure\", \"Body Mass Index (BMI)\", \"OR Duration (Minutes)\"]\n",
    "column_labels = [\"age\", \"bmi\", \"ORdur\"]\n",
    "\n",
    "for i in range(len(columns_to_plot)):\n",
    "    column_label = column_labels[i]\n",
    "    column_to_plot = columns_to_plot[i]\n",
    "    plt.figure()\n",
    "    shap.dependence_plot(column_to_plot, full_dataset_shaps, x_train_display_with_features, alpha = 0.5, dot_size=8, show=False)\n",
    "    plt.axhline(y=0, color='black', linestyle=':', linewidth=1)\n",
    "    plt.savefig(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_dependence_{column_label}_{feature_perturbation_version}.png', \n",
    "                bbox_inches='tight', \n",
    "                dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Additional Specific Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion Beta Blocker, color cardiac\n",
    "if procedure_of_interest == \"Fusion\":\n",
    "\n",
    "    #make directory for these\n",
    "    os.makedirs(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/cardiacs_colored_beta', exist_ok=True)\n",
    "    cardiac_comorbidities = {\"Elix: Cardiac Arrhythmia\": \"arrythmia\", \n",
    "                            \"Elix: Congestive Heart Failure\": \"CHF\", \n",
    "                            \"Elix: Valvular Disease\": \"Valvular_Disease\",\n",
    "                            \"Elix: Complicated Hypertension\": \"HTN_Compl\", \n",
    "                            \"Elix: Uncomplicated Hypertension\": \"HTN_Uncompl\"\n",
    "    }\n",
    "    jitter = 0.2\n",
    "    dotsize = 4\n",
    "\n",
    "    for (key, value) in cardiac_comorbidities.items():\n",
    "        plt.figure()\n",
    "        shap.dependence_plot(key, full_dataset_shaps, x_train_display_with_features, alpha = 0.5, dot_size=dotsize, show=False,\n",
    "                            interaction_index = \"Preoperative Beta Blocker Use (90 Days)\", x_jitter = jitter)\n",
    "        # Add horizontal dotted line at y=0\n",
    "        plt.axhline(y=0, color='black', linestyle=':', linewidth=1)\n",
    "        plt.savefig(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/cardiacs_colored_beta/shap_dependence_{value}_{feature_perturbation_version}.png', \n",
    "                    bbox_inches='tight', \n",
    "                    dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardiac_comorbidities = [\"elix_cardiac_arrhythmia\", \"elix_congestive_heart_failure\", \"elix_valvular_disease\", \"elix_hypertension_complicated\", \"elix_hypertension_uncomplicated\"]\n",
    "x_train_cardiac = x_train.copy()\n",
    "x_train_cardiac['cardiac_comorbidities'] = x_train_cardiac[cardiac_comorbidities].any(axis=1).astype(\"Int64\")\n",
    "\n",
    "# Create the contingency table with descriptive labels\n",
    "beta_blocker_cardiac_contingency = pd.crosstab(\n",
    "    x_train_cardiac['cardiac_comorbidities'], \n",
    "    x_train_cardiac[\"preop_med_90days_beta_blocker\"],\n",
    "    margins=True,  # This adds row and column totals\n",
    "    margins_name='Total'\n",
    ")\n",
    "\n",
    "# Rename the index and columns for clarity\n",
    "beta_blocker_cardiac_contingency.index = ['No Cardiac Disease', 'Has Cardiac Disease', 'Total']\n",
    "beta_blocker_cardiac_contingency.columns = ['No Beta Blocker', 'On Beta Blocker', 'Total']\n",
    "\n",
    "# Optional: Add a title\n",
    "print(\"Contingency Table: Cardiac Disease vs Beta Blocker Use\")\n",
    "print(beta_blocker_cardiac_contingency)\n",
    "\n",
    "beta_blocker_cardiac_contingency.to_csv(f\"{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/cardiacs_colored_beta/beta_blocker_cardiac_contingency.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "table_no_margins = beta_blocker_cardiac_contingency.iloc[:-1,:-1]\n",
    "print(table_no_margins)\n",
    "chi2, p_value, dof, expected = chi2_contingency(table_no_margins)\n",
    "print(f\"Chi-square statistic: {chi2}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "print(f\"Expected frequencies: {expected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explainer Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainerdashboard import ClassifierExplainer, ExplainerDashboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/modelpickle.pkl', 'rb') as f:\n",
    "    full_model_pickled = pickle.load(f)\n",
    "\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/trainingdata.pkl', 'rb') as g:\n",
    "    training_data = pickle.load(g)\n",
    "\n",
    "print(f'Getting from {FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl')\n",
    "with open(f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/shap_values_{feature_perturbation_version}.pkl', 'rb') as f:\n",
    "        full_dataset_shaps, full_dataset_shaps_3d, shap_explainer = pickle.load(f)\n",
    "\n",
    "#unpickle\n",
    "print(f\"Unpickling from {FullDataset_model}, {procedure_of_interest}\")\n",
    "RF_cvmodel, y_pred, y_prob_vec, = full_model_pickled\n",
    "x_train, y_train, x_train_features_long, n_features, x_cols, x_train_std = training_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make and set shaps for explainer\n",
    "\n",
    "dashboardExplainer = ClassifierExplainer(model=RF_cvmodel.best_estimator_, X=x_train, y=y_train, shap='tree', model_output='raw',\n",
    "                                         target='1_year_ltc_postlaminectomy_syndrome', index_name=\"PtIndex\")\n",
    "dashboardExplainer.set_shap_values([-0.5, 0.5], [-full_dataset_shaps, full_dataset_shaps])\n",
    "\n",
    "explainerLocation = f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/explainer.joblib'\n",
    "dashboardExplainer.dump(explainerLocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numeric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dashboard Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainerLocation = f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/explainer.joblib'\n",
    "\n",
    "explainer =  ClassifierExplainer.from_file(explainerLocation)\n",
    "dashboard = ExplainerDashboard(\n",
    "    explainer,\n",
    "    tabs=['whatif'],  # Show only the What-If tab\n",
    "    title=\"What-If Analysis Dashboard\"\n",
    ")\n",
    "# Save the dashboard to a pickle file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainLocation = f'{FullDataset_model}_{procedure_of_interest}_FullModel_Imputed/'\n",
    "dashboard.to_yaml(mainLocation+\"dashboard.yaml\", explainerfile=\"explainer.joblib\" , dump_explainer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = ExplainerDashboard.from_config(mainLocation+\"explainer.joblib\", mainLocation+\"dashboard.yaml\")\n",
    "app = db.flask_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ngrok\n",
    "# Expose local port using ngrok\n",
    "public_url = ngrok.connect(805)  # Expose port 8050\n",
    "print(f\"Dashboard is live at: {public_url}\")\n",
    "\n",
    "# Run the dashboard\n",
    "dashboard.run(port=805)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do all repetitions\n",
    "\n",
    "for rep in repetitions:\n",
    "    preprocessor, skf = scaleAnd_skf(numeric_features, outcome, rep)\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(dum_df, y)):\n",
    "        # Create all the different train_test splits\n",
    "        x_train_actual, x_val, y_train_actual, y_val, x_train, x_test, y_train, y_test, \\\n",
    "        x_test_features_long, n_features, x_cols, x_train_std, x_test_std = set_train_test(dum_df= dum_df, y=y, train_index=train_index, test_index=test_index, rep=rep, preprocessor=preprocessor)\n",
    "\n",
    "        for model in model_set:\n",
    "            \n",
    "            '''\n",
    "            print(procedure)\n",
    "            print(feature)\n",
    "            print(outcome)\n",
    "            print(rep)\n",
    "            print(i)\n",
    "            \n",
    "            print(model)\n",
    "            print(time.strftime('%X %x %Z'))\n",
    "            '''\n",
    "            if model == \"ASA\":\n",
    "                asa_model_fitted, y_pred, y_prob_vec = ASA_model(x_train, x_test, y_train, rep)\n",
    "\n",
    "            elif model == \"ASA_categorical\":\n",
    "                y_pred, y_prob_vec_two = ASA_categorical_model(x_test=x_test)\n",
    "                print(y_prob_vec_two)\n",
    "                        \n",
    "            elif model == \"ENet\":\n",
    "                ENet_model_fitted, y_pred, y_prob_vec, shap_values = ENet_model(outcome, preprocessor, x_train, y_train,\n",
    "                                                                                x_test, x_train_std, x_test_std, rep)    \n",
    "            elif model == \"XGBoost\":\n",
    "                XGBoost_model_fitted, y_pred, y_prob_vec, shap_values = XGBoost_model(outcome, preprocessor, x_train,\n",
    "                                                                              y_train, x_test, x_train_std, x_test_std,\n",
    "                                                                              rep)\n",
    "            \n",
    "            elif model == \"RF\": \n",
    "                \n",
    "                   \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_results_output = pd.concat(feature_results, ignore_index = True)\n",
    "feature_results_output.to_csv(\"thumb_arthro_features_3_11_23_partial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(np.repeat(row, len(x_cols)))\n",
    "print(len(shap_values_row))\n",
    "print(len(temp_feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_features_shap.to_csv(\"tester_shap.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    output_file_results.to_csv(file_name_results)\n",
    "    \n",
    "    \n",
    "    feature_file_results = pd.concat(feature_results)\n",
    "    feature_file_results = feature_file_results[feature_file_results['Procedure'] == procedure]\n",
    "    feature_file_results.to_csv(file_name_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_plot_results.to_csv(\"auc_results_health_util_11_7_22.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(output_file_results)\n",
    "np.median(output_file_results['MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shap_features_row)\n",
    "\n",
    "#shap_features_row.to_csv(\"NN_feature_test.csv\")\n",
    "\n",
    "summarized_features_shap = shap_features_row.groupby(['Feature_Name']).agg(\n",
    "    Feature_Mean_Abs = ('Feature_Value_Abs','mean'),   \n",
    "    Feature_Mean_Real = ('Feature_Value_Real','mean') \n",
    ").reset_index()\n",
    "\n",
    "print(summarized_features_shap)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install joblib==1.1.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(feature_results)\n",
    "#print(all_results)\n",
    "#feature_results.to_csv(\"feature_test_1_30_21.csv\")\n",
    "partial_output_results = pd.concat(all_results)\n",
    "partial_output_features = pd.concat(feature_results)\n",
    "partial_output_results.to_csv(\"partial_acdf_results_5_31_22.csv\")\n",
    "partial_output_features.to_csv(\"partial_acdf_features_5_31_22.csv\")\n",
    "#hyperparam_results.to_csv(\"all_results_acdf_cbc_bmp_hyperparam_lasso_brf_xgb_2_6_22_updated.csv\")\n",
    "\n",
    "print(feature_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_output_file_results = pd.concat(all_results)\n",
    "partial_output_file_results = partial_output_file_results[partial_output_file_results['Procedure'] == \"PLF\"]\n",
    "partial_output_file_results.to_csv(\"partial_plf_results_5_31_22.csv\")\n",
    "    \n",
    "    \n",
    "partial_feature_file_results = pd.concat(feature_results)\n",
    "partial_feature_file_results = partial_feature_file_results[partial_feature_file_results['Procedure'] == \"PLF\"]\n",
    "partial_feature_file_results.to_csv(\"partial_plf_features_5_31_22.csv\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outcome)\n",
    "print(procedure)\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_results = all_results.groupby(['Outcome', 'Features', 'Model']).agg(\n",
    "    WF1_Mean = ('W_F1','mean'),\n",
    "    WF1_SD = ('W_F1', 'std'),\n",
    "    AUC_Mean = ('AUC', 'mean'),\n",
    "    AUC_SD = ('AUC', 'std'),\n",
    "    Acc_Mean = ('Accuracy', 'mean'),\n",
    "    Acc_SD = ('Accuracy', 'std'),\n",
    "    BAcc_Mean = ('Balanced_Accuracy', 'mean'),\n",
    "    BAcc_SD = ('Balanced_Accuracy', 'std'),\n",
    "    Log_Loss_Mean = ('Log-Loss', 'mean'),\n",
    "    Log_Loss_SD = ('Log-Loss', 'std'),\n",
    "    Precision_Neg_Mean = ('Precision_Neg', 'mean'),\n",
    "    Precision_Neg_SD = ('Precision_Neg', 'std'),\n",
    "    Recall_Neg_Mean = ('Recall_Neg', 'mean'),\n",
    "    Recall_Neg_SD = ('Recall_Neg', 'std'),\n",
    "    Precision_Pos_Mean = ('Precision_Pos', 'mean'),\n",
    "    Precision_Pos_SD = ('Precision_Pos', 'std'),\n",
    "    Recall_Pos_Mean = ('Recall_Pos', 'mean'),\n",
    "    Recall_Pos_SD = ('Recall_Pos', 'std'),\n",
    "    n_Mean = ('n', 'mean'),\n",
    "    n_SD = ('n', 'std'),\n",
    "    label_n_Mean = ('label_n', 'mean'),\n",
    "    label_n_SD = ('label_n', 'std')\n",
    "    \n",
    "    \n",
    ").reset_index()\n",
    "\n",
    "summarized_results.to_csv(\"wnd_dehis_summarized_lasso_brf_xgb_2_6_22_updated.csv\")\n",
    "\n",
    "print(summarized_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_coef)\n",
    "print(feature_coef_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_dat = pd.read_csv(r\"Results/LASSO/pre_op_features_2_1_22.csv\", sep=',')\n",
    "feature_dat = pd.read_csv(r\"wnd_dehis_features_lasso_brf_xgb_2_3_22_updated.csv\", sep=',')\n",
    "\n",
    "\n",
    "feature_dat['Feature_Value_Real'] = feature_dat['Feature_Value_Real'].str.strip('[]').astype(float) # uncomment and run this with lasso\n",
    "\n",
    "summarized_features = feature_dat.groupby(['Outcome', 'Model', 'Feature_Name']).agg(\n",
    "    Feature_Value_Mean = ('Feature_Value_Real', 'mean'),\n",
    "    Feature_Value_SD = ('Feature_Value_Real', 'std'),\n",
    "    \n",
    ").reset_index()\n",
    "\n",
    "summarized_features.to_csv(\"wnd_dehiscence_xgb_features_summarized_2_3_22_updated.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myConda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
